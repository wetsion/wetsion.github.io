<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ES嵌套查询与退出嵌套]]></title>
    <url>%2Fes-nested-reverse-nested.html</url>
    <content type="text"><![CDATA[挺久没更新博客了，随手更新一篇吧，最新在使用ES时遇到的一个小问题，记录一下。 业务上有种场景需要对数据进行多条件的查询，数据结构大体如下： 12345678910111213&#123; "batch": 1111, "status": 100, "stages": [ &#123; "id": 123, "waybill": &#123; "companyId": 123, "companyProduct": 321 &#125; &#125; ]&#125; 在es中索引信息大体如下： 123456789101112131415161718192021222324252627&#123; "mappings": &#123; "properties": &#123; "batch": &#123; "type": "long" &#125;, "stages": &#123; "type": "nested", "properties": &#123; "id": &#123; "type": "long" &#125;, "waybill": &#123; "properties": &#123; "companyId": &#123; "type": "integer" &#125;, "companyProduct": &#123; "type": "integer" &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 现在需要先按照 batch 字段做聚合，再根据stages下waybill的companyId和companyProduct做聚合，最后再根据status做聚合。 前面条件很容易能想到再aggs里这样写： 123456789101112131415161718192021222324252627282930&#123; "aggs": &#123; "batch": &#123; "terms": &#123; "field": "batch" &#125;, "aggs": &#123; "stages": &#123; "nested": &#123; "path": "stages" &#125;, "aggs": &#123; "companyId": &#123; "terms": &#123; "field": "stages.waybill.companyId" &#125;, "aggs": &#123; "companyProduct": &#123; "terms": &#123; "field": "stages.waybill.companyProduct" &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 而最后一个条件status字段又是在这个对象结构的根属性，如果继续在上面的json中companyProduct下添加子aggs，那么将查不到结果。 原因是在使用nested进行嵌套聚合时，后续的查询都在这个桶中，如果需要再对不属于当前嵌套的字段进行聚合时，需要先跳出这个桶，即退出嵌套：reverse_nested。 最终可以这样实现： 123456789101112131415161718192021222324252627282930313233343536373839404142&#123; "aggs": &#123; "batch": &#123; "terms": &#123; "field": "batch" &#125;, "aggs": &#123; "stages": &#123; "nested": &#123; "path": "stages" &#125;, "aggs": &#123; "companyId": &#123; "terms": &#123; "field": "stages.waybill.companyId" &#125;, "aggs": &#123; "companyProduct": &#123; "terms": &#123; "field": "stages.waybill.companyProduct" &#125;, "aggs": &#123; "rev": &#123; "reverse_nested": &#123;&#125;, // 退出嵌套 "aggs": &#123; "status": &#123; "terms": &#123; "field": "status" &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>es</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Electron学习和小试牛刀]]></title>
    <url>%2Felectron-vue-markdown-editor.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;前段时间发现了一个好玩的东西：「Electron」，electron是什么呢，electron让前端开发者使用js、html、css就可以构建跨平台的桌面应用程序，electron框架解决了底层原生比较难搞的部分，提供了丰富的API，以及打包生成安装程序，让前端开发者能更专注在应用本身上。 &emsp;&emsp;简言之，通过electron，写js也可以开发桌面app了。 &emsp;&emsp;当我刚看到这个东西，心里还是挺兴奋的，为现在JS的强大而感慨。然后立马着手学习，比葫芦画瓢，上手开发了个桌面MarkDown编辑器。 &emsp;&emsp;首先还是先了解一些基本概念，以及electron提供的API，赋予了我们哪些能力。 &emsp;&emsp;electron本质上是将Chromium和Node合并在了同一个运行环境中，也可以理解为它相当于封装了一个浏览器，我们开发的其实还是web页面，只不过运行在了内置浏览器中，而Node则支持了与操作系统交互。所以，electron的应用架构主要是基于「主进程」和「渲染进程」。 主进程&emsp;&emsp;主进程，从目录结构和代码来说，就是运行package.json和src/main.js脚本的进程。主进程负责创建窗口，创建web页面，包括与操作系统交互的操作。 渲染器进程&emsp;&emsp;上面说到了主进程是创建窗口，而渲染器进程则是负责在创建好的窗口中渲染页面，例如vue代码将会在渲染器进程中解析运行。 &emsp;&emsp;再看一些基本API概念，至少在我的桌面markdown编辑器涉及到的： ipcMain&emsp;&emsp;主进程的通信器，在主进程中使用，用于处理从渲染器进程发送的消息以及向渲染器进程发送消息 接收消息： ipcMain.on(msgName, handler)发送消息： 需要注意的是ipcMain并不像ipcRenderer那样提供了send方法，想要向渲染器进程发消息，需要换种方式：BrowserWindow.getFocusedWindow().webContents.send(msgName, data) ipcRenderer&emsp;&emsp;渲染器进程的通信器，在渲染器进程中使用，向主进程发送消息和接收主进程消息。 接收消息： ipcRenderer.on(msgName, handler)发送消息： ipcRenderer.send(msgName) BrowserWindow&emsp;&emsp;窗口，在主进程中创建 app&emsp;&emsp;在主进程中，控制应用程序的事件生命周期，提供了诸如ready、window-all-closed等事件监听，以及例如quit()这样的方法 dialog&emsp;&emsp;对话框，主进程中执行，弹出例如打开文件、保存文件、警告这样的操作系统对话框 举两个常用的方法，在我的项目里也有涉及的：dialog.showSaveDialog(options, callback) 弹出保存文件对话框，可在options参数中指定保存文件类型dialog.showOpenDialog(options, callback) 弹出打开文件对话框，可在options参数中指定诸如是否能多选文件 Menu&emsp;&emsp;主进程中执行，创建操作系统原生应用菜单、上下文菜单，（包括Mac系统下的dock菜单） 通常调用Menu.buildFromTemplate(template)方法指定模版创建菜单对象，再在应用窗口创建完成后，通过Menu.setApplicationMenu(menus)方法设置应用的系统菜单，针对Mac系统，通过app.dock.setMenu(menu)设置dock菜单 &emsp;&emsp;上述就是项目组用到的基本API，markdown编辑器的UI主要是通过vue + elementUI实现，也就是electron-vue，并引用了一个第三方开源的MarkDown组件：mavonEditor，总体还是挺简单的，实现的功能包括窗口最大化、窗口最小化、关闭窗口、自定义窗口顶部标题栏、自定义系统菜单、自定义dock菜单、打开文件、保存文件、拖拽打开文件。 &emsp;&emsp;项目版本：vue 2.5.16、vue-electron 1.0.6、electron 2.0.4、element-ui 2.13.0 主进程执行的脚本，src/main.js： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209import &#123; app, BrowserWindow, Menu, ipcMain, dialog &#125; from 'electron'if (process.env.NODE_ENV !== 'development') &#123; global.__static = require('path').join(__dirname, '/static').replace(/\\/g, '\\\\')&#125;let mainWindowconst winURL = process.env.NODE_ENV === 'development' ? `http://localhost:9080` : `file://$&#123;__dirname&#125;/index.html`let aboutWindowconst aboutWindowUrl = process.env.NODE_ENV === 'development' ? `http://localhost:9080/#about` : `file://$&#123;__dirname&#125;/index.html#/about`let windowCount = 0function createWindow () &#123; /** * 初始化主窗口 */ mainWindow = new BrowserWindow(&#123; title: '秋月编辑器', height: 600, useContentSize: true, width: 1000, frame: false, // 默认标题栏去掉 // resizable: false, // 是否窗口可调整大小 webPreferences: &#123; nodeIntegration: true, nodeIntegrationInWorker: true, webSecurity: false, devTools: true &#125; &#125;) mainWindow.loadURL(winURL) windowCount ++ mainWindow.on('closed', () =&gt; &#123; mainWindow = null &#125;) // 去除原生顶部菜单栏 mainWindow.setMenu(null) // 自定义Mac 的 dock菜单 const dockMenu = Menu.buildFromTemplate([ &#123; label: '新窗口', click () &#123; createWindow() &#125; &#125; ]) app.dock.setMenu(dockMenu) return mainWindow&#125;// 主进程监听渲染器进程发来的事件// 关闭窗口ipcMain.on('close', () =&gt; &#123; console.log('window count: ', windowCount) BrowserWindow.getFocusedWindow().close()&#125;)ipcMain.on('min', () =&gt; &#123; BrowserWindow.getFocusedWindow().minimize()&#125;)ipcMain.on('max', () =&gt; &#123; BrowserWindow.getFocusedWindow().maximize()&#125;)ipcMain.on('unmax', () =&gt; &#123; BrowserWindow.getFocusedWindow().unmaximize()&#125;)ipcMain.on('ondragstart', (event, filePath) =&gt; &#123; event.sender.startDrag(&#123; file: filePath, icon: `file://$&#123;__dirname&#125;/title/max.png` &#125;)&#125;)ipcMain.on('render-process-open-file', () =&gt; &#123; dialog.showSaveDialog( &#123; filters: [ &#123; name: 'MarkDown', extensions: ['md'] &#125; ] &#125;, (filename, bookmark) =&gt; &#123; console.log('render-process-open-file:', filename) if (filename) &#123; BrowserWindow.getFocusedWindow().webContents.send('main-process-save-to-another', filename) &#125; &#125; )&#125;)app.on('ready', () =&gt; &#123; createWindow() let menu = Menu.buildFromTemplate([ &#123; submenu: [ &#123; label: '关于秋月编辑器', click (event, focusedWindow, focusedWebContents) &#123; if (aboutWindow) &#123; aboutWindow.show() &#125; else &#123; aboutWindow = new BrowserWindow(&#123; title: '关于秋月编辑器', height: 400, useContentSize: true, width: 300, resizable: false, frame: true, webPreferences: &#123; nodeIntegration: true, nodeIntegrationInWorker: true, webSecurity: false, devTools: true &#125; &#125;) aboutWindow.loadURL(aboutWindowUrl) aboutWindow.on('closed', () =&gt; &#123; aboutWindow = null &#125;) &#125; &#125; &#125;, &#123; label: '关闭当前', role: 'close' &#125;, &#123; label: '退出', role: 'quit' &#125; ] &#125;, &#123; label: '文件', submenu: [ &#123; label: '打开..', click (event, focusedWindow, focusedWebContents) &#123; dialog.showOpenDialog( &#123; properties: ['openFile'], filters: [ &#123; name: 'MarkDown', extensions: ['md'] &#125; ] &#125;, (filePaths, bookmarks) =&gt; &#123; console.log(filePaths) if (filePaths) &#123; focusedWindow.webContents.send('main-process-open-file', filePaths) &#125; &#125; ) &#125; &#125;, &#123; label: '保存', click (event, focusedWindow, focusedWebContents) &#123; focusedWindow.webContents.send('main-process-save', 'save') &#125; &#125;, &#123; label: '另存为', click (event, focusedWindow, focusedWebContents) &#123; dialog.showSaveDialog( &#123; filters: [ &#123; name: 'MarkDown', extensions: ['md'] &#125; ] &#125;, (filename, bookmark) =&gt; &#123; console.log(filename) console.log(bookmark) if (filename) &#123; focusedWindow.webContents.send('main-process-save-to-another', filename) &#125; &#125; ) &#125; &#125; ] &#125; ]) Menu.setApplicationMenu(menu)&#125;)app.on('window-all-closed', () =&gt; &#123; if (process.platform !== 'darwin') &#123; app.quit() &#125;&#125;)app.on('activate', () =&gt; &#123; if (mainWindow === null) &#123; createWindow() &#125;&#125;) 主要创建窗口，以及监听处理各类事件。 自定义的窗口顶部标题栏： title.vue 1234567891011121314151617181920212223242526&lt;template&gt; &lt;div id="newTitle"&gt; &lt;div class="left"&gt; &lt;title-btn type="max"/&gt; &lt;title-btn type="min"/&gt; &lt;title-btn type="close"/&gt; &lt;/div&gt; &lt;div class="center"&gt; &lt;span&gt;&#123;&#123; label &#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;div class="right"&gt; &lt;span class="name"&gt;秋月编辑器-MarkDown神器&lt;/span&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import TitleBtn from './TitleBtn/title-btn' import &#123; getMdFilePath &#125; from '@/utils/storerage' export default &#123; name: 'title', components: &#123; TitleBtn &#125;, props: ['label'] &#125;&lt;/script&gt; title-btn.vue： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;template&gt; &lt;div class="title-btn" @click="click"&gt; &lt;img v-if="type === 'max' &amp;&amp; !isMax" id="maxLogo" src="~@/assets/title/max.png" alt="electron-vue"&gt; &lt;img v-if="type === 'max' &amp;&amp; isMax" id="maxLogo" src="~@/assets/title/unmax.png" alt="electron-vue"&gt; &lt;img v-if="type === 'min'" id="minLogo" src="~@/assets/title/min.png" alt="electron-vue"&gt; &lt;img v-if="type === 'close'" id="closeLogo" src="~@/assets/title/close.png" alt="electron-vue"&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; const style = &#123; min: &#123; backgroundColor: 'red', right: '100px' &#125;, max: &#123; // backgroundColor: 'yellow', backgroundImage: '~@/assets/title/max.png', right: '60px' &#125;, close: &#123; backgroundColor: 'black', right: '20px' &#125; &#125; export default &#123; name: 'title-btn', props: ['type'], data () &#123; return &#123; isMax: false &#125; &#125;, computed: &#123; style () &#123; return style[this.type] &#125; &#125;, methods: &#123; click () &#123; console.log(this.type) switch (this.type) &#123; case 'max': if (!this.isMax) &#123; this.$electron.ipcRenderer.send('max') this.isMax = true &#125; else &#123; this.$electron.ipcRenderer.send('unmax') this.isMax = false &#125; break; case 'min': this.$electron.ipcRenderer.send('min') break; case 'close': this.$electron.ipcRenderer.send('close') break; &#125; &#125; &#125; &#125;&lt;/script&gt; markdown编辑主页面： edit.vue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137&lt;template&gt; &lt;div id="editorDiv"&gt; &lt;mavon-editor v-model="markdownText" :toolbars="toolbarConfig" :style="editorStyle" @save="save"/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import &#123; saveMdFilePath &#125; from '@/utils/storerage' const fs = require('fs') export default &#123; name: 'edit', data () &#123; return &#123; markdownText: '', sourceFilePath: undefined, toolbarConfig: &#123; bold: true, // 粗体 italic: true, // 斜体 header: true, // 标题 underline: true, // 下划线 strikethrough: true, // 中划线 mark: true, // 标记 superscript: true, // 上角标 subscript: true, // 下角标 quote: true, // 引用 ol: true, // 有序列表 ul: true, // 无序列表 link: true, // 链接 imagelink: true, // 图片链接 code: true, // code table: true, // 表格 fullscreen: false, // 全屏编辑 readmodel: false, // 沉浸式阅读 htmlcode: true, // 展示html源码 help: true, // 帮助 /* 1.3.5 */ undo: true, // 上一步 redo: true, // 下一步 trash: true, // 清空 save: true, // 保存（触发events中的save事件） /* 1.4.2 */ navigation: true, // 导航目录 /* 2.1.8 */ alignleft: true, // 左对齐 aligncenter: true, // 居中 alignright: true, // 右对齐 /* 2.2.1 */ subfield: true, // 单双栏模式 preview: true &#125; &#125; &#125;, computed: &#123; editorStyle () &#123; console.log(window.innerHeight) return &#123; height: '530px' &#125; &#125; &#125;, mounted () &#123; const editorDiv = document.getElementById('editorDiv') editorDiv.addEventListener('drop', (event) =&gt; &#123; event.preventDefault() const file = event.dataTransfer.files const path = file[0].path console.log('drag file:', path) this.openMd(path) &#125;) editorDiv.addEventListener('dragover', (event) =&gt; &#123; event.preventDefault() &#125;) // 渲染器监听主进程点击保存文件后发送的事件 this.$electron.ipcRenderer.on('main-process-save', () =&gt; &#123; this.save() &#125;) // 渲染器监听主进程点击另存为后发送的事件 this.$electron.ipcRenderer.on('main-process-save-to-another', (event, data) =&gt; &#123; console.log(data) this.saveAnother(data) &#125;) // 渲染器监听主进程打开文件后发送的事件 this.$electron.ipcRenderer.on('main-process-open-file', (event, data) =&gt; &#123; console.log(data) this.openMd(data[0]) &#125;) &#125;, methods: &#123; /** * 保存 */ save () &#123; if (this.sourceFilePath) &#123; // 如果是已经打开的文档，直接保存 this.saveMd(this.sourceFilePath) &#125; else &#123; // 如果是空白文档，先选择存储地址,然后后续按照「另存为」方式 this.$electron.ipcRenderer.send('render-process-open-file') &#125; &#125;, /** * 另存为 */ saveAnother (path) &#123; console.log('save another:', path) if (this.sourceFilePath) &#123; // 如果已经是打开的文件，则直接另存为 this.saveMd(path) &#125; else &#123; // 如果是空白文件，另存时则保存并打开文件 this.sourceFilePath = path this.saveMd(path) this.openMd(path) &#125; &#125;, saveMd (path) &#123; fs.writeFileSync(path, this.markdownText) this.$message.success('保存成功！') &#125;, openMd (path) &#123; this.sourceFilePath = path const content = fs.readFileSync(path) const cttStr = content.toString() console.log(cttStr) this.markdownText = cttStr // this.$electron.ipcRenderer.send('ondragstart', path) // 告知主界面文件路径 this.$emit('set-file-path', this.sourceFilePath) &#125; &#125; &#125;&lt;/script&gt; 效果如下： 源码地址：https://github.com/wetsion/electron-vue-demo electron文档地址：https://www.electronjs.org/docs electron还有很多功能，还需要通过实践去学习探索。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>electron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security Oauth2：实现授权码Redis模式]]></title>
    <url>%2Fspring-security-oauth2-authorization-code-redis.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;在之前rms-auth尝试集群部署的时候出现过一些问题，其中一个问题就是rms-auth认证中心其中一个服务生成的授权码在其他服务中无法通过认证从而无法进一步生成token，后来暂时放弃了认证中心的集群部署，近期着手处理了这个问题。 &emsp;&emsp;在Spring security oauth2授权码模式中，默认情况下生成的授权码生成后存在JVM内存中，也就是说在集群部署时，一个服务生成的授权码只存在当前服务应用的内存中，所以无法被其他服务所认证。可以通过查看源码发现： 在AuthorizationServerEndpointsConfigurer中： 123456 private AuthorizationCodeServices authorizationCodeServices() &#123; if (authorizationCodeServices == null) &#123; authorizationCodeServices = new InMemoryAuthorizationCodeServices(); &#125; return authorizationCodeServices;&#125; 以及在授权码模式的endpoint（AuthorizationEndpoint）里： 1private AuthorizationCodeServices authorizationCodeServices = new InMemoryAuthorizationCodeServices(); &emsp;&emsp;对于授权码的生成、写和读，SpringSecurityOauth2提供了接口：AuthorizationCodeServices，通过实现这个接口，可以自定义授权码操作，默认提供了RandomValueAuthorizationCodeServices、JdbcAuthorizationCodeServices和InMemoryAuthorizationCodeServices三个实现类，后两者继承了RandomValueAuthorizationCodeServices，RandomValueAuthorizationCodeServices提供生成随机授权码字符串的功能，所以我们同样只需要继承该类即可。 &emsp;&emsp;为了解决集群部署情况下的问题，我这里选择将授权码存储在redis中。 自定义一个InRedisAuthorizationCodeServices类： 1234567891011121314151617181920212223242526272829303132public class InRedisAuthorizationCodeServices extends RandomValueAuthorizationCodeServices &#123; private String prefix = "rms:authorization_code:"; private final RedisTemplate&lt;String, Object&gt; redisTemplate; private final JdkSerializationStrategy serializationStrategy = new JdkSerializationStrategy(); public InRedisAuthorizationCodeServices(RedisTemplate redisTemplate) &#123; Assert.notNull(redisTemplate, "redis connection factory required"); this.redisTemplate = redisTemplate; &#125; @Override protected void store(String code, OAuth2Authentication authentication) &#123; String key = prefix + code; redisTemplate.opsForValue().set(key, serializationStrategy.serialize(authentication)); &#125; @Override protected OAuth2Authentication remove(String code) &#123; OAuth2Authentication auth2Authentication = serializationStrategy.deserialize( (byte[])redisTemplate.opsForValue().get(prefix + code), OAuth2Authentication.class); redisTemplate.delete(prefix + code); return auth2Authentication; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125;&#125; 然后在授权服务器配置中将自定义扩展的service配置上： 123456789101112131415161718@EnableAuthorizationServer@Configurationpublic class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter &#123; // 省略其他配置 @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints // 省略其他配置 .authorizationCodeServices(inRedisAuthorizationCodeServices(redisTemplate)); // 省略其他配置 &#125; @Bean public AuthorizationCodeServices inRedisAuthorizationCodeServices(RedisTemplate redisTemplate) &#123; return new InRedisAuthorizationCodeServices(redisTemplate); &#125;&#125; 至此就完成了授权码的redis模式，实现起来还是比较简单的。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
        <tag>SpringSecurityOauth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上手实现一个微型配置中心动态自动更新配置]]></title>
    <url>%2Fspring-config-center-auto-update.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;为什么要实现一个配置中心呢？ &emsp;&emsp;需求背景是组内的很多项目，尤其前后端分离的项目，由于前端项目打包是采用的hash的方式，打包的app.js或者css文件是带有hash值的，之前一直是每次前端有更新，就打包后将新的hash值更新到后端的application.properties中，而后端项目每次更新就得重新发布，一连串影响结果就是每次前端更新却连累后端也得重新发布，这是有点畸形的，前后端的耦合过重。 &emsp;&emsp;在这样一个背景下，长痛不如短痛，于是想到使用类似配置中心的方式来管理这些前端资源的hash版本号，而如果因此就引入Apollo、SpringCloudConfig这种专业的配置中心又过于笨重。考虑到本身我们RMS统一平台就维护有所有产品线子系统信息，可以在此基础上，维护一份配置项信息，与各自的子系统关联，RMS平台提供一个查询给RMS-SDK，RMS-SDK新增配置中心的功能，子系统通过SDK自动动态更新配置项的值，无需重启。 &emsp;&emsp;虽说是一个微型的配置中心，但也分为server和client两部分。 server&emsp;&emsp;server主要就是RMS平台，配置项数据的管理，以及持久化，server在内部管理数据的同时，对外提供一个查询的接口，主要用于SDK的查询。server端没什么好说的，就不放代码了，放张编辑配置项的图片意思一下： client&emsp;&emsp;client即指子系统，子系统在引用了新SDK之后便具有了配置中心client的角色，配置项数据的更新等操作都是由SDK在底层自动完成，对子系统是无感知的。 &emsp;&emsp;下面详细说下客户端 SDK的实现。 1.开启配置中心&emsp;&emsp;定义了一个注解@EnableRmsConfigCenter，在入口类或者@Configuration修饰的类上使用该注解开启配置中心，该注解Import了一个RmsConfigCenterRegistrar类，在RmsConfigCenterRegistrar中向Spring容器注册了两个bean定义（BeanDefinition）： 123456789101112131415161718192021@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(RmsConfigCenterRegistrar.class)public @interface EnableRmsConfigCenter &#123; String type() default "http";&#125;public class RmsConfigCenterRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, SelfDefConfigProcessor.class.getName(), SelfDefConfigProcessor.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, PropertySourceProcessor.class.getName(), PropertySourceProcessor.class); &#125;&#125; &emsp;&emsp;@EnableRmsConfigCenter中的type用于指定获取配置中心数据的方式，默认以http轮询，也可以指定redis从rms平台的redis中获取。 &emsp;&emsp;RmsConfigCenterRegistrar注册了两个bean定义，后面将一一说明。 2.SelfDefConfigProcessor记录使用@Value注解的类、字段先看下SelfDefConfigProcessor的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class SelfDefConfigProcessor implements BeanPostProcessor, BeanFactoryAware &#123; private BeanFactory beanFactory; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; Class clazz = bean.getClass(); for (Field field : findAllField(clazz)) &#123; processField(bean, beanName, field); &#125; return bean; &#125; private void processField(Object bean, String beanName, Field field) &#123; Value value = field.getAnnotation(Value.class); if (value == null) &#123; return; &#125; String key = value.value(); SelfDefConfigValue selfDefConfigValue = new SelfDefConfigValue(key, beanName, field, bean); SelfDefConfigValueRegistry.register(beanFactory, key, selfDefConfigValue); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125; private List&lt;Field&gt; findAllField(Class clazz) &#123; final List&lt;Field&gt; fields = new LinkedList&lt;&gt;(); ReflectionUtils.doWithFields(clazz, new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException, IllegalAccessException &#123; fields.add(field); &#125; &#125;); return fields; &#125;&#125; &emsp;&emsp;SelfDefConfigProcessor类实现了BeanPostProcessor接口，即Bean后处理器（BeanPostProcessor的bean会被Spring上下文检测到，并将其用于后面Bean的创建，例如在postProcessBeforeInitialization()方法中实现一些标记操作，在postProcessAfterInitialization()方法中实现一些包装操作），这里我们主要在postProcessBeforeInitialization()实现主要逻辑，解析每个Bean的字段，如果字段被@Value注解修饰，则将@Value的value值连同字段、当前Bean、Bean的名称一起封装成SelfDefConfigValue类对象，并将其与其对应的BeanFactory关联存储在自定义的注册表SelfDefConfigValueRegistry中，在后面监听到配置更新时，我将从注册表中查找对应配置项所在的类和字段。 3.PropertySourceProcessor初始化配置项数据以及长轮询监听配置项数据变化还是先看下代码： 12345678910111213141516171819202122232425262728293031323334public class PropertySourceProcessor implements EnvironmentAware, BeanFactoryPostProcessor &#123; PlatformBean platformBean; private ConfigurableEnvironment environment; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; log.info(environment.getProperty("client-id")); platformBean = (PlatformBean) beanFactory.getBean("platformBean"); log.info(platformBean.getClientId()); this.initPropertySources(beanFactory); &#125; private void initPropertySources(ConfigurableListableBeanFactory beanFactory) &#123; if (environment.getPropertySources().contains(PropertySourcesConstants.RMS_PROPERTY_SOURCE_NAME)) &#123; return; &#125; ConfigDataChangeListener listener = new ConfigDataChangeListener( environment, beanFactory); ConfigDataPropertySource configDataPropertySource = new ConfigDataPropertySource(PropertySourcesConstants.RMS_PROPERTY_SOURCE_NAME, PropertySourcesConstants.RMS_CONFIG_DATA_REPOSITORY_HTTP, listener, platformBean); ConfigDataPropertySourceFactory.addConfigDataPropertySource(configDataPropertySource); environment.getPropertySources().addFirst(configDataPropertySource); &#125; @Override public void setEnvironment(Environment environment) &#123; this.environment = (ConfigurableEnvironment) environment; &#125;&#125; &emsp;&emsp;PropertySourceProcessor实现了BeanFactoryPostProcessor接口，实现了BeanFactoryPostProcessor接口的Bean也会被spring上下文自动检测到，在spring创建Bean之前应用，但BeanFactoryPostProcessor与BeanPostProcessor不同，BeanFactoryPostProcessor不能和bean实例交互，只可以修改bean定义（BeanDefinition），BeanFactoryPostProcessor接口提供的postProcessBeanFactory()可用于修改spring上下文内部的bean factory。在我定义的PropertySourceProcessor中，在postProcessBeanFactory()方法，主要是为了在Bean实例化之前，获取到配置中心的配置项数据，并将这些数据设置到Spring的环境（Environment）中，用于后续bean实例化之后，Spring将Environment中的PropertySource注入到@Value修饰的变量中。 &emsp;&emsp;这里通过实现Spring的PropertySource接口，自定义了ConfigDataPropertySource，在这里封装了初始第一次从server获取配置项，由于是扩展的PropertySource接口，所以可以设置到Spring的Environment中，Spring也自然可以通过getProperty()获取配置数据并注入到bean。 &emsp;&emsp;同时ConfigDataPropertySource还开启了一个定时线程池，轮询配置中心server获取配置项，有更新时，则调用定义的监听器ConfigDataChangeListener，从之前写入的注册表SelfDefConfigValueRegistry中找到配置项对应的bean以及字段，通过反射修改字段值。 具体代码如下： 12345678910111213141516171819202122232425public class ConfigDataPropertySource extends PropertySource&lt;Object&gt; &#123; private ConfigDataRepository configDataRepository; public ConfigDataPropertySource(String name, String type, ConfigDataChangeListener listener, PlatformBean platformBean) &#123; super(name); log.info("ConfigDataPropertySource init"); this.configDataRepository = "redis".equals(type) ? new RedisConfigDataRepository() : new HttpConfigDataRepository(listener, platformBean); &#125; @Nullable @Override public Object getProperty(String name) &#123; return configDataRepository.getPlatformConfigDataCache().getConfigurations().getProperty(name); &#125; public void addChangeListener(ConfigDataChangeListener listener) &#123; configDataRepository.addChangeListener(listener); &#125;&#125; 获取、轮询数据以及监听数据进一步封装成了ConfigDataRepository，提供两种实现，即Redis读取和Http轮询：RedisConfigDataRepository、HttpConfigDataRepository，这里只看Http即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class HttpConfigDataRepository implements ConfigDataRepository &#123; private volatile AtomicReference&lt;PlatformConfigDataCache&gt; platformConfigDataCache; private ConfigDataChangeListener listener; private PlatformBean platformBean; private final static ScheduledExecutorService executorService; static &#123; executorService = Executors.newScheduledThreadPool(1, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r, "Rms_Http_Config_Data_Repository_Thread-" + System.currentTimeMillis()); thread.setDaemon(true); if (thread.getPriority() != Thread.NORM_PRIORITY) &#123; thread.setPriority(Thread.NORM_PRIORITY); &#125; return thread; &#125; &#125;); &#125; public HttpConfigDataRepository(ConfigDataChangeListener listener, PlatformBean platformBean) &#123; this.platformConfigDataCache = new AtomicReference&lt;&gt;(); this.platformBean = platformBean; this.addChangeListener(listener); this.syncData(); this.scheduleRefreshData(); &#125; @Override public synchronized void syncData() &#123; // 同步获取数据，如果变化就调用listener RestTemplate restTemplate = new RestTemplate(); try &#123; String result = restTemplate.getForObject(platformBean.getConfigUrl() + "?clientId=" + platformBean.getClientId(), String.class); if (Objects.nonNull(result)) &#123; JSONObject jsonObject = JSONObject.parseObject(result); log.info(jsonObject.toJSONString()); if (jsonObject.getBooleanValue("success")) &#123; Properties properties = ConfigDataUtil.trasformConfigData( jsonObject.getJSONObject("results").getString("configs")); PlatformConfigDataCache current = new PlatformConfigDataCache(); current.setClientId(platformBean.getClientId()); current.setConfigurations(properties); current.setLastUpdateTime( jsonObject.getJSONObject("results").getLong("updateTime")); PlatformConfigDataCache previous = this.platformConfigDataCache.get(); if (Objects.isNull(previous)) &#123; this.platformConfigDataCache.set(current); log.debug("after set cache: &#123;&#125;", JSON.toJSONString(this.platformConfigDataCache.get())); &#125; else &#123; if (current.getLastUpdateTime() &gt; previous.getLastUpdateTime()) &#123; this.platformConfigDataCache.set(current); listener.onChange(current); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; log.error("获取配置数据失败", e); &#125; &#125; @Override public void scheduleRefreshData() &#123; // 周期性调用syncData() executorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; log.info("start refresh config data"); syncData(); &#125; &#125;, 20, 10, TimeUnit.SECONDS); &#125; @Override public void addChangeListener(ConfigDataChangeListener listener) &#123; this.listener = listener; &#125; @Override public PlatformConfigDataCache getPlatformConfigDataCache() &#123; return this.platformConfigDataCache.get(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class ConfigDataChangeListener &#123; private final Environment environment; private final ConfigurableBeanFactory beanFactory; public ConfigDataChangeListener(Environment environment, ConfigurableListableBeanFactory beanFactory) &#123; this.beanFactory = beanFactory; this.environment = environment; &#125; public void onChange(PlatformConfigDataCache newData) &#123; Properties properties = newData.getConfigurations(); Enumeration names = properties.propertyNames(); while (names.hasMoreElements()) &#123; String key = (String) names.nextElement(); List&lt;SelfDefConfigValue&gt; selfDefConfigValues = SelfDefConfigValueRegistry.getRegistry() .get(beanFactory) .get(PropertySourcesConstants.RMS_CONFIG_PROPERTY_PREFIX + key + PropertySourcesConstants.RMS_CONFIG_PROPERTY_SUBFIX); if (Objects.nonNull(selfDefConfigValues)) &#123; selfDefConfigValues.forEach(selfDefConfigValue -&gt; &#123; try &#123; selfDefConfigValue.update(properties.getProperty(key)); &#125; catch (IllegalAccessException e) &#123; log.error("更新 @value 失败, bean name: [&#123;&#125;], key: [&#123;&#125;]", selfDefConfigValue.getBeanName(), selfDefConfigValue.getKey(), e); &#125; &#125;); &#125; &#125; &#125;&#125; &emsp;&emsp;这样一个配置中心以及动态自动更新配置就实现了，具体代码在 https://github.com/wetsion/study/tree/master/src/main/java/com/wetsion/study/self_def_config_center 写在后面的话。实现这样一个配置中心主要基于对Apollo（阿波罗）的学习。在有这样一个想法之后，在SpringCloudConfig和Apollo中选择了Apollo，通过学习它的源码，对自动更新原理有了较清晰的理解，也感叹别人的设计。当然我这样一个微型的配置中心也是有很多需要完善的地方，比如没有对namespace作区分处理，就会存在重名的问题，也就会发生冲突，所以后续完善过程中在轻量的同时，也要保证没有大问题。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习：过期策略]]></title>
    <url>%2Fredis-expire-policy.html</url>
    <content type="text"><![CDATA[redis的过期策略有定期删除（主动）和惰性删除（被动）。 （主动）定期删除，就是redis每隔段时间就会随机抽取一些设置了过期时间的key，检查是否过期，若过期则删除，默认是每隔100毫秒。 这里redis具体的操作是：1.从设置了过期时间的key中随机抽取20个key做测试，2.从这20个key中找到已过期的并删除，3.如果这20个key中已过期的超过了25%则从第一步再重新开始。以上操作redis每秒执行10次。 （被动）惰性删除，就是在获取某个key时，redis检查一下是否设置了过期时间以及是否过期，如果过期了就会删除，并且不会返回任何东西。 但如果定时删除漏掉了一些过期key，并且后续也没查这些key，那么也就不会走惰性删除，那么这些key也就堆积在内存中了，会消耗内存，如果已使用的内存大于maxmemory，这时redis还有一个内存淘汰机制。 内存淘汰的过程是，客户端要执行新命令，例如新增，redis先检查内存使用情况，如果大于maxmemory，根据已配置的策略清除key，然后再执行新命令。 redis的内存淘汰机制提供了以下几种： noeviction “不驱逐”，顾名思义，就是不会清除内存，当内存不足以写入新数据时，新写入数据会报错。 allkeys-lru LRU还是挺常见的，Least Recently Used，即最近最少使用，当内存不足以写入新数据时，在所有的key里，删除最近最少使用的key。 allkeys-random 当内存不足以写入新数据时，从所有的key中，随机删除某个key volatile-lru 从已设置过期时间的key中，删除最近最少使用的key volatile-random 从已设置过期时间的key中，随机删除某个key volatile-ttl 从已设置过期时间的key中，优先删除最早要过期的key 通过命令： CONFIG GET maxmemory-policy 可以查看当前淘汰策略，我本地redis是4.0.10版本，默认是noeviction。 通过 CONFIG SET maxmemory-policy allkeys-lru 可设置淘汰策略 对于maxmemory，通过CONFIG GET maxmemory命令查看到默认为0（64位系统默认为0，32位系统默认为3GB内存限制），即代表对内存使用没有限制，直到耗尽所有可用内存（当到达极限时，redis会返回内存不足的错误，但不会因为内存不足而使服务器死机），所以最好做一些限制，可以使用CONFIG SET maxmemory xxx设置maxmemory为指定大小。 另外，值得一提的是，在删除一部分key之后，redis并不是将内存直接释放回操作系统，RSS可能仍然是之前的大小，但redis的内存分配器可以重用空闲的内存块，在删除一部分key之后再写入新的key，分配器会尝试重用之前释放的内存，RSS可能会保持稳定或者不会增长很多。 扩展：Redis中LRU策略关于redis的LRU最近最少使用策略，其实有些疑惑是如何找到最近最少使用的key，在通过查阅文档和一部分源码后有了一些了解。 12345678910// server.h 里定义的 db 结构typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ dict *expires; /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */&#125; redisDb; redis的LRU其实也还是随机采样的，只不过对于allkeys-lru和volatile-lru，采样的基础数据集不一样，allkeys-lru的基础是整个db下的所有数据（源码中的redisDb下的*dict），而volatile-lru的基础数据是已设置过期时间的数据（源码中的redisDb下的*expires）,然后都是从基础数据集中随机抽取maxmemory-samples个数据， maxmemory-samples是配置的采样个数，默认为5，可通过CONFIG SET maxmemory-samples 10来设置，设置的越大，采样的精度越准确，但同样也越消耗CPU，效率越低。 然后淘汰掉最少使用的key。而在maxmemory-samples个采样数据中，最少使用的数据该如何确定呢？ 123456789101112// server.h 里定义的 redisObject 结构#define LRU_BITS 24typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj; 可以看到，在redis中，所有的redis对象结构都有一个lru字段，是24位的unsigned类型字段，该字段的高16位用来记录访问时间，低8位用来记录访问频率，有了这个字段，就可以判断谁是最少使用的了。 关于redis的过期策略相关先学习到这里，还是要再结合源码多看看。]]></content>
      <categories>
        <category>后端</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS：SVG学习及在微信小程序中的简单运用]]></title>
    <url>%2Fcss-svg-and-use-in-miniprogram.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;之前简单学习了svg，但无用武之地，很快就忘了，最近在写小程序项目时，想要实现一个上下的边框粗细渐变的一个效果，类似如下图： &emsp;&emsp;就类似这样，在上下各有一条粗细渐变的细线，不知如何实现，于是想到使用svg来试试。 &emsp;&emsp;首先先了解学习下SVG。 （参考阮一峰的博客：https://www.ruanyifeng.com/blog/2018/08/svg.html） &emsp;&emsp;SVG其实是一种图像格式，基于xml语法，官方名称是可缩放矢量图，相对于其他图像格式是基于像素处理，它则是基于对图像的形状描述，所以特点就是不论放大多少倍都不会失真。 &emsp;&emsp;SVG可以写在网页中，直接在网页上显示；也可以写在.svg文件中，通过&lt;img&gt;、&lt;iframe&gt;、&lt;object&gt;等标签引用插入在网页中，或者在css中通过url()引入；也可以转为base64编码，作为data uri引入（在小程序中我就是采用这种方式）。 &emsp;&emsp;由于SVG是基于xml语法，所以SVG的语法主要就是svg提供的一些标签，主要有以下标签： &lt;svg&gt; &emsp;&emsp;最外层的当然就是&lt;svg&gt;标签，提供了三个属性： width heigth &emsp;&emsp;&lt;svg&gt;的宽度和高度，表示svg图像在html元素中占据的高度宽度，如果是百分比，则是相对位置，如果是数字，就是单位是像素的绝对位置，如果未指定这两个属性，svg图像默认是宽300px 高150px。 viewBox &emsp;&emsp;表示svg图像的视图大小，比如只想展示svg图像的一部分，注意这里是视图大小不是svg的大小，svg图像还是上面俩属性设置的大小，但展示的可能只是svg图像的一部分，viewBox设置四个数字，分别是左上角的横纵坐标、视图的宽高，比如svg宽高是100，viewBox设置 0 0 50 50，那么整个svg只显示原来50 x 50的图像，也就是左上角四分之一被放大了四倍。 &lt;polyline&gt; &emsp;&emsp;用于绘制一根折线，有以下属性： points 主要属性，指定折线中的各个点的坐标，通过依次连接这些点构成一条折线，坐标横纵坐标用英文逗号分隔，点之间用空格分隔 fill svg中很多标签都有的属性，指定填充的颜色，支持颜色名、16进制颜色、rgb颜色，这里就是个折线，不存在填充，所以一般设置none，如果不设置为none，那么将会默认填充黑色，就和下面polygon标签等效了 stroke 同样svg很多都有的属性，指定描边线条的颜色，也支持颜色名、16进制颜色、rgb颜色，默认无颜色 stroke-width 指定描边线条的宽度 &lt;polygon&gt; &emsp;&emsp;用于绘制多边形，属性同上面&lt;polyline&gt;，通过将属性points配置的点连接起来形成一个闭合的多边形，fill指定多边形填充的颜色，如果不配置，默认黑色 &lt;line&gt; &emsp;&emsp;用于绘制直线，属性x1和y1分别指定起点的横纵坐标，属性x2和y2分别指定终点的横纵坐标；fill和stroke属性同上述标签 &lt;circle&gt; &lt;ellipse&gt; &lt;rect&gt; &emsp;&emsp;这三个标签有点类似，&lt;circle&gt;通过属性 cx和cy确定圆心的横纵坐标，再通过属性r确定圆的半径，进行绘制圆形，fill、stroke、stroke-width属性同上述标签；&lt;ellipse&gt;通过属性cx和cy确定圆心的横纵坐标，再通过属性rx和ry指定椭圆横向轴和纵向轴的半径，完成绘制椭圆形，fill、stroke、stroke-width属性同上述标签；&lt;rect&gt;通过属性x和y确定矩形左上角点的横纵坐标，再通过width和height确定矩形宽和高，完成绘制矩形，fill、stroke、stroke-width属性同上述标签。 &lt;path&gt; &emsp;&emsp;用于制路径 &lt;text&gt; &emsp;&emsp;用于绘制文本，属性x和y代表文本区块基线起点的横纵坐标 &lt;use&gt; &emsp;&emsp;用于复制一个形状，属性href指定被复制的形状节点，属性x和y设置左上角的坐标 &lt;g&gt; &emsp;&emsp;用于将多个形状组成一个组，方便复用 &lt;defs&gt; &emsp;&emsp;用于自定义形状，内部代码不会显示，仅供引用 &lt;animate&gt; &emsp;&emsp;用于制作动画效果，用在形状标签内，让该形状产生动画效果，属性attributeName 发生动画效果的属性名，属性from单次动画的初始值，属性to单次动画的结束值，属性dur单次动画的持续时间，属性repeatCount动画的循环模式（indefinite无限循环） &lt;animateTransform&gt; &emsp;&emsp;上面&lt;animate&gt;对css的transform不起作用，如果要变形、旋转，就使用该标签。 &emsp;&emsp;学习了svg，那么怎么实现开头说的那个效果呢，首先写好一段svg，再将svg转成base64编码，作为data uri在小程序的样式中，被background-image引用，代码如下： 12345678&lt;view class="id"&gt; &lt;view class="border-line"&gt;&lt;/view&gt; &lt;view&gt; &lt;text&gt;会员ID:&#123;&#123;userId&#125;&#125;&lt;/text&gt; &lt;text&gt;邀请码:&#123;&#123;userInviteCode&#125;&#125;&lt;/text&gt; &lt;/view&gt; &lt;view class="border-line"&gt;&lt;/view&gt;&lt;/view&gt; &emsp;&emsp;border-line样式的view就是我打算显示渐变边框的地方，样式如下： 12345.avatar-name-div .name-div .id .border-line&#123; height: 2px; width: 100%; background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' height='100%25' width='100%25'%3E %3Cpolygon points='0,1 125,0 250,1 125,2 0,1' fill='%23e9ded8'/%3E %3C/svg%3E");&#125; 最终实现效果如下： &emsp;&emsp;好了，关于svg的学习和实践就先记录到此，svg来实现画一些图形确实还是挺不错的，但也让我延伸想到canvas，后面有时间再了解了解canvas。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>css</tag>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：@Scope注解学习]]></title>
    <url>%2Fspring-boot-annotation-scope.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近在项目中遇到了一个bug，在解决bug的过程中，发现自己以往对于@Scope注解的理解一直存在问题，甚至是有些错误的，通过排查项目中bug以及写demo、查阅资料，对于@Scope有了新的认识。 &emsp;&emsp;先通过注解的javadoc，可以了解到，@Scope在和@Component注解一起修饰在类上，作为类级别注解时，@Scope表示该类实例的范围，在和@Bean一起修饰在方法上，作为方法级别注解时，@Scope表示该方法返回的实例的范围。 &emsp;&emsp;对于@Scope注解，我们常用的属性一般就是：value和proxyMode，value就是指明使用哪种作用域范围，proxyMode指明使用哪种作用域代理。 &emsp;&emsp;@Scope定义提供了的作用域范围一般有：singleton单例、prototype原型、requestweb请求、sessionweb会话，同时我们也可以自定义作用域。 作用域范围 &emsp;&emsp;singleton单例范围，这个是比较常见的，Spring中bean的实例默认都是单例的，单例的bean在Spring容器初始化时就被直接创建，不需要通过proxyMode指定作用域代理类型。 &emsp;&emsp;prototype原型范围，这个使用较少，这种作用域的bean，每次注入调用，Spring都会创建返回不同的实例，但是，需要注意的是，如果未指明代理类型，即不使用代理的情况下，将会在容器启动时创建bean，那么每次并不会返回不同的实例，只有在指明作用域代理类型例如TARGET_CLASS后，才会在注入调用每次创建不同的实例。 &emsp;&emsp;requestweb请求范围，（最近遇到的问题就是和request作用域的bean有关，才发现之前的理解有偏差），当使用该作用域范围时（包括下面的session作用域），必须指定proxyMode作用域代理类型，否则将会报错，对于request作用域的bean，（之前一直理解的是每次有http请求时都会创建），但实际上并不是这样，而是Spring容器将会创建一个代理用作依赖注入，只有在请求时并且请求的处理中需要调用到它，才会实例化该目标bean。 &emsp;&emsp;sessionweb会话范围，这个和request类似，同样必须指定proxyMode，而且也是Spring容器创建一个代理用作依赖注入，当有会话创建时，并且在会话中请求的处理中需要调用它，才会实例话该目标bean，由于是会话范围，生命依赖于session。 作用域代理 &emsp;&emsp;如果指定为proxyMode = ScopedProxyMode.TARGET_CLASS，那么将使用cglib代理创建代理实例；如果指定为proxyMode = ScopedProxyMode.INTERFACE，那么将使用jdk代理创建代理实例；如果不指定，则直接在Spring容器启动时创建该实例。而且使用代理创建代理实例时，只有在注入调用时，才会真正创建类对象。 &emsp;&emsp;除了上述作用域范围，Spring也允许我们自定义范围，主要操作为： 先实现Scope接口创建自定义作用域范围类 使用CustomScopeConfigurer注册自定义的作用域范围 &emsp;&emsp;后面写了一个例子实践一下，自定义了一种同一分钟的作用域范围，即同一分钟获取的是相同实例。 &emsp;&emsp;首先自定义作用域范围类TimeScope: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Slf4jpublic class TimeScope implements Scope &#123; private static Map&lt;String, Map&lt;Integer, Object&gt;&gt; scopeBeanMap = new HashMap&lt;&gt;(); @Override public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) &#123; Integer hour = Calendar.getInstance().get(Calendar.HOUR_OF_DAY); // 当前是一天内的第多少分钟 Integer minute = hour * 60 + Calendar.getInstance().get(Calendar.MINUTE); log.info("当前是第 &#123;&#125; 分钟", minute); Map&lt;Integer, Object&gt; objectMap = scopeBeanMap.get(name); Object object = null; if (Objects.isNull(objectMap)) &#123; objectMap = new HashMap&lt;&gt;(); object = objectFactory.getObject(); objectMap.put(minute, object); scopeBeanMap.put(name, objectMap); &#125; else &#123; object = objectMap.get(minute); if (Objects.isNull(object)) &#123; object = objectFactory.getObject(); objectMap.put(minute, object); scopeBeanMap.put(name, objectMap); &#125; &#125; return object; &#125; @Override public Object remove(String name) &#123; return scopeBeanMap.remove(name); &#125; @Override public void registerDestructionCallback(String name, Runnable callback) &#123; &#125; @Override public Object resolveContextualObject(String key) &#123; return null; &#125; @Override public String getConversationId() &#123; return null; &#125;&#125; Scope接口提供了五个方法，只有get()和remove()是必须实现，get()中写获取逻辑，如果已有存储中没有该名称的bean，则通过objectFactory.getObject()创建实例。 &emsp;&emsp;然后注册自定义的作用域范围： 123456789101112131415161718192021@Configuration@Slf4jpublic class BeanScopeConfig &#123; @Bean public CustomScopeConfigurer customScopeConfigurer() &#123; CustomScopeConfigurer customScopeConfigurer = new CustomScopeConfigurer(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeScope", new TimeScope()); customScopeConfigurer.setScopes(map); return customScopeConfigurer; &#125; @Bean @Scope(value = "timeScope", proxyMode = ScopedProxyMode.TARGET_CLASS) public TimeScopeBean timeScopeBean() &#123; TimeScopeBean timeScopeBean = new TimeScopeBean(); timeScopeBean.setCurrentTime(System.currentTimeMillis()); log.info("time scope bean"); return timeScopeBean; &#125;&#125; &emsp;&emsp;然后注入调用timeScopeBean，同一分钟内重复调用，使用相同实例，不同分钟将创建新实例。 &emsp;&emsp;关于@Scope新的理解认识就这些了，以后再有新理解再补充吧 (⊙﹏⊙)b]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：iView和elementUI嵌套弹窗问题]]></title>
    <url>%2Fvue-iview-elementui-multi-modal.html</url>
    <content type="text"><![CDATA[最近在写一个使用elementUI的Vue前端项目时，有一个需求是在弹窗显示了关联的列表信息后，再点击列表中某条记录，进行弹窗编辑，也就是嵌套弹窗。 其实前阵子在写另一个使用iView的Vue前端项目时，也碰到了类似的问题，这一次就一起整理做下记录。 elementUI对于elementUI，提供的弹窗组件是&lt;el-dialog&gt;&lt;/el-dialog&gt;，想要解决嵌套的问题，即在外层父级el-dialog加上属性:modal-append-to-body=&quot;false&quot;和append-to-body=&quot;true&quot;，而在内层子级el-dialog加上属性append-to-body=&quot;true&quot;，样例代码如下： 1234&lt;el-dialog title="父级弹窗" :visible.sync="showParent" :modal-append-to-body="false" append-to-body&gt; &lt;el-dialog :title="子级弹窗" :visible.sync="showChild" append-to-body&gt; &lt;/el-dialog&gt;&lt;/el-dialog&gt; iView对于iView呢，提供的弹窗组件是&lt;Modal&gt;&lt;/Modal&gt;，想要解决嵌套的问题，比elementUI要复杂一些。首先需要知道的是，iView中的Modal默认的z-index是1000，而想要嵌套，则后面子级弹窗的z-index需要配置大于1000，同时父级弹窗需要配置属性:transfer=&quot;false&quot;，这样后面子级的弹窗将会覆盖父级弹窗，样例代码如下： 12345678910&lt;template&gt; &lt;Modal v-model="showParent" :transfer="false" title="父级弹窗"&gt; &lt;Modal v-model="showChild" title="子级弹窗" class-name="child-modal"&gt;&lt;/Modal&gt; &lt;/Modal&gt;&lt;/template&gt;&lt;style&gt; .child-modal &#123; z-index: 1002; &#125;&lt;/style&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：CyclicBarrier学习]]></title>
    <url>%2Fjava-source-concurrent-cyclicbarrier.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;前面刚学了CountDownLatch，文末提到了CyclicBarrier，可以重置计数，那么这篇笔记就顺便学习下CyclicBarrier。 &emsp;&emsp;从CyclicBarrier类单词就可以看出来，这是一个循环的屏障、栅栏，让所有线程都被阻止在这个栅栏之前，等到所有线程都到达栅栏（也就是都被阻塞了），然后打开栅栏，让所有被阻止的线程都执行。 &emsp;&emsp;show me code！还是写个栗子： 12345678910111213141516171819202122232425262728293031public class CyclicBarrierTest &#123; public static void main(String[] args) &#123; final CyclicBarrier cb = new CyclicBarrier(3, new Runnable() &#123; @Override public void run() &#123; System.out.println("铁柱彩礼钱借够了，结婚"); System.out.println("铁柱老婆带着钱跟隔壁老王跑了"); &#125; &#125;); ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i=0;i&lt; 9;i++)&#123; final int user = i+1; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep((long) (Math.random() * 1000)); int k = cb.getNumberWaiting() + 1; System.out.println("铁柱借钱凑彩礼，当前已有" + k + "百万"); cb.await(); System.out.println("铁柱卖血搬砖还钱"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; threadPool.execute(runnable); &#125; threadPool.shutdown(); &#125;&#125; 运行结果： 123456789101112131415161718192021222324铁柱借钱凑彩礼，当前已有1百万铁柱借钱凑彩礼，当前已有2百万铁柱借钱凑彩礼，当前已有3百万铁柱彩礼钱借够了，结婚铁柱老婆带着钱跟隔壁老王跑了铁柱卖血搬砖还钱铁柱卖血搬砖还钱铁柱卖血搬砖还钱铁柱借钱凑彩礼，当前已有1百万铁柱借钱凑彩礼，当前已有2百万铁柱借钱凑彩礼，当前已有3百万铁柱彩礼钱借够了，结婚铁柱老婆带着钱跟隔壁老王跑了铁柱卖血搬砖还钱铁柱卖血搬砖还钱铁柱卖血搬砖还钱铁柱借钱凑彩礼，当前已有1百万铁柱借钱凑彩礼，当前已有2百万铁柱借钱凑彩礼，当前已有3百万铁柱彩礼钱借够了，结婚铁柱老婆带着钱跟隔壁老王跑了铁柱卖血搬砖还钱铁柱卖血搬砖还钱铁柱卖血搬砖还钱 &emsp;&emsp;还是和CountDownLatch例子一样现实的例子，为了体现CyclicBarrier的可重置，这里假设铁柱借钱凑彩礼钱结婚（在我的老家，借钱凑彩礼钱的现象还是很普遍的），但这次比较倒霉，结婚后老婆卷钱跟隔壁老王跑了，然后忍痛卖血搬砖还钱，然后继续攒钱，最后不断地继续重蹈覆辙。。。 &emsp;&emsp;在这个例子中，「借钱凑彩礼」这类子线程在调用await()方法后会被阻塞，直到被阻塞的子线程数量达到了CyclicBarrier初始化时定义的3个，那么将会放开，唤醒继续执行这些被阻塞的线程（也就是例子中借钱后的还钱～），如果CyclicBarrier使用的是和例子一样的构造方法（参数是阻塞线程数量和栅栏放开触发执行的线程），那么将会先执行定义的栅栏放开触发执行的线程，再继续执行被阻塞的线程。 &emsp;&emsp;从运行结果来看，似乎是当阻塞的线程达到了定义的数量，就会触发栅栏放开，并且栅栏又重置了，那么是怎么实现的呢，还是从学习源码入手。 await()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; int index = --count; if (index == 0) &#123; // tripped boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();&#125; &emsp;&emsp;CyclicBarrier是基于ReentrantLock实现的，内部有一个ReentrantLock对象属性，在调用的核心实现dowait()方法中，首先使用lock.lock()上锁，用来保证dowait()操作是同步操作。 &emsp;&emsp;CyclicBarrier中有个静态内部类Generation，每个CyclicBarrier实例中每一回合都会初始化一个Generation对象属性: generation（每一回合是指栅栏没被破坏或重置，如果被破坏或重置，就是新的一回合），Generation类中只有一个属性：boolean broken，用于记录当前栅栏是否被破坏（breakBarrier()），当栅栏被破坏或重置（reset()）时，该值都会改变。 &emsp;&emsp;在dowait()中，获取generation，判断当前栅栏当前这一回合的broken状态，如果为true，说明被破坏或者重置过，则抛出异常。再判断当前线程是否被中断，如果当前线程被中断，那么这个线程将不可能会到达栅栏，为了避免死锁，调用breakBarrier()方法破坏栅栏，并抛出异常。校验过栅栏的broken状态和线程状态之后，将count值减一（count是CyclicBarrier中用于记录栅栏前仍需要等待的线程数量），如果count等于0，说明设定数量的线程都已到达了栅栏前，如果在CyclicBarrier构造初始化时设置了栅栏放开触发执行的线程，那么执行栅栏放开触发执行的线程（从command.run()可以看出，这里执行是同步执行该线程，而非异步并发执行），然后调用nextGeneration()方法： 1234567private void nextGeneration() &#123; // signal completion of last generation trip.signalAll(); // set up next generation count = parties; generation = new Generation();&#125; &emsp;&emsp;调用nextGeneration()方法唤醒在条件队列等待的线程（这里是条件队列，trip是ReentrantLock的Condition对象，调用signalAll()方法将条件队列等待的线程添加到同步队列中参与竞争锁，这里参考前面学习AQS关于Condition的笔记，那么条件队列等待的线程是什么时候插入的呢，在后面await()将会看到），并重置栅栏前仍需等待的线程数量，以及重新初始化generation对象，CyclicBarrier的循环重置就是在这里实现的。 &emsp;&emsp;调用nextGeneration()重置之后返回，如果这里出现了异常，则调用breakBarrier()破坏栅栏，使失败。 &emsp;&emsp;而对于count不等于0，也就是当前线程到达后，当前线程不是最后一个到达的线程，栅栏前还有线程没到达，则进入循环，直到栅栏被破坏或者线程中断或者超时。在循环中，根据timed参数判断是否是需要超时等待，如果不是，则调用trip.await()直接进入等待，即AQS中ConditionObject#await(): 123456789101112131415161718public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 该方法实现可中断的条件等待，CyclicBarrier通过调用该方法将当前线程加入到AQS的条件队列中等待。 &emsp;&emsp;如果需要超时等待，并且参数nanos等待时间大于0，则调用trip.awaitNanos(nanos)进行超时等待： 123456789101112131415161718192021222324252627public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime();&#125; 和await()差不多，只不过多了超时时间。 &emsp;&emsp;再回到dowait()，在加入当前线程到条件队列进行等待之后，判断栅栏当前回合的broken状态，如果已被破坏，则抛出异常；g != generation如果已经是新的回合，则直接返回；如果是需要超时等待，但时间已到，则调用breakBarrier()破坏栅栏，唤醒在条件队列等待的线程，然后抛出异常。 &emsp;&emsp;CyclicBarrier还可以使用reset()来主动介入使栅栏重置： 12345678910public void reset() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; breakBarrier(); // break the current generation nextGeneration(); // start a new generation &#125; finally &#123; lock.unlock(); &#125;&#125; &emsp;&emsp;通过breakBarrier()破坏当前回合栅栏，并重新开启新的回合。 &emsp;&emsp;CyclicBarrier相对来说是比CountDownLatch复杂的，巧妙地使用ReentrantLock和Condition实现了阻塞、计数，并且可以重用，相比CountDownLatch更灵活，还可以使到达栅栏后先执行指定的触发任务再执行后续任务。]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：CountDownLatch学习]]></title>
    <url>%2Fjava-source-concurrent-countdownlatch.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;前面相继学习了ReentrantLock和Semaphore，都是基于AQS来实现的，这次学习的CountDownLatch同样也是基于AQS实现的。 &emsp;&emsp;CountDownLatch可以理解是一个倒计时计数器，是用于让一个或多个线程等待在其他线程的操作执行完之后再执行的同步辅助。值得注意的是。这里的倒计时计数是一次性的，计数无法重置，即调用countDown()方法来计数，await()方法等待阻塞直到计数减到零，到达零之后释放所有等待的线程，后续任何的await()调用都是立即返回。 &emsp;&emsp;talk is cheap, show me code!还是从一个例子开始入手： 123456789101112131415161718192021222324252627282930313233343536373839public class CountDownLatchTest &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; @Override public void run() &#123; try &#123; System.out.println("正在攒钱买房..."); Thread.sleep((long) (Math.random()*10000)); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); new Thread()&#123; @Override public void run() &#123; try &#123; System.out.println("正在攒钱买车..."); Thread.sleep((long) (Math.random()*10000)); latch.countDown(); System.out.println("还有" + latch.getCount() + "个目标没完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); //主线程 System.out.println("等待有车有房后就结婚"); try &#123; //等待，阻塞点 latch.await(); System.out.println("已经买车买房了，准备结婚了！"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果： 12345正在攒钱买房...正在攒钱买车...等待有车有房后就结婚还有1个目标没完成已经买车买房了，准备结婚了！ &emsp;&emsp;栗子就像社会一样现实，想要结婚（执行人生的主线程任务），就得先完成攒钱买车买房（这些子线程任务）。 &emsp;&emsp;首先初始化CountDownLatch，传参是2，即定义为两个待完成目标： 12345678public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count);&#125;// SyncSync(int count) &#123; setState(count);&#125; &emsp;&emsp;构造方法中即初始化内部类Sync（同ReentrantLock、Semaphore一样，都是AQS的实现类），Sync的构造方法中调用AQS的setState()方法，设置初始同步状态state，也可以理解为需要等待的目标数。 &emsp;&emsp;在执行的子线程中调用countDown()方法来倒计时： 1234567891011121314151617181920212223public void countDown() &#123; sync.releaseShared(1);&#125;// AQSpublic final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;// CountDownLatch Syncprotected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; &emsp;&emsp;这里其实类似其他类的release()方法，在Sync的tryReleaseShared()中，自旋，获取同步状态值state，如果state等于0，说明已经倒计时到0了，没有需要等待完成的目标了，返回false；如果不为0，则减一，再通过CAS修改state的值，如果修改成功，再判断减一之后的值是否等于0。这里如果返回true，才会调用AQS的doReleaseShared()唤醒在等待的线程。 &emsp;&emsp;那么在等待的线程是如何进入等待的呢，栗子中的结婚主线程是调用await()等待阻塞的： 123456789101112131415public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;// AQSpublic final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;// CountDownLatch Syncprotected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; &emsp;&emsp;这里倒像是前面学习的那些类的获取锁，通过getState()获取同步状态state，如果等于0，则返回1，说明没有需要等待完成的目标了，可以直接执行当前线程；如果不等于0，返回-1，说明还有需要等待完成的目标，则调用AQS的doAcquireSharedInterruptibly()方法将当前线程插入到等待队列队尾进行阻塞等待。 开头说到CountDownLatch计数是一次性的，看到这里也应该有了答案，因为await()是需要判断当前同步状态state的值的，而countDown()将state不断地减一，并没有其他方法来将state值重置，所以一旦state值到达了0，那么后续其他调用await()等待的线程都会直接执行。 &emsp;&emsp;OK，CountDownLatch类的实现比较简单，基本上就看完了，类注释中提到，针对需要重置计数，可以考虑使用CyclicBarrier，那么下一目标就是学习CyclicBarrier了。]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：Semaphore学习]]></title>
    <url>%2Fjava-source-concurrent-semaphore.html</url>
    <content type="text"><![CDATA[前面在学习了AQS之后又学习了下ReentrantLock，接下来再来看下Semaphore。 Semaphore就是信号量，通常用于限制线程数，控制同时访问资源的线程数量。也是基于AQS来实现的，和ReentrantLock类似，也分公平锁和非公平锁，默认也是使用非公平锁。 先通过一个买票的例子来练习下，设定有两个卖票窗口，有十个人要买票，可以使用Semaphore来实现： 1234567891011121314151617181920212223242526272829303132333435public class SemaphoreDemo &#123; static class SemphoreRunner implements Runnable&#123; private Semaphore semaphore; private int user; public SemphoreRunner(Semaphore semaphore, int user)&#123; this.semaphore = semaphore; this.user = user; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println("用户：" + user + "进入窗口，准备买票"); Thread.sleep((long) (Math.random() * 3000)); System.out.println("用户：" + user + "买好票，准备离开"); Thread.sleep((long) (Math.random() * 3000)); System.out.println("用户：" + user + "已经离开"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125; &#125; public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(2); ExecutorService service = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++)&#123; service.execute(new SemphoreRunner(semaphore, i+1)); &#125; service.shutdown(); &#125;&#125; 运行结果： 123456789101112131415161718192021222324252627282930用户：1进入窗口，准备买票用户：2进入窗口，准备买票用户：1买好票，准备离开用户：1已经离开用户：3进入窗口，准备买票用户：2买好票，准备离开用户：3买好票，准备离开用户：3已经离开用户：4进入窗口，准备买票用户：2已经离开用户：5进入窗口，准备买票用户：4买好票，准备离开用户：4已经离开用户：6进入窗口，准备买票用户：5买好票，准备离开用户：5已经离开用户：7进入窗口，准备买票用户：6买好票，准备离开用户：6已经离开用户：8进入窗口，准备买票用户：7买好票，准备离开用户：8买好票，准备离开用户：8已经离开用户：9进入窗口，准备买票用户：7已经离开用户：10进入窗口，准备买票用户：9买好票，准备离开用户：9已经离开用户：10买好票，准备离开用户：10已经离开 使用Semaphore，必须先调用acquire()获取锁（或者说是许可，这里我还是称呼其为锁，只不过Semaphore维护了多把锁），先看下acquire()源码： acquire()1234567891011public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;// AQS :public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 这里sync是内部类Sync对象，是AQS在Semaphore的抽象实现，这里Sync和ReentrantLock中的Sync类似，也有两个子类实现，即公平与非公平两个版本，这里调用sync.acquireSharedInterruptibly(1)实际上是调用AQS的acquireSharedInterruptibly()方法，从前面学习已经知道，acquireSharedInterruptibly()是在共享模式下的获取锁（会被线程中断打断），先调用AQS子类实现的tryAcquireShared()来尝试获取锁，这里就是调用Semaphore中Sync的tryAcquireShared()，分为了公平和非公平两个实现版本，先看下默认的非公平实现： 非公平的tryAcquireShared()12345678910111213protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125;// Sync#nonfairTryAcquireShared()final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 在非公平的实现中，调用Sync默认提供了的nonfairTryAcquireShared()方法，在nonfairTryAcquireShared()中先获取AQS中的同步状态state（这里state的是在Semaphore对象new的时候通过Sync调用AQS的setState设置的），也就是可用的锁的个数，拿state减去要获取的锁个数（默认为1），如果小于0，说明目前没有剩余可用锁，则直接返回负值；如果大于0，则再通过CAS修改state的值，修改为减之后的值，如果成功，则返回剩余锁个数（即获取锁成功了），如果失败则继续循环。 再看下公平的实现： 公平的tryAcquireShared()1234567891011protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 这里也是自旋，先通过hasQueuedPredecessors()判断当前线程之前是否存在排队线程，如果有排队等待的线程，则不参与获取锁的竞争，返回-1；如果没有，则同样获取当前同步状态state，即可用锁个数，减去要获取的锁个数，如果小于0，即目前无剩余可用锁，直接返回负值；如果大于0，和非公平实现一样，通过CAS修改state，如果成功，返回剩余锁个数（为正数），失败则继续自旋循环。 接上文，在AQS的acquireSharedInterruptibly()中，如果tryAcquireShared()大于0，即获取锁成功，如果为负值，即获取锁失败，调用doAcquireSharedInterruptibly()方法，这里在前文AQS的学习中已知晓，将当前线程插入到等待队列队尾排队等待唤醒，不再赘述。 对于acquire()获取锁的操作，Semaphore的公平和非公平实现又体现在哪，有什么区别呢，通过通读源码，不难发现，公平的实现比非公平的实现多了两行代码，即if (hasQueuedPredecessors()) return -1;，公平的实现会先判断在等待队列里是否有线程在排队等待，而非公平的实现则直接参与竞争锁。 release()Semaphore的release()方法直接调用AQS的releaseShared()： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 再调用Semaphore中Sync的tryReleaseShared()实现，这里非公平和公平都共用该方法释放锁： 12345678910protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) return true; &#125;&#125; 这里实现也比较简单，即计算释放锁之后可用锁的数量，然后CAS操作将state更新成新的值，成功后，在调用AQS的doReleaseShared()唤醒后续等待的线程，不再赘述。 Semaphore作为信号量，可以使用在竞争资源有限的场景，但讲道理，实际开发中，却是没用到过 -.-||]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：ReentrantLock学习]]></title>
    <url>%2Fjava-source-concurrent-reentrantlock.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;前面学习了AQS，趁热打铁继续学习基于AQS实现的可重入锁ReentrantLock。 使用ReentrantLock的方式也很简单，通常都是以下的方式来使用： 1234ReentrantLock lock = new ReentrantLock();lock.lock();// 代码lock.unlock(); 关于lock.lock()&emsp;&emsp;实现即为调用Sync对象的lock()方法，而可重入锁的同步控制基础就是内部类Sync，而Sync就是继承自AbstractQueuedSynchronizer实现的，使用AQS的state来表示持有锁的线程的数量。Sync的子类有FairSync和NonfairSync，也就是常听说的可重入锁的公平锁版本和非公平锁版本，通过在构造方法里传入true或false来选择使用公平锁或者非公平锁。 在默认情况使用无参构造方法，创建的是非公平锁即NonfairSync， 先看下非公平锁的lock()：123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; &emsp;&emsp;可以看到，先通过AQS中的CAS操作compareAndSetState在期望是0的情况下尝试将state状态设置为1，如果成功了，也就是说明了AQS中的锁是无线程持有的，那么就调用setExclusiveOwnerThread()将当前线程设置为独占模式下拥有锁的线程，即顶层父类AbstractOwnableSynchronizer的Thread exclusiveOwnerThread属性；如果CAS操作失败，说明锁被其他线程持有，那么就调用acquire(1)进行尝试获取锁，可能会将当前线程插入同步队列队尾，这里在前面学习AQS的笔记中已经解析过。 而对于公平锁FairSync的lock()：123final void lock() &#123; acquire(1);&#125; &emsp;&emsp;则是只调用acquire(1)来参与尝试获取锁。 &emsp;&emsp;前文学习AQS的时候已经知道，acquire()会先调用子类实现的tryAcquire()方法来尝试获取锁，那么再看下公平与非公平版本是分别如何实现的。 非公平锁NonfairSync的tryAcquire()：1234567891011121314151617181920212223protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;// Sync.classfinal boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; &emsp;&emsp;NonfairSync的tryAcqiure()是直接调用父类Sync的nonfairTryAcquire()方法。再看nonfairTryAcquire()方法，先获取当前线程，调用AQS的getState()获取同步状态即锁的状态，如果状态c等于0，并且通过CAS设置state成功，则将当前线程设置为独占锁的线程，这里和NonfairSync#lock()第一步还是一样的（所以非公平锁还是挺霸道的，一来就是想直接独占锁，即便第一步失败了，在第二步tryAcquire的时候还是「贼心不死」，还是想尝试再直接独占锁）；如果同步状态c不为0，再判断当前线程是否是独占锁的线程，如果是，则对状态c进行累加，即标明重入次数，将新的状态值进行设置。在上面两步判断中，如果CAS设置失败则返回false，以及如果当前线程不是锁的独占持有的线程也返回false，都说明尝试获取锁失败，在前文学习AQS已经知道，tryAcquire()失败则将当前线程插入同步队列进行等待排队获取锁。 再看公平锁FairSync的tryAcquire()1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; &emsp;&emsp;同样也是先获取当前线程以及获取锁的状态，如果锁的状态c等于0，即没有线程持有锁，再调用hasQueuedPredecessors()判断当前线程之前是否存在排队线程，如果不存在，则通过CAS设置state，如果设置成功，则将当前线程设置为独占锁的线程，返回true；如果锁的状态不为0，并且当前线程就是独占锁的线程，那么和NonfairSync的tryAcqiure()做法相同，不做赘述。 关于lock.unlock()&emsp;&emsp;实现即调用sync.release(1)，由于Sync并没重写release()方法，所以无论公平锁还是非公平锁都是调用的AQS的release()： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; AQS再调用子类Sync实现的tryRelease()： 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; &emsp;&emsp;先将锁的状态减去释放的数量，这里是减1，再判断当前线程是否是独占锁的线程，如果不是，就抛出异常；再判断减1之后的锁状态值是否等于0，如果等于0，说明完全释放了锁，则将独占锁的线程设为空；继续再设置锁状态，返回释放成功与否，只有锁状态为0即完全释放了锁时，才会返回true。 &emsp;&emsp;再回到release()中，tryRelease()释放成功之后，调用unparkSuccessor()唤醒后继等待的线程，前文学习AQS已学习了，不再赘述。 &emsp;&emsp;通过对比，可以发现，公平锁获取锁还需要先判断同步队列中是否存在排队的线程，按照等待顺序来获取锁，而非公平锁则没这个限制，是更「霸道」的抢占，而ReentrantLock默认也是非公平锁，或许是因为非公平锁这种特征会效率更高。 其他方法tryLock()123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; &emsp;&emsp;对于不带等待时间参数的tryLock()，其实公平锁和非公平锁都是调用非公平的nonfairTryAcquire()，而带有等待时间参数的tryLock(): 123456789101112public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125;// AQS 中的方法：public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; &emsp;&emsp;可以看到这种带有等待时间的，先调用AQS的tryAcquireNanos()，在其中，再根据公平锁还是非公平锁调用相应的tryAcquire()实现，如果tryAcquire()尝试获取锁失败，则调用doAcquireNanos()以独占定时的模式获取锁: 123456789101112131415161718192021222324252627282930private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; &emsp;&emsp;其实对比acquireQueued()方法，可以发现，相差不大，只是多了对时间的判断，在doAcquireNanos()中，先计算出deadline，也就是设置的定时的结束时间，然后就是和acquireQueued()类似的将当前线程加入等待队列，后面在死循环中遍历前驱节点，直到前驱节点是头节点并且尝试获取锁成功，在循环过程中加了对时间的判断，如果超过了设置的定时结束时间，则直接返回false退出。]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年七夕]]></title>
    <url>%2Flife-2019-qixi.html</url>
    <content type="text"><![CDATA[又是一年七夕，不知道啥时候能脱单哦，唉。 又想找个女朋友，又害怕找个女朋友，觉得自己现在没啥能力，而现在不再是校园，进入社会女生都冲着结婚去的，自己又能给别人什么呢，没房没车的，唉，努力吧！]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fasterxml Jackson远程代码执行漏洞修复方案]]></title>
    <url>%2Ffasterxml-jackson-bug-resolve.html</url>
    <content type="text"><![CDATA[最近fasterxml jackson爆出了同阿里fastjson类似的远程代码执行的漏洞，修复方案也是同样的升级版本，但jackson不同于fastjson，jackson被很多插件所依赖，影响面比较广，只单单的引入新的jackson-databind并不能完全有效，所幸官方也及时更新了一个pom，这里记录一下。 在根项目maven的pom.xml文件里的dependencyManagement中引入新的pom： 1234567&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-bom&lt;/artifactId&gt; &lt;version&gt;2.9.9.2.20190727&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>踩坑</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：AbstractQueuedSynchronizer(AQS)学习(二)]]></title>
    <url>%2Fjava-source-concurrent-aqs2.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;上一篇笔记学习了AQS的独占锁与共享锁，这篇笔记继续学习AQS。 &emsp;&emsp;AQS中还有个ConditionObject类，ConditionObject实现了Condition接口，Condition提供了一系列等待和通知的方法，例如await()、awaitUninterruptibly()、signal()、signalAll()等，Condition是用来实现线程之间的等待，而且Condition对象只能在独占锁中使用。 &emsp;&emsp;同样，先看下ConditionObject中有哪些属性： private transient Node firstWaiter 条件队列的头节点 private transient Node lastWaiter 条件队列的尾节点 &emsp;&emsp;ConditionObject类中包含了这样两个属性，中维护一个Node节点构成的条件队列，而Node中又有一个nextWaiter，说明了条件队列是单向队列。 &emsp;&emsp;看下await()是如何实现让当前持有锁的线程阻塞等待释放锁的： 123456789101112131415161718public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; &emsp;&emsp;可以看到await()不会忽略中断，如果当前线程被中断，则抛出异常；调用addConditionWaiter()往条件队列添加一个等待节点： 12345678910111213141516171819202122232425262728293031323334private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125;&#125; &emsp;&emsp;这里先获取条件队列的尾节点，如果尾节点的状态不为CONDITION，则调用unlinkCancelledWaiters()（从条件队列头节点开始遍历，如果节点的状态不为CONDITION，将节点从条件队列中移除）；根据当前线程创建状态为CONDITION的新节点；如果尾节点不存在，将新节点设置为头节点，否则将新节点设置为尾节点的后继节点，同时将新节点设置为新的尾节点（ 总结一句话就是新建条件节点插入到条件队列队尾 ）。 &emsp;&emsp;再回到await()接着看，新建完节点之后，调用fullyRelease()： 123456789101112131415final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; &emsp;&emsp;获取当前state状态值，使用这个状态调用release()释放独占锁并唤醒同步队列中下一个等待节点，释放成功，将当前节点的状态设置为CANCELLED，失败就抛出异常。 &emsp;&emsp;通过fullRelease()释放锁之后，使用isOnSyncQueue()判断当前节点是否在同步队列中，如果不在同步队列，则阻塞当前线程，如果已经在同步队列，调用acquireQueued()获取锁，然后当前节点的后继节点如果不为空，说明条件队列该节点后面有在等待的线程，则调用unlinkCancelledWaiters()将条件队列中不为CONDITION中的节点移除，最后，如果interruptMode为THROW_IE则抛出异常，如果是REINTERRUPT，则中断当前线程。 再看signal()： 123456789101112131415161718192021222324public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; &emsp;&emsp;这里先通过子类实现重写的isHeldExclusively()来判断当前线程是否独占锁，如果未持有锁，则抛出异常，然后从条件队列的头节点firstWaiter开始遍历，将头节点的后继节点设置为新的头节点，如果新的头节点为空，那说明条件队列是个空队列了，那么再将尾节点也设置为null，为了方便GC，再将first.nextWaiter引用设置为null，在do-while循环条件中，调用transferForSignal()，将头节点的状态通过CAS更新为默认的0（如果更新失败，说明该节点状态不为CONDITION了，即已经在同步队列里了，返回false退出，继续doSignal()的循环），然后调用enq(node)将节点插入到同步队列中，在上一篇文章说独占模式的时候，已经知道enq()返回的是插入之前时，同步队列的尾节点，而这个尾节点也是当前插入节点的前驱节点，而插入的节点自然成为新的尾节点，然后获取之前尾节点也就是当前节点前驱节点的waitStatus，如果waitStatus大于0也就是CANCELLED状态，或者无法通过CAS设置成SIGNAL状态，则调用Lock.unpark()唤醒当前节点中的线程，然后退出doSignal()中的循环。 &emsp;&emsp;从上面的源码可以发现，signal()唤醒并不是立即唤醒，而是将条件队列的节点插入到同步队列尾部等待，还是需要等待前面的节点获取完锁之后，才会轮到它。 总结 &emsp;&emsp;其实对于await()和signal()，我觉得可以用几句话就能简单总结，在独占模式下，多个线程争抢锁，某个线程A获取到了锁（其他线程由于阻塞进入到同步队列中），而这个线程可以使用await()释放锁，阻塞自己，将当前线程添加到条件队列中（注意这里是条件队列而不是同步队列，就意味着这个线程将不能再参与争抢锁），而这时，其它在同步队列中的线程将获取锁，在某一个线程B获取到锁之后，它也可以继续await()释放锁，把自己放到条件队列中，也可以通过signal()将在条件队列中第一个线程唤醒，将其加入到同步队列参与竞争锁（或者通过signalAll()将条件队列中的所有线程唤醒，都加入到同步队列中参与竞争锁）。 &emsp;&emsp;用最近在玩的「云顶之弈」游戏来比喻的话（可能不太贴切），同步队列好比放在棋盘上等待参与战斗的英雄们，而条件队列相当于在棋盘下方放置的备用英雄们，棋盘上的英雄竞争攻击的机会，await()就相当于玩家通过把英雄放回到下方备用英雄区，而signal()就相当于把备用区的英雄放到棋盘上参与战斗。 &emsp;&emsp;再写个栗子加深下理解： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ConditionDemo &#123; static class Thread1 implements Runnable&#123; private Lock lock; private Condition condition; public Thread1(Lock lock, Condition condition) &#123; this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; try &#123; System.out.println("线程1争抢锁"); lock.lock(); System.out.println("线程1获得锁，调用await释放锁"); condition.await(); System.out.println("线程1被唤醒"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; static class Thread2 implements Runnable&#123; private Lock lock; private Condition condition; public Thread2(Lock lock, Condition condition) &#123; this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; try &#123; System.out.println("线程2争抢锁"); lock.lock(); System.out.println("线程2获得锁, 调用await释放锁"); condition.await(); System.out.println("线程2被唤醒"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; static class Thread3 implements Runnable&#123; private Lock lock; private Condition condition; public Thread3(Lock lock, Condition condition) &#123; this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; try &#123; System.out.println("线程3争抢锁"); lock.lock(); System.out.println("线程3获得锁"); condition.signalAll(); System.out.println("线程3唤醒条件队列等待线程"); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); Thread thread1 = new Thread(new Thread1(lock, condition)); Thread thread2 = new Thread(new Thread2(lock, condition)); Thread thread3 = new Thread(new Thread3(lock, condition)); thread1.start(); thread2.start(); Thread.sleep(5000L); thread3.start(); &#125;&#125; &emsp;&emsp;这里定义了三个线程，线程一和二先来争抢锁，然后都使用await()，然后主线程等待5秒后再启用线程三，线程三中使用signalAll()将条件队列中所有线程唤醒，运行结果如下： 123456789线程1争抢锁线程1获得锁，调用await释放锁线程2争抢锁线程2获得锁, 调用await释放锁线程3争抢锁线程3获得锁线程3唤醒条件队列等待线程线程1被唤醒线程2被唤醒 &emsp;&emsp;可以看到，线程1先获取到锁，然后await()释放锁之后先进入条件队列，所以再最后唤醒时也是先唤醒加入到同步队列，先获取锁。 &emsp;&emsp;这篇笔记又学习了AQS的条件队列Condtion这一块，后面笔记将再结合具体的AQS实现类来学习AQS以及并发各种同步的实现。]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年生日暨入职丁香园一周年]]></title>
    <url>%2Flife-2019-birthday.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;今年生日挺巧的，正好和入职现在所在的丁香园一周年是同一天。 &emsp;&emsp;其实也是来杭州一周年多几天，时间总是过得很快，回头想想这一年，一时不知道自己有哪些变化，自己有比一年前的自己有进步吗？ &emsp;&emsp;这一年来，工作的重心有大半是在前端方面，对于Vue的使用倒也称得上是熟练了，或许也只是熟练而已。心里还是有些抵触，不愿花更多时间去深入学习前端，总是很矛盾，一方面觉得自己毕竟不是专门干前端的，还占用自己学习后端的时间，即便花时间去学习前端，也不可能去找前端的工作，即便找前端工作，又没有别人专门做的前端的精通；另一方面，又觉得似乎多一项前端方面的技能也是不错，看着自己写出来的「烂」页面，竟有时也有些成就感….。 &emsp;&emsp;就在这种纠结中，工作了一年了，其实自己也知道，学习和总结做的都不好，之前断断续续偶尔做过笔记，但颇有心血来潮之意，三分热度之后便抛之脑后。从六月开始，也许久在这种安逸的环境（不得不说，现在所在的部门确实是相对安逸的，工作压力并没多大），也许是突然醒悟，意识到自己竟已毕业两年了，不能再这样浑浑噩噩下去，个人角度来说，不可能在丁香园一直干下去，而想要往高处走，就得提升自己，多学习多积累多总结。 &emsp;&emsp;笔记博客一定是要坚持写的，目标也是要定的，以进阿里等大厂的要求作为目标，正所谓，取乎其上，得乎其中，取乎其中，得乎其下，取乎其下，则无所得矣，或许自己能力真的到达不了大厂的要求，但明确目标和计划，为之努力了，总会有一个对得起自己的结果。 &emsp;&emsp;祝自己生日快乐，许的愿望能实现！]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码学习：AbstractQueuedSynchronizer(AQS)学习]]></title>
    <url>%2Fjava-source-concurrent-aqs.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近在学习JUC包下相关类时，例如如ReentrantLock、Semaphore等，发现内部都是基于Java提供的AQS框架来实现的，也就是AbstractQueuedSynchronizer类，所以先学习搞懂此类，再去看那些类，也会有助于理解。 &emsp;&emsp;AQS即AbstractQueuedSynchronizer，是JUC提供的一个框架，用于实现依赖于先进先出（FIFO）等待队列的阻塞锁和相关同步器（信号量，事件等），此类旨在成为依赖单个原子int值来表示状态的大多数同步器的有用基础，正如这个类的注释说的，此类支持默认独占模式和共享模式之一或两者，即独占锁和共享锁。 &emsp;&emsp;AQS常见的使用方式就是定义内部类继承它，将该内部类作为一个辅助类来实现同步。 &emsp;&emsp;在类注释一开始就提到了依赖于一个FIFO队列，这个队列是一个同步队列，在类的内部有一个Node静态内部类，该类就是CLH队列中节点的实现，看一下源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 可以看到具有以下属性， &emsp;&emsp;节点中包含前驱节点prev和后继节点next，说明这个同步队列是一个双向队列； &emsp;&emsp;waitStatus表示当前节点的状态，默认状态值为0（condition时默认初始化为CONDITION），一共有五个状态，除了默认0之外，还有SIGNAL(-1)、CANCELLED(1)、CONDITION(-2)、PROPAGATE(-3)： CANCELLED 代表线程已取消，由于超时或者被打断，具有该状态的节点不会再被阻塞 SIGNAL 代表此节点的后续的节点是被阻塞（或将被阻塞）的，那么当当前节点释放或者取消的时候，就需要unpark唤醒它的后继节点。 PROPAGATE 代表releaseShared应该传播到其他节点，仅在doReleaseShared()中设置，也仅限头节点，以确保继续传播。 CONDITION 代表当前节点线程处在条件队列中（这个是一个特殊状态，只在condition队列即等待队列中节点中存在，同步队列中不存在这种状态的节点） &emsp;&emsp;thread属性代表当前节点持有的线程，或者说拥有当前节点的线程 &emsp;&emsp;nextWaiter属性是链接在条件队列等待的下一个节点，或者是特殊值SHARED。如果是特殊在SHARED，所在当前节点是共享模式；如果是null，代表所在的当前节点是独占模式，如果是其他值，所在的当前节点也是独占模式，但nextWaiter将是condition条件队列的下一个节点。 &emsp;&emsp;通过看AbstractQueuedSynchzonizer类的注释和通览整个类，虽然是个抽象类，但并没有一个抽象方法，而需要子类重写实现的方法都是通过在方法体抛出UnsupportedOperationException异常来让子类知道，提供了以下五个方法给子类实现 tryAcquire 尝试在独占模式下acquire，子类实现方法应查询对象的状态state字段是否允许以独占模式acquire，如果允许，那么可以acquire。该方法通常在线程执行acquire时（即执行acquire()方法）调用，如果失败，则acquire()方法会将线程加入等待队列（如果还没加入等待队列），直到它被其他线程发出的信号释放 tryRelease 尝试在独占模式下设置状态来体现对节点的释放，通常在线程执行release()方法释放节点时调用 tryAcquireShared 尝试在共享模式下acquire，子类实现方法应查询对象的state状态字段是否允许acquire，如果允许，可以acquire。方法通常在线程执行acquire时（即执行acquireShared()）调用，如果失败，则acquireShared会将线程加入等待队列（如果线程还没加入等待队列），直到被其他线程发出的信号释放 tryReleaseShared 尝试在共享模式下设置状态来体现对节点的释放，通常在线程执行releaseShared()方法释放节点时调用 isHeldExclusively 判断当前同步器是否仅被当前线程独占。需要注意的是，该方法仅被AbstractQueuedSynchronizer.ConditionObject中的方法调用，因此不使用condition条件，则不需要实现。 &emsp;&emsp;除了内部类Node之外，还有一个ConditionObject，这里先暂不去看它。再看AbstractQueuedSynchronizer还有哪些属性： private transient volatile Node head; 同步队列的头节点，如果head存在，head节点的waitStatus属性确保不会成为CANCELLED private transient volatile Node tail; 同步队列的尾节点 ，仅会在enq()方法新增新的等待节点时被修改，即每当新节点进来都会被插到最后 private volatile int state; 同步状态，也可以理解为锁的状态，0代表没被占用，大于0代表有线程持有当前锁 &emsp;&emsp;同时对于这些属性以及Node类中的属性，除了使用volatile修饰之外，AQS还提供了对应的CAS操作，来保证以原子方式来将这些属性设置为给定的更新值，例如compareAndSetHead()、compareAndSetWaitStatus()。 &emsp;&emsp;前面通过注释了解到AQS类支持独占模式（独占锁）和共享模式（共享锁），在独占锁下，其他线程试图获取锁就无法成功，在共享锁下，多个线程获取锁可能会成功。 先看一下如何实现独占锁。 独占模式（独占锁）&emsp;&emsp;独占锁，顾名思义，就是在多个线程尝试获取锁的时候，只能有一个线程能获取到锁，而其他线程将会被阻塞等待（按照FIFO排队等待），而持有锁的线程释放锁之后，将会唤醒正在等待锁的下一个线程。 而获取独占锁，主要依靠acquire()方法和acquireInterruptibly()： 123456789101112public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; &emsp;&emsp;acquireInterruptibly()是以独占可中断模式获取锁，而acquire()也是独占模式获取锁，但会忽略中断。acquireInterruptibly()会先判断线程是否中断，若中断就抛出异常。 &emsp;&emsp;两个方法都会首先通过tryAcquire()尝试获取锁，tryAcquire()方法前面说过，是留给子类实现的，用于查询state的值来判断允许以独占模式获取锁，如果可以则返回true，即代表当前线程获得了锁，acquire()方法直接返回，可以执行当前线程要做的操作。如果返回false，说明当前线程没有获得锁， &emsp;&emsp;acquireInterruptibly()将会接着调用doAcquireInterruptibly()（其实查看doAcquireInterruptibly()会发现其实就是等同于acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，不同点是acquireQueued()中if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) 后只是 interrupted = true，而doAcquireInterruptibly() 却将异常抛了出去throw new InterruptedException()，具体看下面的源码学习） &emsp;&emsp;而acquire()则是接着继续执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，这里先执行addWaiter(Node.EXCLUSIVE)： 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; &emsp;&emsp;这里传入的参数为Node.EXCLUSIVE，通过注释可知是代表是独占模式，在addWaiter()中将当前线程包装成node节点，然后获取tail尾节点。1.如果有尾节点，将当前node节点的前驱节点指向尾节点，再通过CAS操作，将当前node节点设置为新的尾节点，成功后再将老的尾节点的后继节点指向到当前node节点（也就是新的尾节点），通过这番操作，新增的节点都会作为尾节点插入到队列中，并构成了一个双向队列。2.如果没尾节点（说明此时这是一个空队列），则调用enq()方法： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; &emsp;&emsp;可以看到这里是个for(;;)死循环，还是先获取尾节点，如果尾节点为空，则创建一个无任何的Node节点，并通过CAS操作设置成head头节点，再将头节点设置到尾节点，进入下一次循环，这样就能获取到尾节点了，将当前节点的前驱节点指向尾节点（由于前面将头节点指向了尾节点，所以此时当前节点的前驱节点也就是头节点），再通过CAS操作将当前节点设置为新的尾节点，再将旧的尾节点的后继节点指向当前节点（也就是头节点的后继节点指向了当前节点），这样也将当前节点插到了队尾，并也构成了一个双向队列。 &emsp;&emsp;再回到前面，addWaiter()当前节点插入队尾成功后，再执行acquireQueued()： 12345678910111213141516171819202122232425final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; &emsp;&emsp;这个方法用于让在队列中的线程以独占模式获取锁，通常被condition wait方法（ConditionObject中的方法）以及acquire()方法调用。可以看到依然是for(;;)死循环，首先获取当前节点的前驱节点，1.如果前驱节点是头节点，并且通过tryAcquire()获取锁成功，则将当前节点设置为头节点，并将当前节点中的线程清空，当前节点的前驱节点也设为空（这里p.next=null是为了将老的头节点的后继清空，这样老的节点对象就没有任何依赖关系了，便于GC回收对象），而interrupted还是false，说明不被中断，在acquire()将不会执行到selfInterrupt，所以当前线程将继续执行。2.如果前驱节点不是头节点获取tryAcquire()获取锁失败，2.先通过shouldParkAfterFailedAcquire()检查是否需要阻塞获取锁失败的节点： 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; &emsp;&emsp;在shouldParkAfterFailedAcquire()中，检查前驱节点的状态（waitStatus），如果前驱节点为SIGNAL，返回true，即当前节点需要被阻塞（SIGNAL前文已说代表后继节点是被阻塞或将被阻塞的）；如果状态大于0，也就是状态是CANCELLED（只有CANCELLED是大于0的），则循环不断向前寻找节点，直到节点的waitStatus不大于0也就是不等于CANCELLED，找到节点后，设置为前驱节点，并与之构成双向队列，返回false，即当前节点不需要被阻塞；如果状态既不是SIGNAL，也不大于0，则通过CAS将前驱节点的waitStatus设置为SIGNAL，然后返回false，即当前节点不需要被阻塞。 &emsp;&emsp;再回到上面acquireQueued()中，如果shouldParkAfterFailedAcquire()返回true，则调用parkAndCheckInterrupt()让当前线程阻塞，再将interrupted设为true，但此时并没跳出for循环，将会继续获取前驱节点，然后判断是否是头节点以及尝试获取锁（需要注意的是，这时的前驱节点和上一次循环时的前驱节点可能会不一样，因为在shouldParkAfterFailedAcquire()中有向前寻找节点并重新构成双向队列的操作）。当发生异常，非正常退出时，调用cancelAcquire()将当前节点状态设置为CANCELLED，即所在线程已取消，不需要唤醒了。 以上是独占模式下获取锁，那么释放锁是如何做的呢。通过调用release()方法开始释放锁： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; &emsp;&emsp;这里先调用tryRelease()方法尝试释放锁，该方法由子类去实现，表示当前持有锁的线程动作执行完了，需要释放锁，将锁让给其他线程。tryRelease()成功之后，获取头节点，如果头节点不为空，并且头节点的状态不为0，说明队列中可能存在需要唤醒的等待节点 注一：为什么不为0就说明队列存在需要唤醒的等待节点呢，我的理解是，一方面，首先头节点如果存在就不会是CANCELLED，而CONDITION仅在条件队列中，这里是同步队列，PROPAGATE又仅在doReleaseShared()中设置，如果head头节点的状态不为初始化的0，那么就只能为SIGNAL。另一方面，在往队列插入节点到队尾成功后，前文在acquireQueued()中，可以看到，如果tryAcquire()获取锁失败，在shouldParkAfterFailedAcquire()会将前驱节点的状态通过CAS更新为SIGNAL，然后再调用parkAndCheckInterrupt()让当前线程节点阻塞。而SIGNAL就指明当前节点的后继节点是被阻塞的，所以即存在需要唤醒的节点 注二：回头看整个获取锁的过程，其实也就是节点入队列的过程，头节点在刚初始化是无任何状态的Node对象，但第一个线程节点入队列获取到锁之后，头节点就变成第一个线程节点，此后，头节点就是当前获取锁正在执行的节点。 （接注一注二之前内容），则调用unparkSuccessor()唤醒下一个被阻塞的线程节点： 1234567891011121314private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; &emsp;&emsp;可以看到，获取当前节点的状态，如果小于0（其实就是SIGNAL），通过CAS更新为0，然后获取后继节点s，如果后继节点为空的话，就从tail尾节点往前遍历，如果节点的状态小于等于0，就将这个节点指给s，如果s不为空，就通过LockSupport.unpark()唤醒后继节点s的线程。 上面是关于独占锁的获取与释放，那么对于共享锁呢，共享模式下，多个线程获取锁都可能会成功。 共享模式（共享锁）与独享锁类似，共享模式下，通过acquireShared()和acquireSharedInterruptibly()方法获取锁。这两个方法都是以共享模式获取锁： 1234567891011public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 通过对比可以发现，前者会忽略中断，后者首先检查中断状态，被中断则抛出异常中止。 &emsp;&emsp;先看下acquireShared()，先调用子类重写实现的tryAcquireShared()方法尝试获取共享锁，在独享模式时，tryAcquire()返回的就是true或false，而这里返回的是int数，如果获取失败，则返回负数，如果在共享模式下获取锁成功，但没有后续的共享模式获取可以成功（可以理解为锁的获取名额用完了），则返回0，如果共享模式下获取锁成功，并且后续的共享模式下获取锁也可能可以成功（即获取锁的名额还有），则返回正数。所以如果tryAcquireShared()返回小于0，即获取锁失败，那么调用doAcquireShared()： 123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; &emsp;&emsp;这里和独占模式有些类似，独占模式是addWaiter(Node.EXCLUSIVE)，共享模式下是addWaiter(Node.SHARED)，从前文已知，addWaiter()是将当前线程构建成节点，并插入到队列中，这里同理。然后进入到for循环里。先获取当前线程节点的前驱节点，如果前驱节点就是头节点的话，调用tryAcquireShared()尝试获取锁（这里和独占模式是类似的，只有前驱节点是head头节点才能尝试获取锁），如果返回大于等于0，说明获取共享锁成功，接着调用setHeadAndPropagate()： 12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; &emsp;&emsp;与独占锁有些类似，获取锁成功后，调用setHeadAndPropagate()也将当前节点设置为头节点，但不同于独占锁的是，不仅仅将当前节点设置为头节点，还根据tryAcquireShared()返回的值判断，如果大于0，获取当前节点的后继节点，如果后继节点也是shared共享模式节点，则通过调用doReleaseShared()方法向后传播，唤醒后面等待的节点（在后面释放锁的时候具体来看该方法）。 &emsp;&emsp;再回到doAcquireShared()，剩下的和独占模式几乎一样，如果当前节点前驱节点不是头节点，也是调用shouldParkAfterFailedAcquire()，parkAndCheckInterrupt()。 &emsp;&emsp;那么doAcquireSharedInterruptibly()呢，该方法与doAcquireShared()几乎一样，只是在if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())里抛出了异常:throw new InterruptedException();。 再看下共享模式下锁的释放： &emsp;&emsp;AQS提供了releaseShared()方法来在共享模式下释放锁： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; &emsp;&emsp;同独占模式类似，先调用由子类重写实现的tryReleaseShared()尝试释放，如果成功，则调用doReleaseShared()： 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; &emsp;&emsp;在前文中，获取到锁之后setHeadAndPropagate()方法中也调用来该方法，这里详细看下doReleaseShared()的实现。也是一个for循环，获取到头节点赋值给节点h，如果头节点的状态为SIGNAL，且能通过CAS将头节点的状态设置为0，则调用unparkSuccessor()唤醒头节点的后继节点，如果不能通过CAS将头节点状态设置0，则进行下一轮循环重试；如果头节点状态为0，就调用CAS将状态设置为PROPAGATE（开头时候已知道，设置为PROPAGATE即以确保可以向后传播），如果设置失败，就进行下一轮循环重试；如果h等于头节点，即头节点未发生变化，则跳出循环。 &emsp;&emsp;前文说到，在AQS中除了Node类，还有个ConditionObject类，本文先学习到这里，下一篇文章继续学习ConditionObject，学习AQS如何利用ConditionObject来实现等待通知，以及AQS中的其他方法与细节的补充。]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码学习：mapper关于事务的补充]]></title>
    <url>%2Fmybatis-mapper-transaction.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近在整理某个系统需要优化的点的时候，发现在查询时速度很慢，经过排查代码，发现同事在某个service出现了循环调用另一个service的方法，而另一份servcei是查询数据库的，而这些service都没使用@@Transactional事务，同时，根据debug打印的sql查询语句，发现单条sql语句查询都很快，初步怀疑是频繁创建会话，重复打开关闭连接消耗了大量时间，于是重写了这个service的方法，直接使用相应的mapper，然后使用@@Transactional声明为一个事务，这样所有的sql都在一个会话中了，只打开关闭了一次连接，响应的速度极大的提高了。 &emsp;&emsp;那么，在之前的mapper注册注入的文章中，学习到通过注入mapper的方式时，每次调用方法都是创建一个sqlsession。而使用@@Transactional事务注解后，service方法中所有mapper的调用都是一个会话了，在service方法结束之后统一对会话进行提交，那么这又是怎么实现的呢。 &emsp;&emsp;通过之前的学习，已知道注入后，本质上是SqlSessionTemplate通过内部代理类SqlSessionInterceptor对象sqlSessionProxy，再看一遍SqlSessionInterceptor的invoke()方法： 1234567891011121314151617181920212223242526272829@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; Object result = method.invoke(sqlSession, args); if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125; &emsp;&emsp;先getSqlSession()： 1234567891011public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; LOGGER.debug(() -&gt; "Creating a new SqlSession"); session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session; &#125; &emsp;&emsp;从getSqlSession()这个方法中可以看到，先通过TransactionSynchronizationManager.getResource(sessionFactory)获取SqlSessionHolder，从TransactionSynchronizationManager类的名字似乎是关于事务的，进入getResource这个方法： 123456789101112131415161718192021222324 private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;("Transactional resources"); @Nullablepublic static Object getResource(Object key) &#123; Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key); Object value = doGetResource(actualKey); // 日志打印 return value;&#125;private static Object doGetResource(Object actualKey) &#123; Map&lt;Object, Object&gt; map = resources.get(); if (map == null) &#123; return null; &#125; Object value = map.get(actualKey); if (value instanceof ResourceHolder &amp;&amp; ((ResourceHolder) value).isVoid()) &#123; map.remove(actualKey); if (map.isEmpty()) &#123; resources.remove(); &#125; value = null; &#125; return value;&#125; &emsp;&emsp;可以看到，该类的resources属性是一个ThreadLocal对象，泛型是Map&lt;Object, Object&gt;，也就是说保存和当前线程绑定的一个map，然后根据key获取map中保存的对象 service层方法中mapper的调用都是在一个线程中进行的 &emsp;&emsp;而SqlSessionUtils#getSqlSession()根据sessionFactory获取了一个SqlSessionHolder对象，反推之，说明在某个过程中，曾经放入了一个SqlSessionHolder对象，其实在这个方法后面有句registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session);这就是放入的操作，这个操作是在获取不到SqlSessionHolder，也就获取不到session之后，创建一个新的sqlSession，然后构造一个SqlSessionHolder对象，注册到TransactionSynchronizationManager的resourcesmap中，具体看下registerSessionHolder()这个方法： 123456789101112131415161718192021222324private static void registerSessionHolder(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator, SqlSession session) &#123; SqlSessionHolder holder; if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; Environment environment = sessionFactory.getConfiguration().getEnvironment(); if (environment.getTransactionFactory() instanceof SpringManagedTransactionFactory) &#123; LOGGER.debug(() -&gt; "Registering transaction synchronization for SqlSession [" + session + "]"); holder = new SqlSessionHolder(session, executorType, exceptionTranslator); TransactionSynchronizationManager.bindResource(sessionFactory, holder); TransactionSynchronizationManager.registerSynchronization(new SqlSessionSynchronization(holder, sessionFactory)); holder.setSynchronizedWithTransaction(true); holder.requested(); &#125; else &#123; if (TransactionSynchronizationManager.getResource(environment.getDataSource()) == null) &#123; LOGGER.debug(() -&gt; "SqlSession [" + session + "] was not registered for synchronization because DataSource is not transactional"); &#125; else &#123; throw new TransientDataAccessResourceException( "SqlSessionFactory must be using a SpringManagedTransactionFactory in order to use Spring transaction synchronization"); &#125; &#125; &#125; else &#123; LOGGER.debug(() -&gt; "SqlSession [" + session + "] was not registered for synchronization because synchronization is not active"); &#125; &#125; &emsp;&emsp;通过TransactionSynchronizationManager.isSynchronizationActive()判断有事务之后（每当开启一个事务，就会调用TransactionSynchronizationManager#initSynchronization()对synchronizations初始化），并且判断环境中有spring管理的TransactionFactorybean之后，构造SqlSessionHolder对象与sessionFactory绑定，注册到TransactionSynchronizationManager的resourcesmap中。注意，这里有个操作TransactionSynchronizationManager.registerSynchronization(new SqlSessionSynchronization(holder, sessionFactory));，将在后面说到，在service层方法执行完，统一提交事务时会涉及到。 &emsp;&emsp;结合上述，回到SqlSessionInterceptor#invoke()，可以知道，会尝试从TransactionSynchronizationManager的resources获取当前线程当前sessionFactory对应的SqlSessionHolder，如果之前放入过，则直接取出SqlSessionHolder中持有的sqlSession，如果没，则创建sqlSession返回，再根据是否有声明事务，构造SqlSessionHolder持有sqlSession，再注册进TransactionSynchronizationManager的resources，返回sqlSession。 &emsp;&emsp;拿到sqlSession后，通过method.invoke(sqlSession, args)直接调用SqlSession的数据操作，获取结果。然后通过isSqlSessionTransactional()判断是否具有事务（尝试从TransactionSynchronizationManager的resources中获取当前线程对应的SqlSessionHolder，如果为空，或者持有的sqlSession不等于当前的sqlSession，说明不具有事务），如果无事务，那么就sqlSession.commit(true)立即提交当前会话。在返回结果之前，会执行closeSqlSession()（ 即同上再次尝试从resources获取SqlSessionHolder，如果不具有事务，则关闭会话）。 sqlSession.commit()包含了提交事务的作用，但在与spring的事务整合时发现，一些属性会影响使其执行不到其中transaction.commit()，然后靠后续通过Connection调用NaticeSession发送commit指令给mysql来提交 &emsp;&emsp;从以上了解到了没有事务情况下，每次mapper调用都会创建新的会话，并且会话会在执行完后立即提交，而有事务时，共用一个会话，执行完数据操作后并不会提交会话，通过debug日志知道，在service方法执行完后，统一提交了事务，那么是如何统一提交事务呢，以及为什么未使用事务mapper执行完就提交会话了呢。 &emsp;&emsp;service的方法在被执行调用时，实际上是被代理类CglibAopProxy动态代理，并进入到通用回调DynamicAdvisedInterceptor中，看一下这个回调中的intercept(): 1234567891011121314151617181920212223242526272829303132public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; &emsp;&emsp;这里是一个关键点，对于有事务和无事务的分岔点就在这里，检查该方法（切点）的InvokerInterceptor数量，如果为空，那么就跳过创建MethodInvocation，而直接调用代理目标也就是service方法，如果不为空，则创建一个CglibMethodInvocation并执行。而如果方法有@Transactional注解修饰，该方法（切点）会拥有一个TransactionInterceptor，所以就不直接调用service方法，而是创建CglibMethodInvocation调用。 无事务的情况&emsp;&emsp;无事务时，直接调用代理目标也就是service方法，service调用mapper的方法，而调用mapper的方法，从前面的学习已经知道实质上调用SimpleExecutor的doUpdate()或doQuery()，而这两个方法实际上是调用StatementHandler的update和query，而再往后则是调用PreparedStatement的execute()，最终调用mysql的jdbc驱动包中原始会话NaticeSession的execSQL()，第一次先建立连接，第二次发送SET autocommit=1，告诉mysql后续的操作都是自动提交，所以后续直接执行sql获取结果 有事务的情况&emsp;&emsp;就如上面所说，创建CglibMethodInvocation，然后反射调用TransactionInterceptor，TransactionInterceptor继承自TransactionAspectSupport，TransactionInterceptor的invoke()调用TransactionAspectSupport的invokeWithinTransaction()： 12345678910111213141516171819202122232425262728293031protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal; try &#123; retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; // CallbackPreferringPlatformTransactionManager情况下的处理 &#125; &#125; &emsp;&emsp;可以观察到，这是一个环绕切面，先通过retVal = invocation.proceedWithInvocation()调用代理目标，也就是调用service方法执行切点，然后后置地调用commitTransactionAfterReturning(txInfo)，这里是在切点执行之后，用于提交事务的。在调用service方法时，调用mapper的方法，在最终调用mysql驱动包时，建立连接后，给mysql发送了SET autocommit=0，即意味着后续的sql执行都先不提交，而在commitTransactionAfterReturning()： 123456protected void commitTransactionAfterReturning(@Nullable TransactionInfo txInfo) &#123; if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) &#123; // 日志打印省略 txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125; &#125; &emsp;&emsp;这里获取到的TransactionManager是DataSourceTransactionManager，DataSourceTransactionManager继承AbstractPlatformTransactionManager，commit方法中再次调用processCommit()，processCommit()调用doCommit()，在doCommit()中获取连接Connection，调用Connection#commit()，最终也是调用NativeSession#execSQL()，只不过给mysql发送的是commit，即提交之前发送的所有sql。 在processCommit()中调用doCommit()之前，有一步调用triggerBeforeCommit(status)，而在这个方法中调用TransactionSynchronizationUtils.triggerBeforeCommit(status.isReadOnly())，而在前文中，提到过，在创建sqlSession时，会构造SqlSessionHolder，然后注册到TransactionSynchronizationManager，同时TransactionSynchronizationManager.registerSynchronization(new SqlSessionSynchronization(holder, sessionFactory));创建了SqlSessionSynchronization对象注册。而TransactionSynchronizationUtils.triggerBeforeCommit(status.isReadOnly())中即对TransactionSynchronizationManager中所有的TransactionSynchronization对象遍历，执行它们的beforeCommit()，而SqlSessionSynchronization的beforeCommit()中，获取持有sqlSessionHolder进而获取SqlSession，然后调用commit()。 学习到这里，对mybatis的会话关于事务方面做了些补充，但学习的越多，疑惑也就越多（坑也就越多…），比如关于Spring如何管理事务的，将带着这些疑问进行后续的学习，做好学习笔记。]]></content>
      <categories>
        <category>后端</category>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：整合Actuator实现动态修改日志级别]]></title>
    <url>%2Fspring-boot-actuator-update-log-level.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;由于线上服务器是没有权限进行操作的，所以只能靠打印日志来追踪问题，但如果所有日志都使用info级别也不行，这样日志文件就会太大了，占硬盘空间。对于有的日志要使用debug级别，而如果修改配置文件，项目还得重启才能生效，所以就想到要动态修改日志级别。 引入actuator依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.properties文件中加入： 1management.security.enabled=false 关闭安全认证。 通过GET请求访问/loggers接口，获取到所有的日志级别，类似如下： 123456789101112131415161718192021&#123; "levels": [ "OFF", "ERROR", "WARN", "INFO", "DEBUG", "TRACE" ], "loggers": &#123; "ROOT": &#123; "configuredLevel": "INFO", "effectiveLevel": "INFO" &#125;, "com": &#123; "configuredLevel": null, "effectiveLevel": "INFO" &#125;, // 省略n行 &#125;&#125; loggers中的每个key即为ROOT和各个包路径对应的日志级别。 通过POST请求访问/loggers/{key}接口，key即为上面获取到的结果中loggers的key，也就是ROOT和各个包路径，请求体如下： 123&#123; "configuredLevel": "DEBUG"&#125; 这样，就将key对应的日志级别设置成了debug。 注意，系统重启后，修改的将会恢复。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码学习：二级缓存]]></title>
    <url>%2Fmybatis-second-cache.html</url>
    <content type="text"><![CDATA[上一篇文章说到了mybatis的一级缓存，这篇继续学习mybatis的二级缓存。 二级缓存不同于一级缓存只作用于同一会话中，而是全局的，或者说，对于不同的会话sqlsession，只要是同一个mappedstatement（即相同的mapper同一个方法），就会生效（前提是sqlsession提交之后）。 打开二级缓存，除了默认打开的mybatis.configuration.cache-enabled属性之外，还需要在需要的mapper接口上使用@CacheNamespace注解（等价于xml配置时在mapper xml文件里加上&lt;cache/&gt;标签）。 示例实践例如以下： 1234567@Mapper@CacheNamespacepublic interface FoodMapper &#123; @Select("select * from food where id=#&#123;id&#125;") Food getById(@Param("id") Long id);&#125; 然后在controller中调用（这里还是和上一篇一级缓存一样用的是通过sessionFactory创建会话，其实也可以直接注入foodMapper调用）： 123456789101112@GetMapping("/mybatis/test4") public void test4() &#123; SqlSession session = sqlSessionFactory.openSession(); SqlSession session2 = sqlSessionFactory.openSession(); Food food = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); session.commit(); log.info(JSON.toJSONString(food)); Food food2 = (Food) session2.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food2)); &#125; 以上的demo开启了两个会话，共执行了两次查询操作，但只打印了一次sql查询语句，但如果把session.commit()删除，那么将会打印两次sql查询语句，这也是前面说的二级缓存在会话提交之后生效。 源码学习那么还是通过从源码学习下二级缓存的原理，同样的，先从DefaultSqlSession#selectOne()入手，上一篇文章已经知道，DefaultSqlSession实际上先调用的是CachingExecutor的query()： 12345678910111213141516171819@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); if (cache != null) &#123; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); @SuppressWarnings("unchecked") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; 在上述源码中，Cache cache = ms.getCache()即为获取二级缓存。 那么在mappedStatement中的cache是何时初始化设置与MappedStatement绑定的呢 还是得从mapper bean的创建与注入说起，上一篇文章我知道了mapper的bean通过MapperFactoryBean创建，而在MapperFactoryBean初始化的时候调用Configuration#addMapper，而Configuration#addMapper调用MapperRegistry#addMapper()，在这里将mapper包装成了MapperProxyFactory放入缓存中，着重看下这个方法： 123456789101112131415161718192021public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; if (hasMapper(type)) &#123; throw new BindingException("Type " + type + " is already known to the MapperRegistry."); &#125; boolean loadCompleted = false; try &#123; knownMappers.put(type, new MapperProxyFactory&lt;&gt;(type)); // It's important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won't try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125; &#125; 上一篇文章就说到，MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse();是将mapper中的方法解析成对于的MappedStatement对象。在MapperAnnotationBuilder的构造方法中，对assistant属性进行了初始化（assistant是MapperBuilderAssistant对象，后面会通过这个助手类创建cache），再看下parse()这个方法： 12345678910111213141516171819202122public void parse() &#123; String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) &#123; loadXmlResource(); configuration.addLoadedResource(resource); assistant.setCurrentNamespace(type.getName()); parseCache(); parseCacheRef(); Method[] methods = type.getMethods(); for (Method method : methods) &#123; try &#123; // issue #237 if (!method.isBridge()) &#123; parseStatement(method); &#125; &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteMethod(new MethodResolver(this, method)); &#125; &#125; &#125; parsePendingMethods(); &#125; 其中，对assistant助手类设置了命名空间（这个namespace后面将用于作为cache的ID），parseCache()就是判断mapper接口是否有@CacheNamespace注解修饰，如果有，则接入二级缓存： 123456789private void parseCache() &#123; CacheNamespace cacheDomain = type.getAnnotation(CacheNamespace.class); if (cacheDomain != null) &#123; Integer size = cacheDomain.size() == 0 ? null : cacheDomain.size(); Long flushInterval = cacheDomain.flushInterval() == 0 ? null : cacheDomain.flushInterval(); Properties props = convertToProperties(cacheDomain.properties()); assistant.useNewCache(cacheDomain.implementation(), cacheDomain.eviction(), flushInterval, size, cacheDomain.readWrite(), cacheDomain.blocking(), props); &#125; &#125; 通过assistant助手类对象，创建一个新的cache对象： 1234567891011121314151617181920public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass, Class&lt;? extends Cache&gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) &#123; Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); configuration.addCache(cache); currentCache = cache; return cache; &#125; 前面说到，namespace作为cache的ID，这在CacheBuilder的构造方法中进行了设置： 1234public CacheBuilder(String id) &#123; this.id = id; this.decorators = new ArrayList&lt;&gt;(); &#125; 通过CacheBuilder对象，进行一系列属性配置，最后通过build()方法创建Cache对象，将属性装配到Cache对象中，再返回： 123456789101112131415public Cache build() &#123; setDefaultImplementations(); Cache cache = newBaseCacheInstance(implementation, id); setCacheProperties(cache); if (PerpetualCache.class.equals(cache.getClass())) &#123; for (Class&lt;? extends Cache&gt; decorator : decorators) &#123; cache = newCacheDecoratorInstance(decorator, cache); setCacheProperties(cache); &#125; cache = setStandardDecorators(cache); &#125; else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) &#123; cache = new LoggingCache(cache); &#125; return cache; &#125; 再回到MapperBuilderAssistant#useNewCache()，创建完cache对象之后，通过configuration.addCache(cache)将cache对象存到Configuration的caches这样一个map中，并在当前的MapperBuilderAssistant对象assistant的currentCache属性保存一份（在后面会用到）。 cache对象已经创建好了，那么是怎么装配到mapper接口中方法对应的MappedStatement对象中的呢，接着看MapperAnnotationBuilder#parse()方法，在parseCache()之后，foreach遍历所有的方法，然后通过parseStatement()解析生成MappedStatement对象： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980void parseStatement(Method method) &#123; Class&lt;?&gt; parameterTypeClass = getParameterType(method); LanguageDriver languageDriver = getLanguageDriver(method); SqlSource sqlSource = getSqlSourceFromAnnotations(method, parameterTypeClass, languageDriver); if (sqlSource != null) &#123; Options options = method.getAnnotation(Options.class); final String mappedStatementId = type.getName() + "." + method.getName(); Integer fetchSize = null; Integer timeout = null; StatementType statementType = StatementType.PREPARED; ResultSetType resultSetType = null; SqlCommandType sqlCommandType = getSqlCommandType(method); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = !isSelect; boolean useCache = isSelect; KeyGenerator keyGenerator; String keyProperty = null; String keyColumn = null; if (SqlCommandType.INSERT.equals(sqlCommandType) || SqlCommandType.UPDATE.equals(sqlCommandType)) &#123; // first check for SelectKey annotation - that overrides everything else SelectKey selectKey = method.getAnnotation(SelectKey.class); if (selectKey != null) &#123; keyGenerator = handleSelectKeyAnnotation(selectKey, mappedStatementId, getParameterType(method), languageDriver); keyProperty = selectKey.keyProperty(); &#125; else if (options == null) &#123; keyGenerator = configuration.isUseGeneratedKeys() ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; &#125; else &#123; keyGenerator = options.useGeneratedKeys() ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; keyProperty = options.keyProperty(); keyColumn = options.keyColumn(); &#125; &#125; else &#123; keyGenerator = NoKeyGenerator.INSTANCE; &#125; if (options != null) &#123; if (FlushCachePolicy.TRUE.equals(options.flushCache())) &#123; flushCache = true; &#125; else if (FlushCachePolicy.FALSE.equals(options.flushCache())) &#123; flushCache = false; &#125; useCache = options.useCache(); fetchSize = options.fetchSize() &gt; -1 || options.fetchSize() == Integer.MIN_VALUE ? options.fetchSize() : null; //issue #348 timeout = options.timeout() &gt; -1 ? options.timeout() : null; statementType = options.statementType(); resultSetType = options.resultSetType(); &#125; String resultMapId = null; ResultMap resultMapAnnotation = method.getAnnotation(ResultMap.class); if (resultMapAnnotation != null) &#123; resultMapId = String.join(",", resultMapAnnotation.value()); &#125; else if (isSelect) &#123; resultMapId = parseResultMap(method); &#125; assistant.addMappedStatement( mappedStatementId, sqlSource, statementType, sqlCommandType, fetchSize, timeout, // ParameterMapID null, parameterTypeClass, resultMapId, getReturnType(method), resultSetType, flushCache, useCache, // TODO gcode issue #577 false, keyGenerator, keyProperty, keyColumn, // DatabaseID null, languageDriver, // ResultSets options != null ? nullOrEmpty(options.resultSets()) : null); &#125; &#125; 该方法中，先根据方法的注解和方法传参获取sql资源，即判断是否有@Insert、@Update、Select、@Delete注解，如果有这些注解，获取注解中的sql语句，根据注解中的sql语句和传参创建SqlSource对象。 如果SqlSource对象不为空 再获取方法上@Options注解（@Options注解可以配置是否使用缓存、是否主键自增、主键的列名等属性） 再根据sql类型创建不同的主键生成器KeyGenerator 如果是Insert和Update类型，再获取方法上的@Selectkey注解 如果@SelectKey注解存在，根据selectKey注解也创建一个MapperStatement对象，它的id是原方法对应的MapperStatement对象ID再加上!selectKey后缀（原MapperStatement对象ID为类全限定名加上.加上方法名），调用助手类assistant.addMappedStatement创建（暂放在后面说），并创建SelectKeyGenerator放入Configuration的keyGenerators中 如果@SelectKey注解不存在，则按照@Options注解配置的或者Configuration中配置的 如果是非Insert和Update，使用NoKeyGenerator 如果@Options注解存在，获取该注解的属性，覆盖默认配置 调用当前助手类MapperBuilderAssistant对象assistant的addMappedStatement()方法 着重看一下MapperBuilderAssistant#addMappedStatement()，该方法主要用于创建MappedStatement，并通过cache(currentCache)，将上面步骤中MapperBuilderAssistant#useNewCache()创建并放入当前MapperBuilderAssistant对象的cache，与创建的MappedStatement绑定，再将MappedStatement对象放入到Configuration的mappedStatements中保存。 至此，关于MappedStatement中cache的来源以及cache如何和MappedStatement绑定的，就已经明了了。 回到文章前面，看到的CachingExecutor的query()的地方，通过Cache cache = ms.getCache()获取缓存对象cache 如果cache存在，并且isUseCache，则按照二级缓存情况处理。 先通过TransactionalCacheManager对象tcm.getObject(cache, key)方法根据cache获取对应的TransactionalCache进而再根据key去TransactionalCache中的Cache对象获取缓存，这里key是CacheKey对象，是根据当前方法对应的MappedStatement对象和方法传参以及sql等构建的一个对象，可用来唯一确定查询。 如果通过tcm.getObject(cache, key)获取的缓存为空，则调用BaseExecutor#query()获取查询结果，再将查询结果通过tcm.putObject(cache, key, list);放入二级缓存 结果返回 如果cache不存在，则如同上篇一级缓存的文章说的，调用BaseExecutor的query()查询，返回结果 &emsp;&emsp;TransactionalCacheManager是一个TransactionalCache的管理类，内部维护了一个Cache:TransactionalCache的键值对的map。而TransactionalCache是对Cache对象包装了一层，这个Cache对象就是MappedStatement中的cache，所以当TransactionalCacheManager.getObject()时，本质上还是从Cache中获取，那还包装一层TransactionalCache是不是有些多余呢，并不是，而是为了put操作，这也是接下来解释前文说的，为什么缓存在sqlSession会话提交之后才生效。 看一下TransactionalCache#putObject()和#getObject()： 12345678910111213141516@Overridepublic Object getObject(Object key) &#123; Object object = delegate.getObject(key); if (object == null) &#123; entriesMissedInCache.add(key); &#125; if (clearOnCommit) &#123; return null; &#125; else &#123; return object; &#125;&#125;@Overridepublic void putObject(Object key, Object object) &#123; entriesToAddOnCommit.put(key, object);&#125; 可以看到，我在读缓存时，是从delegate（Cache对象）中获取key对应的值，而写入时，是往entriesToAddOnCommit中put。entriesToAddOnCommit是什么呢，是一个HashMap，可以理解为是一个待提交保存的集合，由此可见，在写缓存时并没有直接写入Cache。那么再看TransactionalCache#commit()： 12345678910111213141516171819202122public void commit() &#123; if (clearOnCommit) &#123; delegate.clear(); &#125; flushPendingEntries(); reset();&#125;private void reset() &#123; clearOnCommit = false; entriesToAddOnCommit.clear(); entriesMissedInCache.clear();&#125;private void flushPendingEntries() &#123; for (Map.Entry&lt;Object, Object&gt; entry : entriesToAddOnCommit.entrySet()) &#123; delegate.putObject(entry.getKey(), entry.getValue()); &#125; for (Object entry : entriesMissedInCache) &#123; if (!entriesToAddOnCommit.containsKey(entry)) &#123; delegate.putObject(entry, null); &#125; &#125;&#125; 可以看到，当进行会话提交时，会将待提交集合entriesToAddOnCommit中的数据迁移至Cache对象中，然后再将entriesToAddOnCommit清空。 至此，二级缓存的实现就已经了解了，结合上一篇一级缓存的学习，可以发现，使用二级缓存之后，查询数据，先尝试从二级缓存中拿数据，没有则去一级缓存中拿，一级缓存中再没有，才去查询数据库。 补充：对前文创建Cache做一些补充，其实返回Cache对象是被包装了很层的Cache对象，以@CacheNamespace的默认配置来看，在创建对象时，这层层包装的最底层是PerpetualCache，然后被LruCache包装，LruCache再被ScheduledCache包装，ScheduledCache再被SerializedCache包装，SerializedCache再被LoggingCache包装，LoggingCache再被SynchronizedCache包装，默认最终返回的是SynchronizedCache对象。]]></content>
      <categories>
        <category>后端</category>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码学习：一级缓存]]></title>
    <url>%2Fmybatis-first-cache.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;Mybatis提供了两种缓存，一种是一级缓存，一种是二级缓存，今天先学习下一级缓存。 一级缓存的作用域是sqlsession会话级别，同一个会话中，相同的MapperStatement（调用相同mapper的相同方法，上一篇mapper注册注入的文章说到过，mapper的方法将会解析生成对应的MapperStatement），传相同的参数，那么将会从缓存中查询，不会再查询数据库。 下面通过几个例子验证： 首先定义了一个mapper（两个方法的sql是一样的，后面将会说到为什么这样）： 123456789@Mapperpublic interface FoodMapper &#123; @Select("select * from food where id=#&#123;id&#125;") Food getById(@Param("id") Long id); @Select("select * from food where id=#&#123;id&#125;") Food selectById(@Param("id") Long id);&#125; 然后调用mapper： 123456789101112131415161718192021222324252627282930313233343536@AutowiredSqlSessionFactory sqlSessionFactory;@GetMapping("/mybatis/test2")public void test2() &#123; SqlSession session = sqlSessionFactory.openSession(); Food food = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food)); Food food2 = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food2));&#125;@GetMapping("/mybatis/test3")public void test3() &#123; SqlSession session = sqlSessionFactory.openSession(); Food food = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food)); Food food2 = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.selectById", 1L); log.info(JSON.toJSONString(food2));&#125;@GetMapping("/mybatis/test4")public void test4() &#123; SqlSession session = sqlSessionFactory.openSession(); SqlSession session2 = sqlSessionFactory.openSession(); Food food = (Food) session.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food)); Food food2 = (Food) session2.selectOne( "site.wetsion.mybatislearning.mapper.FoodMapper.getById", 1L); log.info(JSON.toJSONString(food2));&#125; 可以看到，我使用sqlSessionFactory来手动调用openSession创建会话，为什么不直接注入foodMapper呢，其实上一篇mapper注册与注入的文章，我已经知道，其实使用mapper调用方法，实际上是通过MapperProxy代理对象创建MapperMethod对象并调用execute()方法，而execute()调用SqlSessionTemplate的对应方法，SqlSessionTemplate则创建代理会话sqlSessionProxy处理。所以我们每次使用foodMapper.getById都会创建一个会话，就不满足一级缓存的条件了。 在test2()中，我在一个会话中，两次调用了getById()方法，并都传入参数1，结果如下： 12345678910Cache Hit Ratio [site.wetsion.mybatislearning.mapper.FoodMapper]: 0.0JDBC Connection [HikariProxyConnection@173171954 wrapping com.mysql.cj.jdbc.ConnectionImpl@4959bc8] will not be managed by Spring==&gt; Preparing: select * from food where id=? ==&gt; Parameters: 1(Long)&lt;== Columns: id, name, color&lt;== Row: 1, aa, red&lt;== Total: 12019-06-27 22:52:54.135 INFO 30524 --- [nio-9066-exec-3] s.w.mybatislearning.web.FoodController : &#123;"color":"red","id":1,"name":"aa"&#125;Cache Hit Ratio [site.wetsion.mybatislearning.mapper.FoodMapper]: 0.02019-06-27 22:52:54.137 INFO 30524 --- [nio-9066-exec-3] s.w.mybatislearning.web.FoodController : &#123;"color":"red","id":1,"name":"aa"&#125; 可以看到，只打印了一条查询sql，只查询了一次，第二次从缓存中读取的 在test3()中，在同一个会话中，我分别调用getById和selectById，参数都为1，上面定义也知道，这两个方法执行的语句是一样的，运行结果如下： 123456789101112131415Cache Hit Ratio [site.wetsion.mybatislearning.mapper.FoodMapper]: 0.0JDBC Connection [HikariProxyConnection@377160664 wrapping com.mysql.cj.jdbc.ConnectionImpl@18bcff67] will not be managed by Spring==&gt; Preparing: select * from food where id=? ==&gt; Parameters: 1(Long)&lt;== Columns: id, name, color&lt;== Row: 1, aa, red&lt;== Total: 12019-06-27 22:56:38.756 INFO 30524 --- [nio-9066-exec-5] s.w.mybatislearning.web.FoodController : &#123;"color":"red","id":1,"name":"aa"&#125;Cache Hit Ratio [site.wetsion.mybatislearning.mapper.FoodMapper]: 0.0==&gt; Preparing: select * from food where id=? ==&gt; Parameters: 1(Long)&lt;== Columns: id, name, color&lt;== Row: 1, aa, red&lt;== Total: 12019-06-27 22:56:38.759 INFO 30524 --- [nio-9066-exec-5] s.w.mybatislearning.web.FoodController : &#123;"color":"red","id":1,"name":"aa"&#125; 可以看到，执行了两次sql查询语句，且都一样，说明不满足一级缓存的条件. 网上有的文章说，查询语句相同的sql会被缓存，这里验证了，查询语句相同并不是必要条件 在test4()中，我创建了两个会话，调用相同的方法，结果就不用贴出来了，依然是执行了两次sql查询，并没使用缓存。 上面的例子证明了一级缓存确实是在同一会话，相同的MapperStatement，相同的参数，则会使用缓存。那么原理是什么呢，还是探索分析以下源码。 从上面的selectOne()入手，我们看下DefaultSqlSession#selectOne()（上篇文章已知道mybatis实际默认使用就是DefaultSqlSession）: 12345678910public &lt;T&gt; T selectOne(String statement, Object parameter) &#123; List&lt;T&gt; list = this.selectList(statement, parameter); if (list.size() == 1) &#123; return list.get(0); &#125; else if (list.size() &gt; 1) &#123; throw new TooManyResultsException("Expected one result (or null) to be returned by selectOne(), but found: " + list.size()); &#125; else &#123; return null; &#125; &#125; 额。。继续看selectList()： 12345678910public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error querying database. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 根据mapper中方法的全限定名从Configuration中获取对应的MapperStatement对象，然后再调用executor的query()方法。 这个executor类型是Executor接口，那么实际是哪个实现类呢，executor属性是通过DefaultSqlSession构造方法设置的，而创建DefaultSqlSession是通过DefaultSqlSessionFactory#openSession()，再调用openSessionFromDataSource()： 123456789101112131415private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException("Error opening session. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 可以看到，executor来自Configuration类： 1234567891011121314151617public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor; &#125; 默认是SimpleExecutor，但由于默认cacheEnabled属性为true，所以通过装饰器模式对SimpleExecutor进行了包装，真正使用的是CacheExecutor。紧接上文，看一下CacheExecutor的query()： 123456@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject); CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; BundleSql呢，就是持有实际的sql字符串，以及一些参数，而CacheKey，顾名思义，就是缓存的键。即生成了sql和缓存键之后，调用query()，似乎要开始真正的查询操作： 12345678910111213141516171819@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); if (cache != null) &#123; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); @SuppressWarnings("unchecked") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; Cache cache = ms.getCache()这里是获取二级缓存，由于这里没设置二级缓存，暂不提，继续看，调用了delegate.query()，这里delegate就是上文说的默认的SimpleExecutor，而SimpleExecutor自身没有query()，继承了父类BaseExecutor的query()，所以一级缓存的核心就是BaseExecutor的query()： 12345678910111213141516171819202122232425262728293031323334@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if (closed) &#123; throw new ExecutorException("Executor was closed."); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list; &#125; 可以看到这样一行list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null;即从本地缓存localCache中获取，这个locaCache是BaseExecutor中的属性，PerpetualCache对象，就是一级缓存，内部实现其实就是一个hashMap，如果这个list结果为空，就会执行list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);： 1234567891011121314private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125; 这是真正的从数据库查询，查询后再往一级缓存localCache中放一份。 到这里，就已经知道一级缓存查询的原理了，那为什么当执行更新操作时，就会清除一级缓存呢，也顺带把这个也看一下。 同理，先看DefaultSqlSession的update方法： 123456789101112@Override public int update(String statement, Object parameter) &#123; try &#123; dirty = true; MappedStatement ms = configuration.getMappedStatement(statement); return executor.update(ms, wrapCollection(parameter)); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error updating database. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; 大同小异，从上面我们已经知道实际是CacheExecutor，所以看CacheExecutor的update： 12345@Override public int update(MappedStatement ms, Object parameterObject) throws SQLException &#123; flushCacheIfRequired(ms); return delegate.update(ms, parameterObject); &#125; 这里flushCacheIfRequired(ms)是和二级缓存相关，暂不看，从上面我们也知道，delegate是SimpleExecutor，但SimpleExecutor的方法都继承自BaseExecutor，所以直接看BaseExecutor的update： 12345678910111213141516@Override public int update(MappedStatement ms, Object parameter) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing an update").object(ms.getId()); if (closed) &#123; throw new ExecutorException("Executor was closed."); &#125; clearLocalCache(); return doUpdate(ms, parameter); &#125; @Override public void clearLocalCache() &#123; if (!closed) &#123; localCache.clear(); localOutputParameterCache.clear(); &#125; &#125; 从方法名我们也知道了，clearLocalCache()如果会话没被关闭，清空一级缓存，然后再执行数据库操作。 至此，一级缓存读写的原理在梳理源码的过程中已经很清晰了，之后再学习下二级缓存原理。]]></content>
      <categories>
        <category>后端</category>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码学习：mapper的注册与注入]]></title>
    <url>%2Fmybatis-mapper-register-autowire.html</url>
    <content type="text"><![CDATA[一直在使用mybatis，对它的源码断断续续地看过一点，知之甚少，所以打算把mybatis源码坚持看一遍，并记录成一系列学习笔记，以免后面忘了，可以看着再回忆回忆。 先从最常用的点入手，在使用的时候，通过都是定义一个mapper接口，例如这样： 12345public interface FoodMapper &#123; @Select("select * from food where id=#&#123;id&#125;") Food getById(@Param("id") Long id);&#125; 然后在启动类上加上mapper扫描路径： 123456789@SpringBootApplication@MapperScan(basePackages = "site.wetsion.mybatislearning.mapper")public class MybatisLearningApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MybatisLearningApplication.class, args); &#125;&#125; 最后再在用到的地方注入使用： 12345678910111213@RestController@Slf4jpublic class FoodController &#123; @Autowired FoodMapper foodMapper; @GetMapping("/mybatis/test1") public void test() &#123; Food food = foodMapper.getById(7L); log.info(JSON.toJSONString(food)); &#125;&#125; 这样一波操作看起来很简单，但都是mybatis和spring帮我做了很多事，所以先从这里入手，通过学习源码了解下是怎么样做到将mapper接口注册成bean，并再注入使用的。 首先，可以明确的一点是，是我通过使用@MapperScan注解告诉了spring，mapper接口的所在位置，所以先看该注解的源码（以下源码版本为jdk1.8，mybatis-spring-boot-starter 2.0.1）： 12345678910@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)@Repeatable(MapperScans.class)public @interface MapperScan &#123; // 省略注解的属性&#125; 这个注解通过Import引入了MapperScannerRegistrar，顾名思义，我先猜测它就是mapper的注册器，同时看到注解的注释有这样一句话：It performs when same work as {@link MapperScannerConfigurer} via {@link MapperScannerRegistrar}.，意思就是MapperScannerRegistrar和MapperScannerConfigurer做的是同样的工作，而MapperScannerConfigurer是干嘛的呢，使用xml配置时，通常这样指定mapper包路径，将mapper注册成bean： 1234&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="site.wetsion.mybatislearning.mapper" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /&gt; &lt;/bean&gt; 所以点开MapperScannerRegistrar，看它如何实现的： 12345678910public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AnnotationAttributes mapperScanAttrs = AnnotationAttributes .fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); if (mapperScanAttrs != null) &#123; registerBeanDefinitions(mapperScanAttrs, registry); &#125; &#125;&#125; 通过import引入MapperScannerRegistrar之后，执行完aware接口的操作之后，将会调用上述核心的registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)，可以看到，在该方法中，先获取@MapperScan注解的属性，不为空，将会调用私有的registerBeanDefinitions()方法，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647void registerBeanDefinitions(AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry) &#123; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); Optional.ofNullable(resourceLoader).ifPresent(scanner::setResourceLoader); Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass("annotationClass"); if (!Annotation.class.equals(annotationClass)) &#123; scanner.setAnnotationClass(annotationClass); &#125; Class&lt;?&gt; markerInterface = annoAttrs.getClass("markerInterface"); if (!Class.class.equals(markerInterface)) &#123; scanner.setMarkerInterface(markerInterface); &#125; Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass("nameGenerator"); if (!BeanNameGenerator.class.equals(generatorClass)) &#123; scanner.setBeanNameGenerator(BeanUtils.instantiateClass(generatorClass)); &#125; Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass("factoryBean"); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) &#123; scanner.setMapperFactoryBeanClass(mapperFactoryBeanClass); &#125; scanner.setSqlSessionTemplateBeanName(annoAttrs.getString("sqlSessionTemplateRef")); scanner.setSqlSessionFactoryBeanName(annoAttrs.getString("sqlSessionFactoryRef")); List&lt;String&gt; basePackages = new ArrayList&lt;&gt;(); basePackages.addAll( Arrays.stream(annoAttrs.getStringArray("value")) .filter(StringUtils::hasText) .collect(Collectors.toList())); basePackages.addAll( Arrays.stream(annoAttrs.getStringArray("basePackages")) .filter(StringUtils::hasText) .collect(Collectors.toList())); basePackages.addAll( Arrays.stream(annoAttrs.getClassArray("basePackageClasses")) .map(ClassUtils::getPackageName) .collect(Collectors.toList())); scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(basePackages)); &#125; 这里定义了ClassPathMapperScanner对象scanner，然后获取注解属性，并将属性设置到scanner中，最后调用doScan开始扫描指定的包路径： 123456789101112@Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &#123; LOGGER.warn(() -&gt; "No MyBatis mapper was found in '" + Arrays.toString(basePackages) + "' package. Please check your configuration."); &#125; else &#123; processBeanDefinitions(beanDefinitions); &#125; return beanDefinitions; &#125; 先调用父类也就是ClassPathBeanDefinitionScanner的doScan方法，将指定包下的mapper接口转换成一个个bean定义持有者（BeanDefinitionHolder，拥有名称别名和bean定义，用于后续bean注册），并调用BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, registry)注册bean定义，再将beanDefinitionHolder返回。如果不为空，将调用processBeanDefinitions对这些beanDefinitionHolder处理： 12345678910111213141516171819202122232425262728293031323334353637383940414243private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; "Creating MapperFactoryBean with name '" + holder.getBeanName() + "' and '" + beanClassName + "' mapperInterface"); // mapper接口是bean的原始类，但bean的实际类是MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 definition.setBeanClass(this.mapperFactoryBeanClass); definition.getPropertyValues().add("addToConfig", this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123; definition.getPropertyValues().add("sqlSessionFactory", new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionFactory != null) &#123; definition.getPropertyValues().add("sqlSessionFactory", this.sqlSessionFactory); explicitFactoryUsed = true; &#125; if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; "Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored."); &#125; definition.getPropertyValues().add("sqlSessionTemplate", new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionTemplate != null) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; "Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored."); &#125; definition.getPropertyValues().add("sqlSessionTemplate", this.sqlSessionTemplate); explicitFactoryUsed = true; &#125; if (!explicitFactoryUsed) &#123; LOGGER.debug(() -&gt; "Enabling autowire by type for MapperFactoryBean with name '" + holder.getBeanName() + "'."); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); &#125; &#125; &#125; 这里对beanDefinition进行一系列改造，包括将beanClass设置为MapperFactoryBean，此时，mapper接口是bean的原始类，但bean的实际类是MapperFactoryBean，这里将在后面注入mapper时体现。 这样，所有的mapper就注册进了Spring容器，上面说的是通过@MapperScan注解指定mapper的包路径的方式，通常我们也会使用另一种方式，即不在启动类使用@MapperScan注解，而是在每一个mapper接口上使用@Mapper注解来声明这是一个mapper，然而对于这种方式，是怎样注册成bean的呢。 可以在MybatisAutoConfiguration类中发现一个内部静态类AutoConfiguredMapperScannerRegistrar，这个类在另一个内部静态类，同时也声明为配置类的MapperScannerRegistrarNotFoundConfiguration引入： 12345678910@org.springframework.context.annotation.Configuration @Import(&#123; AutoConfiguredMapperScannerRegistrar.class &#125;) @ConditionalOnMissingBean(MapperFactoryBean.class) public static class MapperScannerRegistrarNotFoundConfiguration implements InitializingBean &#123; @Override public void afterPropertiesSet() &#123; logger.debug("No &#123;&#125; found.", MapperFactoryBean.class.getName()); &#125; &#125; 而AutoConfiguredMapperScannerRegistrar所做的和前文的MapperScannerRegistrar做的是类似的事： 12345678910111213141516171819202122232425262728public static class AutoConfiguredMapperScannerRegistrar implements BeanFactoryAware, ImportBeanDefinitionRegistrar, ResourceLoaderAware &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; if (!AutoConfigurationPackages.has(this.beanFactory)) &#123; logger.debug("Could not determine auto-configuration package, automatic mapper scanning disabled."); return; &#125; logger.debug("Searching for mappers annotated with @Mapper"); List&lt;String&gt; packages = AutoConfigurationPackages.get(this.beanFactory); if (logger.isDebugEnabled()) &#123; packages.forEach(pkg -&gt; logger.debug("Using auto-configuration base package '&#123;&#125;'", pkg)); &#125; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); if (this.resourceLoader != null) &#123; scanner.setResourceLoader(this.resourceLoader); &#125; scanner.setAnnotationClass(Mapper.class); scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(packages)); &#125; &#125; 即对根目录路径下所有类进行扫描，将有@Mapper注解修饰的接口注册成bean。 以上就是mapper接口注册到Spring容器的分析，下面再探索下当我们使用@Autowired尝试注入时，都做了什么事。 上文已经说了，在扫描注册beanDefinition之后，有一步将bean的class改成了MapperFactoryBean，而MapperFactoryBean实现了FactoryBean接口，实现此接口的bean不能用作普通的bean，它是对象的工厂，不能直接作为bean的实例，Spring在处理这类bean时，会调用getObject()获取bean对象。 同时MapperFactoryBean继承自SqlSessionDaoSupport，而SqlSessionDaoSupport继承DaoSupport， DaoSupport定义了初始化的方法，SqlSessionDaoSupport定义了设置数据访问的方式，如setSqlSessionTemplate、setSqlSessionFactory（这两个方法本质上都是为了给属性SqlSessionTemplate sqlSessionTemplate赋值），所以MapperFactoryBean在创建对象时需要设置这两个值其中一个，如果都设置了，setSqlSessionFactory中逻辑将会被覆盖。 DaoSupport实现了InitializingBean接口，所以在Spring容器通过反射创建MapperFactoryBean实例后，将会调用afterPropertiesSet()： 12345678910@Override public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException &#123; checkDaoConfig(); try &#123; initDao(); &#125; catch (Exception ex) &#123; throw new BeanInitializationException("Initialization of DAO failed", ex); &#125; &#125; 随即调用本类的checkDaoConfig(): 12345678910111213141516@Override protected void checkDaoConfig() &#123; super.checkDaoConfig(); notNull(this.mapperInterface, "Property 'mapperInterface' is required"); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123; try &#123; configuration.addMapper(this.mapperInterface); &#125; catch (Exception e) &#123; logger.error("Error while adding the mapper '" + this.mapperInterface + "' to configuration.", e); throw new IllegalArgumentException(e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; 通过调用Configuration的addMapper调用MapperRegistry.addMapper()，将当前bean的原始类（该mapper接口）包装成MapperProxyFactory对象保存至map缓存起来，如下所示： 123456789101112131415161718192021public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; if (hasMapper(type)) &#123; throw new BindingException("Type " + type + " is already known to the MapperRegistry."); &#125; boolean loadCompleted = false; try &#123; knownMappers.put(type, new MapperProxyFactory&lt;&gt;(type)); // It's important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won't try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125; &#125; 上面还有一个地方比较重要：MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type);parser.parse(); 我再看下parse()这个方法： 12345678910111213141516171819202122public void parse() &#123; String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) &#123; loadXmlResource(); configuration.addLoadedResource(resource); assistant.setCurrentNamespace(type.getName()); parseCache(); parseCacheRef(); Method[] methods = type.getMethods(); for (Method method : methods) &#123; try &#123; // issue #237 if (!method.isBridge()) &#123; parseStatement(method); &#125; &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteMethod(new MethodResolver(this, method)); &#125; &#125; &#125; parsePendingMethods(); &#125; 这里主要是遍历mapper中的方法，将方法解析生成对应的MapperStatement对象，并保存在Configuration的Map&lt;String, MappedStatement&gt; mappedStatements中，具体实现见MapperBuilderAssistant#addMappedStatement()暂且不表。 衔接上文说的，MapperFactoryBean实例创建之后，在注入时，通过调用getObject()方法获取bean对象： 1234@Override public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125; 这里getSqlSession获取的是SqlSessionTemplate，即SqlSessionTemplate#getMapper()： 1234@Override public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return getConfiguration().getMapper(type, this); &#125; 其实就是把上面说的放入MapperRegistry的map缓存中的MapperProxyFactory对象取出来，再创建一个当前mapper接口的代理类对象(MapperProxy)，最后Spring将这个代理类对象注入到引用的地方： 123456789101112131415161718192021// MapperRegistry.javapublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException("Type " + type + " is not known to the MapperRegistry."); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException("Error getting mapper instance. Cause: " + e, e); &#125; &#125;// MapperProxyFactory.javaprotected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125; 由于实际注入的是MapperProxy对象，所以当我foodMapper.getById(1)这样调用时，实际上调用的是MapperProxy#invoke()： 12345678910111213public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125; 将mapper的方法封装成MapperMethod对象，调用MapperMethod的execute方法，而在execute本质上是根据操作类型（insert、update、delete、select等）调用SqlSessionTemplate的对应方法，而SqlSessionTemplate通过内部的代理会话sqlSessionProxy进行数据库操作，获取结果。 到这里，就看完了mapper注册与注入的流程。 关于mybatis与Spring整合，mapper的注册与注入，就学习到这里，还有一些瑕疵，后续再写笔记进行补充。]]></content>
      <categories>
        <category>后端</category>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：@EnableAutoConfiguration自动配置原理]]></title>
    <url>%2Fspring-boot-enableautoconfiguration.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;众所周知，springboot的出现为开发带来了很大的方便，主要就是提供了很多自动配置，免去了开发人员花在配置上的时间，使我们开发者能更专注于业务或者架构设计上。 &emsp;&emsp;而springboot的自动配置是通过一系列注解来完成的，例如@EnableAutoConfiguration、@Conditional、@ConditionalOn*、@EnableConfigurationProperties等等。 &emsp;&emsp;这一系列注解我觉得大致可分为两类，一类是条件注解，一类是与配置相关的注解，下面分别举一些例子进行说明。 条件注解 @ConditionalOnBean 当容器里有指定的bean类或者名称时，满足匹配条件 @ConditionalOnMissingBean 当容器里缺少指定的bean类或者名称时，满足匹配条件 @ConditionalOnProperty 检查指定的属性是否有特定的值，name为指定值的key，havingValue为指定值，matchIfMissing为缺少或为设置值时，是否也进行匹配 @ConditionOnClass 当有指定类在classpath时，满足匹配条件 @ConditionOnMissClass 当指定类在classpath不存在时，满足匹配条件 配置相关注解 @EnableAutoConfiguration 开启自动配置 @AutoConfigureAfter 在指定的自动配置类之后进行配置 @AutoConfigureBefore 在指定的自动配置类之前进行配置 @EnableConfigurationProperties 开启对@ConfigurationProperties修饰的bean的支持，将@ConfigurationProperties修饰的类注册成bean &emsp;&emsp;而最核心的我想就是@EnableAutoConfiguration注解了，毕竟只有有了它才能开启自动配置，是所有自动配置的起点，那么就从它开始探索下自动配置的原理。 以下源码版本为springboot 2.0.5.RELEASE 先看下这个注解： 123456789101112131415@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; &emsp;&emsp;可以看到这里导入了AutoConfigurationImportSelector，先看下该类核心的selectImports()方法： 123456789101112131415161718@Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return StringUtils.toStringArray(configurations); &#125; &emsp;&emsp;可以看出，先获取到所有配置，然后删除重复的配置，然后获取需要排除的配置类，再检查需要排除的配置类，从所有配置中移除需要排除的配置，再使用filter过滤掉不满足自动导入条件的配置（例如使用了@Contional及衍生的条件注解的配置类），最后将剩下的配置类返回。 &emsp;&emsp;下面我们具体地看下selectImports()中的getCandidateConfigurations(): 123456789protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, "No auto configuration classes found in META-INF/spring.factories. If you " + "are using a custom packaging, make sure that file is correct."); return configurations; &#125; &emsp;&emsp;该方法主要通过SpringFactoriesLoader.loadFactorynames()使用当前的类加载器返回指定EnableAutoConfiguration在META-INF/spring.factories对应的所有配置类名。 &emsp;&emsp;那么META-INF/spring.factories是什么呢，在spring-boot-autoconfigure.jar包下有这样一个文件： 1234567891011121314# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\...省略... &emsp;&emsp;可以看到，这里几乎写了所有springboot提供的各种配置类，所以@EnableAutoConfiguration导入了AutoConfigurationImportSelector，就几乎相当于将所有的配置类都引入进来加载了，所以springboot的自动配置换句话说，其实是帮我们定义了很多通用配置的配置类，再统一按条件引入进来加载。 &emsp;&emsp;至于selectImports()中其他作用的实现都比较简单，值得一看的是通过filter(configurations, autoConfigurationMetadata)过滤不满足条件的配置类，源码： 123456789101112131415161718192021222324252627282930313233private List&lt;String&gt; filter(List&lt;String&gt; configurations, AutoConfigurationMetadata autoConfigurationMetadata) &#123; long startTime = System.nanoTime(); String[] candidates = StringUtils.toStringArray(configurations); boolean[] skip = new boolean[candidates.length]; boolean skipped = false; for (AutoConfigurationImportFilter filter : getAutoConfigurationImportFilters()) &#123; invokeAwareMethods(filter); boolean[] match = filter.match(candidates, autoConfigurationMetadata); for (int i = 0; i &lt; match.length; i++) &#123; if (!match[i]) &#123; skip[i] = true; skipped = true; &#125; &#125; &#125; if (!skipped) &#123; return configurations; &#125; List&lt;String&gt; result = new ArrayList&lt;&gt;(candidates.length); for (int i = 0; i &lt; candidates.length; i++) &#123; if (!skip[i]) &#123; result.add(candidates[i]); &#125; &#125; if (logger.isTraceEnabled()) &#123; int numberFiltered = configurations.size() - result.size(); logger.trace("Filtered " + numberFiltered + " auto configuration class in " + TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime) + " ms"); &#125; return new ArrayList&lt;&gt;(result); &#125; &emsp;&emsp;这里主要是从META-INF/spring.factories中获取到AutoConfigurationImportFilter： 123# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\org.springframework.boot.autoconfigure.condition.OnClassCondition &emsp;&emsp;即OnClassCondition，调用match()方法检查是否存在有@ConditionalOnClass和@ContionalOnMissClass注解的配置类。 &emsp;&emsp;至此，关于@EnableAutoConfiguration的自动配置原理我们心里也有了答案。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：自定义抽屉组件]]></title>
    <url>%2Fvue-self-drawer-component.html</url>
    <content type="text"><![CDATA[这两天在开发某个前端系统时，想要做一个抽屉弹出的功能，但由于当前系统是使用的element-ui，并没有提供抽屉组件，而之前使用的iView则提供了抽屉组件，于是便着手仿照iView的抽屉组件自定义了一个简易的抽屉组件。 定义组件 dwui-drawer.vue : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;template&gt; &lt;div class="dwui-drawer"&gt; &lt;div v-if="open" :class="computeMode" @click="maskClick"&gt; &lt;/div&gt; &lt;div :class="computeContent"&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'dwui-drawer', props: &#123; /** * 是否点击遮罩层关闭，默认可以 */ maskCloseable: &#123; type: Boolean, default: true &#125;, /** * 抽屉出来位置 */ position: &#123; type: String, default: 'right' &#125;, /** * 是否打开 */ open: &#123; type: Boolean &#125; &#125;, computed: &#123; computeMode () &#123; return this.position === 'left' ? (this.open ? 'dwui-drawer-open-mode': 'dwui-drawer-close-mode') : ( this.open ? 'dwui-drawer-open-mode-right': 'dwui-drawer-close-mode-right') &#125;, computeContent () &#123; return this.position === 'left' ? (this.open ? 'dwui-drawer-open-content' : 'dwui-drawer-close-content') : (this.open ? 'dwui-drawer-open-content-right' :'dwui-drawer-close-content-right') &#125; &#125;, methods: &#123; maskClick() &#123; if (this.maskCloseable) &#123; this.$emit('update:open',false); this.$emit('change'); &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped lang="less"&gt; @import "./dwui-drawer"; .dwui-drawer-open-content,.dwui-drawer-close-content&#123; padding: 30px 0px 0px 0px; &#125; .dwui-drawer-open-content-right,.dwui-drawer-close-content-right&#123; padding: 30px 0px 0px 0px; &#125;&lt;/style&gt; 定义样式文件dwui-drawer.less 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556.dwui-drawer&#123; &amp;-close-content,&amp;-open-content, &amp;-close-content-right,&amp;-open-content-right, &amp;-close-mode ,&amp;-open-mode,&amp;-close-mode-right,&amp;-open-mode-right&#123; position: fixed; top: 0; height: 100%; &#125; &amp;-close-content,&amp;-open-content,&amp;-close-content-right,&amp;-open-content-right&#123; width: 10%; background: #fff; z-index: 99 &#125; &amp;-open-mode,&amp;-close-mode,&amp;-close-mode-right,&amp;-open-mode-right&#123; background: #222222; opacity: 0.8; z-index: 9; width: 100%; right: 0; left: 0; &#125; &amp;-close-content&#123; opacity:0; left: 0%; transform: translate3d(-100%, 0, 0); transition: all .2s; &#125; &amp;-open-content&#123; opacity:1; left: 0%; transform: translate3d(0, 0, 0); transition:all .2s; &#125; &amp;-close-content-right&#123; right: -50%; transition: right .2s; &#125; &amp;-open-content-right&#123; right: 0; transition: right .2s; &#125; &amp;-close-mode&#123; opacity:0; transition: opacity .2s; &#125; &amp;-open-mode&#123; opacity: 0.7; transition: opacity .2s; &#125; &amp;-close-mode-right&#123; opacity:0; transition: opacity .2s; &#125; &amp;-open-mode-right&#123; opacity: 0.7; transition: opacity .2s; &#125;&#125; 使用 123&lt;dwui-drawer :open.sync="showRight" :mask-closeable="true" position="right"&gt; &lt;p&gt;xxxx&lt;/p&gt;&lt;/dwui-drawer&gt; 这样一个抽屉组件就定义好了，记录一下～]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot：@Async注解详解]]></title>
    <url>%2Fspring-boot-annotation-async.html</url>
    <content type="text"><![CDATA[在springboot中，提供了@Async注解来实现异步调用，方法使用@Async修饰之后，就变成了异步方法，这些方法将会在单独的线程被执行，方法的调用者不用在等待方法的完成。 @Async的启用与使用 在配置类或者启动类上加上@EnableAsync注解 例如下面代码： 12345678@SpringBootApplication@EnableAsyncpublic class StudyApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StudyApplication.class, args); &#125;&#125; 无返回值的方法使用@Async 在service上方法上添加@Async注解： 123456789@Service@Slf4jpublic class AsyncService &#123; @Async public void test() &#123; log.info("test"); &#125;&#125; 再在controller中调用service该方法： 1234567891011@RestControllerpublic class AsyncController &#123; @Autowired AsyncService asyncService; @GetMapping("/async/test2") public void testAsync() &#123; asyncService.test(); &#125;&#125; 有返回值的方法使用@Async springboot提供了AsyncResult类来支持@Async处理，该类实现了ListenableFuture接口，而该接口则继承自Future接口，所以对于需要有返回值的方法，可将返回值用Future包装，如下： 1234567891011@Asyncpublic Future&lt;String&gt; testFuture() &#123; log.info("test future:"); try &#123; Thread.sleep(5000L); return new AsyncResult&lt;String&gt;("test"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); return null; &#125;&#125; controller里通过future.get()获取返回值，但需要注意的是，该方法会阻塞 @Async源码探索我们都知道，被@Async修饰的方法都会被单独的线程执行，而spring容器需要维护这些线程，就需要一个线程池，而默认提供的线程池就是SimpleAsyncTaskExecutor，我们通过打印当前线程名就能看出： 1test:Thread[SimpleAsyncTaskExecutor-1,5,main] 那么默认的线程池是怎么样被提供的呢，探索一下源码，这里springboot的版本是2.0.5。 首先想要使用@Async则需要开启这个功能，即@EnbaleAsync注解，我们看一下这个注解源码： 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123;&#125; 单从源码上，可以看到引入了一个selector：AsyncConfigurationSelector，我们再看这个注解的注释，可以发现些端倪： 1234567* &lt;p&gt;By default, Spring will be searching for an associated thread pool definition: * either a unique &#123;@link org.springframework.core.task.TaskExecutor&#125; bean in the context, * or an &#123;@link java.util.concurrent.Executor&#125; bean named "taskExecutor" otherwise. If * neither of the two is resolvable, a &#123;@link org.springframework.core.task.SimpleAsyncTaskExecutor&#125; * will be used to process async method invocations. Besides, annotated methods having a * &#123;@code void&#125; return type cannot transmit any exception back to the caller. By default, * such uncaught exceptions are only logged. 从注释中我们不难发现，默认情况，会去spring上下文中找TaskExecutor、Executor的bean或者名字是taskExecutor的bean，如果都没有，则会默认使用SimpleAsyncTaskExecutor。从注释中我们已经可以确定了，但Spring是怎么实现的呢，@EnableAsync中引入了AsyncConfigurationSelector，我们点开这个类，寻找下是否有实现： 123456789101112131415161718public class AsyncConfigurationSelector extends AdviceModeImportSelector&lt;EnableAsync&gt; &#123; private static final String ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME = "org.springframework.scheduling.aspectj.AspectJAsyncConfiguration"; @Override @Nullable public String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;ProxyAsyncConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME&#125;; default: return null; &#125; &#125;&#125; 可以看到，当是jdk代理模式时，使用ProxyAsyncConfiguration配置类，当使用aspectJ代理时，使用org.springframework.scheduling.aspectj.AspectJAsyncConfiguration，而默认则是jdk代理，所以继续点开ProxyAsyncConfiguration： 12345678910111213141516171819202122232425@Configuration@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class ProxyAsyncConfiguration extends AbstractAsyncConfiguration &#123; @Bean(name = TaskManagementConfigUtils.ASYNC_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public AsyncAnnotationBeanPostProcessor asyncAdvisor() &#123; Assert.notNull(this.enableAsync, "@EnableAsync annotation metadata was not injected"); AsyncAnnotationBeanPostProcessor bpp = new AsyncAnnotationBeanPostProcessor(); Class&lt;? extends Annotation&gt; customAsyncAnnotation = this.enableAsync.getClass("annotation"); if (customAsyncAnnotation != AnnotationUtils.getDefaultValue(EnableAsync.class, "annotation")) &#123; bpp.setAsyncAnnotationType(customAsyncAnnotation); &#125; if (this.executor != null) &#123; bpp.setExecutor(this.executor); &#125; if (this.exceptionHandler != null) &#123; bpp.setExceptionHandler(this.exceptionHandler); &#125; bpp.setProxyTargetClass(this.enableAsync.getBoolean("proxyTargetClass")); bpp.setOrder(this.enableAsync.&lt;Integer&gt;getNumber("order")); return bpp; &#125;&#125; 可以看到熟悉的字眼：executor，而这里的executor来自父类AbstractAsyncConfiguration，难道就要揭开谜底了吗，怀着激动的心情我们继续看这个父类： 123456789101112131415161718192021222324252627282930@Configurationpublic abstract class AbstractAsyncConfiguration implements ImportAware &#123; // 省略 @Nullable protected Executor executor; // 省略 @Override public void setImportMetadata(AnnotationMetadata importMetadata) &#123; // 省略 &#125; @Autowired(required = false) void setConfigurers(Collection&lt;AsyncConfigurer&gt; configurers) &#123; if (CollectionUtils.isEmpty(configurers)) &#123; return; &#125; if (configurers.size() &gt; 1) &#123; throw new IllegalStateException("Only one AsyncConfigurer may exist"); &#125; AsyncConfigurer configurer = configurers.iterator().next(); this.executor = configurer.getAsyncExecutor(); this.exceptionHandler = configurer.getAsyncUncaughtExceptionHandler(); &#125;&#125; 不禁哑然，executor是通过setConfigurers()方法赋值的，而该方法注入了AsyncConfigurer类型的bean，通过configurer.getAsyncExecutor()获取到executor，而可惜的是AsyncConfigurer接口默认返回null，而它唯一的子类，也是返回null，也就是说整个spring上下文并没有该类型的bean，即executor为null，但上面我们明明通过打印日志和注释知道了默认是SimpleAsyncTaskExecutor。 其实这里也指明了一种我们提供自定义线程池的方式，定义一个类实现AsyncConfigurer接口，实现getAsyncExecutor方法返回自定义的executor，再将该类注册成bean。 那么就很明显了，@EnableAsync这条线索是走不通了，默认线程池并不是在开启async的时候提供的，那么就有可能和@Async注解相关。 @Async这个注解的实现是基于spring-aop来做到的，注解源码本身并没什么，看注释： 12* @see AnnotationAsyncExecutionInterceptor* @see AsyncAnnotationAdvisor AnnotationAsyncExecutionInterceptor顾名思义，是@Async注解修饰的方法执行的拦截器，该类继承自AsyncExecutionInterceptor，类本身没什么核心方法，继续看父类AsyncExecutionInterceptor中的核心方法invoke()： 12345678910111213141516171819202122232425262728293031@Override @Nullable public Object invoke(final MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); Method specificMethod = ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass); final Method userDeclaredMethod = BridgeMethodResolver.findBridgedMethod(specificMethod); AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod); if (executor == null) &#123; throw new IllegalStateException( "No executor specified and no default executor set on AsyncExecutionInterceptor either"); &#125; Callable&lt;Object&gt; task = () -&gt; &#123; try &#123; Object result = invocation.proceed(); if (result instanceof Future) &#123; return ((Future&lt;?&gt;) result).get(); &#125; &#125; catch (ExecutionException ex) &#123; handleError(ex.getCause(), userDeclaredMethod, invocation.getArguments()); &#125; catch (Throwable ex) &#123; handleError(ex, userDeclaredMethod, invocation.getArguments()); &#125; return null; &#125;; return doSubmit(task, executor, invocation.getMethod().getReturnType()); &#125; 可以看到有这么一行，确定了async使用的executor： 1AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod); 该方法来自AsyncExecutionInterceptor的父类AsyncExecutionAspectSupport，看一下该方法： 12345678910111213141516171819202122232425262728protected AsyncTaskExecutor determineAsyncExecutor(Method method) &#123; AsyncTaskExecutor executor = this.executors.get(method); if (executor == null) &#123; Executor targetExecutor; String qualifier = getExecutorQualifier(method); if (StringUtils.hasLength(qualifier)) &#123; targetExecutor = findQualifiedExecutor(this.beanFactory, qualifier); &#125; else &#123; targetExecutor = this.defaultExecutor; if (targetExecutor == null) &#123; synchronized (this.executors) &#123; if (this.defaultExecutor == null) &#123; this.defaultExecutor = getDefaultExecutor(this.beanFactory); &#125; targetExecutor = this.defaultExecutor; &#125; &#125; &#125; if (targetExecutor == null) &#123; return null; &#125; executor = (targetExecutor instanceof AsyncListenableTaskExecutor ? (AsyncListenableTaskExecutor) targetExecutor : new TaskExecutorAdapter(targetExecutor)); this.executors.put(method, executor); &#125; return executor; &#125; 这里this.executor初始时是一个空的Map，初始时this.defaultExecutor也是为空，所以将会执行其中的this.defaultExecutor = getDefaultExecutor(this.beanFactory);，而子类AsyncExecutionInterceptor重写了该方法，再回到AsyncExecutionInterceptor查看： 123456@Override @Nullable protected Executor getDefaultExecutor(@Nullable BeanFactory beanFactory) &#123; Executor defaultExecutor = super.getDefaultExecutor(beanFactory); return (defaultExecutor != null ? defaultExecutor : new SimpleAsyncTaskExecutor()); &#125; 看到这里似乎有拨开云雾见青天的意思了，会先调用父类AsyncExecutionAspectSupport的getDefaultExecutor()方法，如果不为空，则返回父类获取的executor，如果为空，则返回SimpleAsyncTaskExecutor，而父类AsyncExecutionAspectSupport的getDefaultExecutor()： 1234567891011121314151617181920212223242526272829303132@Nullable protected Executor getDefaultExecutor(@Nullable BeanFactory beanFactory) &#123; if (beanFactory != null) &#123; try &#123; beanFactory.getBean(TaskExecutor.class); &#125; catch (NoUniqueBeanDefinitionException ex) &#123; logger.debug("Could not find unique TaskExecutor bean", ex); try &#123; return beanFactory.getBean(DEFAULT_TASK_EXECUTOR_BEAN_NAME, Executor.class); &#125; catch (NoSuchBeanDefinitionException ex2) &#123; if (logger.isInfoEnabled()) &#123; logger.info("More than one TaskExecutor bean found within the context, and none is named " + "'taskExecutor'. Mark one of them as primary or name it 'taskExecutor' (possibly " + "as an alias) in order to use it for async processing: " + ex.getBeanNamesFound()); &#125; &#125; &#125; catch (NoSuchBeanDefinitionException ex) &#123; logger.debug("Could not find default TaskExecutor bean", ex); try &#123; return beanFactory.getBean(DEFAULT_TASK_EXECUTOR_BEAN_NAME, Executor.class); &#125; catch (NoSuchBeanDefinitionException ex2) &#123; logger.info("No task executor bean found for async processing: " + "no bean of type TaskExecutor and no bean named 'taskExecutor' either"); &#125; &#125; &#125; return null; &#125; 这里其实就是从Spring上下文获取TaskExecutor类型的bean，或者名称为taskExecutor的bean。 而获取到executor之后，会将被@Async修饰的方法，也就是任务task，提交（submit）到excutor中执行。 所以到这里，关于@Async默认线程池的使用有了答案，默认会使用SimpleAsyncTaskExecutor，而对于我们，想要自定义executor时，有两种方法，一种就是上面说的，自定义类实现AsyncConfigurer接口再注册成bean，另一种就是注册TaskExecutor类型的bean或者名称是taskExecutor的bean。 以上探索的过程主要通过查看源码以及源码注释，以及结合debug模式下查看调用栈]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一场梦把我勾进了回忆的漩涡]]></title>
    <url>%2Fdream-take-me-to-past.html</url>
    <content type="text"><![CDATA[春江秋月何时了，往事知多少？ &emsp;&emsp;六月中旬的杭州，已经开始一只脚迈进了雨季，雨季，总是让人忧伤的。 &emsp;&emsp;清早，湿润的凉风裹挟着丝丝细雨，从半开的窗户溜进屋，轻伏在我的脸上，将我从梦中拉出。睁开眼，梦中那熟悉的面孔和情形仍在脑海漂浮，像回音般想要在回荡中慢慢淡去。我一边努力挣扎着要抓住梦，一边慢慢坠入了回忆的漩涡。 &emsp;&emsp;大概是十几年前了，真快，时间久得若不是一场梦，这样一段记忆恐只能掩盖在脑海深处的泥沙中了。那是初一，你我坐在前后位，我还记得那时的你英语很好，我常常向你请教英语，也许是青春期的悸动，那时的我已被你深深的吸引。十年前没有现在的互联网发达，我只能常打电话给你，只为了在家也能听到你的声音，最终在不知道多少次打电话之后，在一次电话中，我向你表了白，现在想起，竟也仍会有些替那时的自己害羞。 &emsp;&emsp;后来，后来的事我竟然已没法按顺序想起！从回忆中捡起这些记忆的碎片，我竟也无法将他们按时间的轨迹排列，只看到，我在各种节日送了你多次礼物，和你在一起逛街玩，你送我的一双手套，还有年少的我总是为了你吃醋，啊！对！模糊的记忆告诉我，似乎是年少可笑的吃醋让我们的关系慢慢疏远。这一疏远就是十年没联系，曾记得中间有次同学聚会，看到了你，我也未和你说话，但我记得，那天我一直在趁没人注意的机会看你。 &emsp;&emsp;距上次同学聚会见面，一晃又是多年，可笑的是，若不是一场梦，又怎会再想起你。年少的情窦初开，一段似乎美好的记忆竟这样破碎不堪，再逐一拾起时，却被微微地刺痛。 &emsp;&emsp;起身，从漩涡中挣扎出来，看窗外雨似乎又大了起来，摇摇头，是谁想在这雨季述其忧伤，倾其回忆？风雨零落，韶光已逝，还有未来的年华。]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security Oauth2：自定义手动授权页]]></title>
    <url>%2Fspring-security-oauth2-authrize-confirm.html</url>
    <content type="text"><![CDATA[在基于spring security oauth2搭建了认证授权中心之后，Spring security oauth2默认提供了授权页面，但较为简陋，于是提高用户体验，我们需要自定义授权页面，首先我们需要先了解授权的流程。 授权首先是通过get请求访问/oauth/authorize接口，并携带相关参数，例如: http://localhost:9001/oauth/authorize?response_type=code&amp;client_id=8&amp;redirect_uri=http://localhost:8092/api/redirect&amp;username=wetsion&amp;password=$2a$11$P3utwZyiCwy0jM1Hke49WeZVIu5Lv9z6nqhqKluhlweTbhUyWK74G&amp;state=wetsion org.springframework.security.oauth2.provider.endpoint.AuthorizationEndpoint中authorize()负责处理get请求的/oauth/authorize： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 @RequestMapping(value = "/oauth/authorize")public ModelAndView authorize(Map&lt;String, Object&gt; model, @RequestParam Map&lt;String, String&gt; parameters, SessionStatus sessionStatus, Principal principal) &#123; // Pull out the authorization request first, using the OAuth2RequestFactory. All further logic should // query off of the authorization request instead of referring back to the parameters map. The contents of the // parameters map will be stored without change in the AuthorizationRequest object once it is created. AuthorizationRequest authorizationRequest = getOAuth2RequestFactory().createAuthorizationRequest(parameters); Set&lt;String&gt; responseTypes = authorizationRequest.getResponseTypes(); if (!responseTypes.contains("token") &amp;&amp; !responseTypes.contains("code")) &#123; throw new UnsupportedResponseTypeException("Unsupported response types: " + responseTypes); &#125; if (authorizationRequest.getClientId() == null) &#123; throw new InvalidClientException("A client id must be provided"); &#125; try &#123; if (!(principal instanceof Authentication) || !((Authentication) principal).isAuthenticated()) &#123; throw new InsufficientAuthenticationException( "User must be authenticated with Spring Security before authorization can be completed."); &#125; ClientDetails client = getClientDetailsService().loadClientByClientId(authorizationRequest.getClientId()); // The resolved redirect URI is either the redirect_uri from the parameters or the one from // clientDetails. Either way we need to store it on the AuthorizationRequest. String redirectUriParameter = authorizationRequest.getRequestParameters().get(OAuth2Utils.REDIRECT_URI); String resolvedRedirect = redirectResolver.resolveRedirect(redirectUriParameter, client); if (!StringUtils.hasText(resolvedRedirect)) &#123; throw new RedirectMismatchException( "A redirectUri must be either supplied or preconfigured in the ClientDetails"); &#125; authorizationRequest.setRedirectUri(resolvedRedirect); // We intentionally only validate the parameters requested by the client (ignoring any data that may have // been added to the request by the manager). oauth2RequestValidator.validateScope(authorizationRequest, client); // Some systems may allow for approval decisions to be remembered or approved by default. Check for // such logic here, and set the approved flag on the authorization request accordingly. authorizationRequest = userApprovalHandler.checkForPreApproval(authorizationRequest, (Authentication) principal); // TODO: is this call necessary? boolean approved = userApprovalHandler.isApproved(authorizationRequest, (Authentication) principal); authorizationRequest.setApproved(approved); // Validation is all done, so we can check for auto approval... if (authorizationRequest.isApproved()) &#123; if (responseTypes.contains("token")) &#123; return getImplicitGrantResponse(authorizationRequest); &#125; if (responseTypes.contains("code")) &#123; return new ModelAndView(getAuthorizationCodeResponse(authorizationRequest, (Authentication) principal)); &#125; &#125; // Place auth request into the model so that it is stored in the session // for approveOrDeny to use. That way we make sure that auth request comes from the session, // so any auth request parameters passed to approveOrDeny will be ignored and retrieved from the session. model.put("authorizationRequest", authorizationRequest); return getUserApprovalPageResponse(model, authorizationRequest, (Authentication) principal); &#125; catch (RuntimeException e) &#123; sessionStatus.setComplete(); throw e; &#125;&#125; 如果isApproved为false，则调用getUserApprovalPageResponse： 12345678private ModelAndView getUserApprovalPageResponse(Map&lt;String, Object&gt; model, AuthorizationRequest authorizationRequest, Authentication principal) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Loading user approval page: " + userApprovalPage); &#125; model.putAll(userApprovalHandler.getUserApprovalRequest(authorizationRequest, principal)); return new ModelAndView(userApprovalPage, model); &#125; 这里： String userApprovalPage = &quot;forward:/oauth/confirm_access&quot; 即转发到/oauth/confirm_access 默认是由org.springframework.security.oauth2.provider.endpoint.WhitelabelApprovalEndpoint类处理/oauth/confirm_access请求，将用户引导到默认授权页（这里默认授权页是由代码渲染的html页面）： 123456789101112131415161718192021222324252627@FrameworkEndpoint@SessionAttributes("authorizationRequest")public class WhitelabelApprovalEndpoint &#123; @RequestMapping("/oauth/confirm_access") public ModelAndView getAccessConfirmation(Map&lt;String, Object&gt; model, HttpServletRequest request) throws Exception &#123; final String approvalContent = createTemplate(model, request); if (request.getAttribute("_csrf") != null) &#123; model.put("_csrf", request.getAttribute("_csrf")); &#125; View approvalView = new View() &#123; @Override public String getContentType() &#123; return "text/html"; &#125; @Override public void render(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; response.setContentType(getContentType()); response.getWriter().append(approvalContent); &#125; &#125;; return new ModelAndView(approvalView, model); &#125; // 省略其他&#125; 看到这里，我们就已经可以知道，想要自定义授权页，只需要替换掉默认的WhitelabelApprovalEndpoint即可。 引入thymeleaf依赖，在resource下创建templates文件夹，再在templates文件夹创建一个grant.html文件： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;授权&lt;/title&gt;&lt;/head&gt;&lt;!-- 省略样式 --&gt;&lt;body style="margin: 0px"&gt;&lt;div class="title"&gt; &lt;div class="title-right"&gt;大数据RMS统一管理平台 授权&lt;/div&gt; &lt;div class="title-left"&gt; &lt;a href="#help"&gt;help&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="container"&gt; &lt;h3 th:text="'应用 '+$&#123;clientName&#125;+' 请求授权，该应用将获取你的以下信息'"&gt;&lt;/h3&gt; &lt;p&gt;昵称，账号&lt;/p&gt; 授权后表明你已同意 &lt;form method="post" action="/oauth/authorize"&gt; &lt;input type="hidden" name="user_oauth_approval" value="true"&gt; &lt;input type="hidden" name="scope.all" value="true"&gt; &lt;input type="hidden" name="_csrf" th:value="$&#123;_csrf.getToken()&#125;"/&gt; &lt;button class="btn" type="submit"&gt; 同意/授权&lt;/button&gt; &lt;/form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 在applicaiton.properties中配置thymeleaf: 123spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.cache=falsespring.thymeleaf.suffix=.html 创建处理/oauth/confirm_access请求的controller覆盖默认的WhitelabelApprovalEndpoint: 123456789101112131415161718@Controller@SessionAttributes("authorizationRequest")public class GrantController &#123; @Autowired private PlatformService platformService; @RequestMapping("/oauth/confirm_access") public ModelAndView getAccessConfirmation(Map&lt;String, Object&gt; model, HttpServletRequest request) &#123; AuthorizationRequest authorizationRequest = (AuthorizationRequest) model.get("authorizationRequest"); ModelAndView view = new ModelAndView(); view.setViewName("grant"); view.addObject("clientId", authorizationRequest.getClientId()); PlatformDO platformDO = platformService.getById(Long.parseLong(authorizationRequest.getClientId())); view.addObject("clientName", platformDO.getNameCn()); return view; &#125;&#125; 至此，需要用户授权的/oauth/authorize请求将会跳转到自定义的授权页面，就完成了自定义授权页面的开发。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>Java</tag>
        <tag>SpringSecurityOauth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于iview的自定义动态表单组件]]></title>
    <url>%2Fvue-self-definition-dynamic-form.html</url>
    <content type="text"><![CDATA[近期在开发搜索管理系统的时候，由于业务需求需要，基于iview开发了一个动态表单组件 对于调用者，只需要传入表单项的定义，还有对应表单项的值，即可动态渲染出表单，同时支持配置表单是全部渲染还是手动逐步添加显示表单项 代码如下： dynamic-form.vue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189&lt;template&gt; &lt;Form ref="oweForm" :model="data" :label-width="80"&gt; &lt;div v-if="!gradual"&gt; &lt;FormItem v-for="(formItem, index) in formValue" :prop="formItem.name" :label="formItem.note" :key="index" :rules="formItem.rules"&gt; &lt;Row&gt; &lt;Col span="18"&gt; &lt;component :is="showItems[formItem.type]" v-model="data[formItem.name]" :info="formItem"/&gt; &lt;/Col&gt; &lt;Col span="4" offset="1"&gt; &lt;Poptip trigger="hover" :content="formItem.tips === '' ? '无' : formItem.tips"&gt; &lt;Icon type="ios-help-circle-outline" size="18"/&gt; &lt;/Poptip&gt; &lt;/Col&gt; &lt;/Row&gt; &lt;/FormItem&gt; &lt;/div&gt; &lt;div v-else&gt; &lt;FormItem v-for="(formItem, index) in currentGradualFormValue" :prop="formItem.name" :label="formItem.note" :key="index" :rules="formItem.rules"&gt; &lt;Row&gt; &lt;Col span="14"&gt; &lt;component :is="showItems[formItem.type]" v-model="data[formItem.name]" :info="formItem"/&gt; &lt;/Col&gt; &lt;Col span="4" offset="1"&gt; &lt;Poptip trigger="hover" :content="formItem.tips === '' ? '无' : formItem.tips"&gt; &lt;Icon type="ios-help-circle-outline" size="18"/&gt; &lt;/Poptip&gt; &lt;/Col&gt; &lt;Col span="4" offset="1"&gt; &lt;Button @click="removeFormValue(formItem.name)"&gt;Delete&lt;/Button&gt; &lt;/Col&gt; &lt;/Row&gt; &lt;/FormItem&gt; &lt;Row&gt; &lt;Col span="16"&gt; &lt;Select v-model="choosedFormValueName" style="width:200px"&gt; &lt;Option v-for="item in gradualFromValue" :value="item.name" :key="item.name"&gt;&#123;&#123; item.name &#125;&#125;&lt;/Option&gt; &lt;/Select&gt; &lt;/Col&gt; &lt;Col span="8"&gt; &lt;Button @click="addFormValue"&gt;新增表单项&lt;/Button&gt; &lt;/Col&gt; &lt;/Row&gt; &lt;/div&gt; &lt;/Form&gt;&lt;/template&gt;&lt;script&gt;import showItems from './form-items-map'export default &#123; name: 'DynamicForm', props: &#123; value: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125;, form: &#123; type: String, default: '' &#125;, // 是否可逐步添加表单项，默认否，展示全部表单项 gradual: &#123; type: Boolean, default: false &#125; &#125;, data () &#123; return &#123; showItems, gradualFromValue: [], currentGradualFormValue: [], gradualFormMap: &#123;&#125;, choosedFormValueName: '' &#125; &#125;, watch: &#123; form (val) &#123; this.generateGradualFormValue() &#125;, value: &#123; handler (nv, ov) &#123; this.generateGradualFormValue() &#125;, deep: true &#125; &#125;, computed: &#123; formValue: &#123; get () &#123; let formValueArr = JSON.parse(this.form) for (let i = 0; i &lt; formValueArr.length; i++) &#123; let rules = [] if (formValueArr[i].required) &#123; rules.push(&#123;required: true, type: 'string', message: formValueArr[i].hintText, trigger: 'blur'&#125;) &#125; // TODO 正则匹配校验待实现，判空待实现 formValueArr[i].rules = rules // 如果有默认值，将默认值赋值给data[formItem] // if (formValueArr[i].conf.defaultValue) &#123; // this.data[formValueArr[i].name] = formValueArr[i].conf.defaultValue // &#125; &#125; return formValueArr &#125; &#125;, data: &#123; set (val) &#123; this.$emit('input', val) &#125;, get () &#123; return this.value &#125; &#125; &#125;, methods: &#123; async validate () &#123; console.log('df validate') return new Promise((resolve) =&gt; &#123; this.$refs.oweForm.validate((valid) =&gt; &#123; resolve(valid) &#125;) &#125;) &#125;, onValidate (callback) &#123;&#125;, generateGradualFormValue () &#123; this.gradualFromValue = [] this.currentGradualFormValue = [] let formValueArr = JSON.parse(this.form) for (let i = 0; i &lt; formValueArr.length; i++) &#123; let rules = [] if (formValueArr[i].required) &#123; rules.push(&#123;required: true, type: 'string', message: formValueArr[i].hintText, trigger: 'blur'&#125;) &#125; // TODO 正则匹配校验待实现，判空待实现 formValueArr[i].rules = rules this.gradualFormMap[formValueArr[i].name] = formValueArr[i] if (this.value.hasOwnProperty(formValueArr[i].name)) &#123; this.currentGradualFormValue.push(formValueArr[i]) &#125; &#125; this.gradualFromValue = formValueArr &#125;, /*** * 往动态表单里添加表单项 * @param name */ addFormValue () &#123; let canCreate = true this.currentGradualFormValue.forEach(item =&gt; &#123; if (item.name === this.choosedFormValueName) &#123; this.$Message.warning('该表单项已存在！') canCreate = false &#125; &#125;) if (canCreate) &#123; this.currentGradualFormValue.push(this.gradualFormMap[this.choosedFormValueName]) &#125; &#125;, /*** * 删除动态表单项 * @param name */ removeFormValue (name) &#123; let tempArr = [] this.currentGradualFormValue.forEach(item =&gt; &#123; if (item.name !== name) &#123; tempArr.push(item) &#125; &#125;) this.currentGradualFormValue = tempArr &#125; &#125;, mounted () &#123; this.generateGradualFormValue() &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; form属性是一个数组转成的字符串，数组中每一个对象需要包含以下属性： required 是否必填 hintText hintText文本 name 表单项的name note 表单项的label type 表单项的类型 tips 提示文本 form-items-map.js 12345678910111213import FormInput from './form-items/form-input'import FormCheckbox from './form-items/form-checkbox'import FormRadio from './form-items/form-radio'import FormSelect from './form-items/form-select'import FormTextarea from './form-items/form-textarea'export default &#123; 0: FormInput, 1: FormTextarea, 2: FormRadio, 3: FormSelect, 4: FormCheckbox&#125; FormInput、FormCheckbox、FormRadio、FormSelect、FormTextarea都是重写的表单项，具有统一的props form-input.vue 1234567891011121314151617181920212223242526272829303132&lt;template&gt; &lt;Input type="text" v-model="data" :placeholder="info.conf.hintText ? info.conf.hintText : ''"/&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'FormInput', props: &#123; value: &#123; type: String | Number, default: '' &#125;, info: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125; &#125;, computed: &#123; data: &#123; get () &#123; return this.value &#125;, set (val) &#123; this.$emit('input', val) &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; form-checkbox.vue 123456789101112131415161718192021222324252627282930313233343536&lt;template&gt; &lt;CheckboxGroup v-model="data"&gt; &lt;Checkbox v-for="(item, index) in info.conf.data" :label="item.return" :key="index"&gt; &lt;span&gt;&#123;&#123; item.show &#125;&#125;&lt;/span&gt; &lt;/Checkbox&gt; &lt;/CheckboxGroup&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'FormCheckbox', props: &#123; value: &#123; type: String | Number, default: '' &#125;, info: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125; &#125;, computed: &#123; data: &#123; get () &#123; return this.value &#125;, set (val) &#123; this.$emit('input', val) &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; form-radio.vue 123456789101112131415161718192021222324252627282930313233343536&lt;template&gt; &lt;RadioGroup v-model="data"&gt; &lt;Radio v-for="(item, index) in info.conf.data" :label="item.return" :key="index"&gt; &lt;span&gt;&#123;&#123; item.show &#125;&#125;&lt;/span&gt; &lt;/Radio&gt; &lt;/RadioGroup&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'FormRadio', props: &#123; value: &#123; type: String | Number, default: '' &#125;, info: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125; &#125;, computed: &#123; data: &#123; get () &#123; return this.value &#125;, set (val) &#123; this.$emit('input', val) &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; form-select.vue 12345678910111213141516171819202122232425262728293031323334&lt;template&gt; &lt;Select v-model="data" style="width:200px"&gt; &lt;Option v-for="(item, index) in info.conf.data" :value="item.return" :key="index"&gt;&#123;&#123; item.show &#125;&#125;&lt;/Option&gt; &lt;/Select&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'FormSelect', props: &#123; value: &#123; type: String | Number, default: '' &#125;, info: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125; &#125;, computed: &#123; data: &#123; get () &#123; return this.value &#125;, set (val) &#123; this.$emit('input', val) &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; form-textarea.vue 1234567891011121314151617181920212223242526272829303132&lt;template&gt; &lt;Input type="textarea" v-model="data" :placeholder="info.conf.hintText ? info.conf.hintText : ''"/&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'FormTextarea', props: &#123; value: &#123; type: String | Number, default: '' &#125;, info: &#123; type: Object, default: () =&gt; (&#123;&#125;) &#125; &#125;, computed: &#123; data: &#123; get () &#123; return this.value &#125;, set (val) &#123; this.$emit('input', val) &#125; &#125; &#125;&#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 至此一个动态表单组件就完成了，记录一哈，嘿嘿:yum:]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的静态代理和动态代理]]></title>
    <url>%2Fjava-static-dynamic-proxy.html</url>
    <content type="text"><![CDATA[在学习SpringAOP之前，首先需要先对Java的静态代理和动态代理进行了解 静态代理所谓静态代理，就是让代理对象和目标对象实现共同的接口，并且代理对象中包含目标对象的引用 可以通过一个例子来理解静态代理，首先我们定义抽象的动物接口IAnimal : 123public interface IAnimal &#123; void say();&#125; 接着定义一个目标对象的类Dog，实现了IAnimal接口： 1234567891011121314151617181920212223242526272829303132public class Dog implements IAnimal &#123; @Override public void say() &#123; System.out.println("汪汪汪"); &#125;&#125;``` 然后定义代理对象的类`ProxyDog`，在代理对象中定义目标的引用： ```javapublic class ProxyDog implements IAnimal &#123; private IAnimal dog; public ProxyDog(IAnimal dog) &#123; super(); this.dog = dog; &#125; @Override public void say() &#123; dog.say(); &#125;&#125;``` 最后看下该怎么使用代理对象： ```javapublic class StaticTest &#123; public static void main(String[] args) &#123; IAnimal proxyDog = new ProxyDog(new Dog()); proxyDog.say(); &#125;&#125; 可以看到，静态代理本质上是在代理对象内部持有目标对象的引用，由于和目标对象实现了一样的接口，所以调用方法一样，在同样的调用方法里去调用目标对象的该方法，从而达到代理的目的。 动态代理动态代理通过实现java.lang.reflect.InvocationHandler接口，将目标对象引入进来，然后利用反射机制执行目标对象的方法。 还是上面的IAnimal接口，新写一个Cat实现类：123456public class Cat implements IAnimal &#123; @Override public void say() &#123; System.out.println("喵喵喵"); &#125;&#125; 然后定义个实现了InvocationHandler的代理类DynamicCat：123456789101112131415public class DynamicCat implements InvocationHandler &#123; private IAnimal cat; public IAnimal builder(IAnimal cat) &#123; this.cat = cat; return (IAnimal) Proxy.newProxyInstance(cat.getClass().getClassLoader(), this.cat.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return method.invoke(this.cat, args); &#125;&#125; 通过#builder()方法将目标对象引入，并通过Proxy.newProxyInstance创建代理对象，当调用方法时，本质上调用invoke方法，执行目标对象的方法： 123456public class DynamicTest &#123; public static void main(String[] args) &#123; IAnimal proxyCat = new DynamicCat().builder(new Cat()); proxyCat.say(); &#125;&#125;]]></content>
      <categories>
        <category>后端</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue router history模式在SpringBoot应用中的配置]]></title>
    <url>%2Fvue-router-history-springboot.html</url>
    <content type="text"><![CDATA[前面我们记录过vue router使用history模式时，项目打包扔在tomcat里时，tomcat该怎么配置来支持。这次vue项目打包后，js、css等静态资源发布在CDN上，将模版页index.html放在springboot后端项目里，再访问后端提供的url来转到index.html，那么该怎么配置呢？ 如上所述，这次静态资源发布在CDN，给后端项目一个模版页，模版页中引用静态资源，通过时间戳来更新获取最新版本。springboot模版引擎用的thymeleaf，这是模版页： 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"/&gt; &lt;meta content="width=device-width,maximum-scale=1.0,initial-scale=1.0,minimum-scale=1.0,user-scalable=yes,shrink-to-fit=no" name="viewport"/&gt; &lt;title&gt;xxx&lt;/title&gt; &lt;link th:href="$&#123;f2eCdnUrl&#125;+'/layout.min.css?'+$&#123;timestamp&#125;" rel="stylesheet"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;/div&gt; &lt;script type="text/javascript" th:src="$&#123;f2eCdnUrl&#125;+'/vendor.js?'+$&#123;timestamp&#125;"&gt;&lt;/script&gt; &lt;script type="text/javascript" th:src="$&#123;f2eCdnUrl&#125;+'/app.js?'+$&#123;timestamp&#125;"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; springboot提供一个controller接口来访问转到模版页： 12345678910111213@Controllerpublic class IndexController &#123; @Value("$&#123;f2e.cdn.url&#125;") private String f2eCdnUrl; @GetMapping("/view/") public String index(Model model) &#123; model.addAttribute("f2eCdnUrl", f2eCdnUrl); model.addAttribute("timestamp", System.currentTimeMillis()); return "index"; &#125;&#125; 这里的f2eCdnUrl是读取application.properties配的cdn的url，我这里对外是从/view/来访问index页面，而不是直接的/，因为如果我项目里有结合SpringSecurity，需要对/api/**的接口进行鉴权拦截，为了做区分，前端页面统一以/view开头，同样的，在vue router的配置里也需要指明base，如下 12345let router = new VueRouter(&#123; routes: routes, base: '/view', mode: 'history' &#125;) 这个时候，启动springboot项目，可以通过/view/来访问前端项目的首页，并通过前端路由来跳转页面，但一旦刷新页面或者手动输入URL回车就会出现404页面。其实和在tomcat配置的原理类似，我们需要做的是对404做处理，当出现404的时候，再往一个URL上跳。 我们看一下org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer这个接口： 1234567891011121314151617181920212223/** * Strategy interface for customizing auto-configured embedded servlet containers. Any * beans of this type will get a callback with the container factory before the container * itself is started, so you can set the port, address, error pages etc. * &lt;p&gt; * Beware: calls to this interface are usually made from a * &#123;@link EmbeddedServletContainerCustomizerBeanPostProcessor&#125; which is a * &#123;@link BeanPostProcessor&#125; (so called very early in the ApplicationContext lifecycle). * It might be safer to lookup dependencies lazily in the enclosing BeanFactory rather * than injecting them with &#123;@code @Autowired&#125;. * * @author Dave Syer * @see EmbeddedServletContainerCustomizerBeanPostProcessor */public interface EmbeddedServletContainerCustomizer &#123; /** * Customize the specified &#123;@link ConfigurableEmbeddedServletContainer&#125;. * @param container the container to customize */ void customize(ConfigurableEmbeddedServletContainer container);&#125; 可以看到，这个接口是实现了策略模式的，重点是我们使用这个接口去设置error pages，所以我们定义一个配置类，在配置类创建一个EmbeddedServletContainerCustomizer这个接口的bean: 123456789101112131415@Configurationpublic class ErrorPageConfig &#123; @Bean public EmbeddedServletContainerCustomizer containerCustomizer() &#123; return new EmbeddedServletContainerCustomizer() &#123; @Override public void customize(ConfigurableEmbeddedServletContainer configurableEmbeddedServletContainer) &#123; ErrorPage errorPage = new ErrorPage(HttpStatus.NOT_FOUND, "/view/"); configurableEmbeddedServletContainer.addErrorPages(errorPage); &#125; &#125;; &#125;&#125; 可以看到，定义了一个error page，http status是not found的时候，重新跳转回之前设置的/view/这个路径。至此，就实现了springboot对vue router history模式的支持。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud踩的坑：eureka接入security后unknown server]]></title>
    <url>%2Feureka-security-unknowserver.html</url>
    <content type="text"><![CDATA[在使用SpringCloud eureka注册中心，接入Spring security时出现了unknown server找不到注册中心无法注册的问题 最开始我的eureka server的配置是 123spring.securiy.basic.enabled=truespring.security.user.name=weixinspring.security.user.password=weixin 通过查找资料，有网友说高版本不再需要这些配置项，于是新建了个配置类 1234567891011121314151617181920@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.NEVER); http.authorizeRequests().anyRequest().authenticated().and().httpBasic(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication().passwordEncoder(NoOpPasswordEncoder.getInstance()) //admin .withUser("weixin").password("weixin").roles("EUREKA-CLIENT").and() //eureka-security-client .withUser("eureka-security-client").password("eureka-security-client").roles("EUREKA-CLIENT") ; &#125;&#125; 再次启动，发现问题依旧存在，继续查找，有网友说，高版本security默认开启了csrf检验，需要手动关闭csrf检验，于是在配置类中增加了 http.csrf().disable() 于是配置类最终是这样123456789101112131415161718192021@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.NEVER); http.csrf().disable(); http.authorizeRequests().anyRequest().authenticated().and().httpBasic(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication().passwordEncoder(NoOpPasswordEncoder.getInstance()) //admin .withUser("weixin").password("weixin").roles("EUREKA-CLIENT").and() //eureka-security-client .withUser("eureka-security-client").password("eureka-security-client").roles("EUREKA-CLIENT") ; &#125;&#125; 再次启动，问题依旧存在。此时，戏剧性的，令人无语的原因终于发现了，竟然是eureka server与client中的eureka.client.service-url.defaultZone该配置项的问题，我写的是eureka.client.service-url.default-zone，不是驼峰命名，导致了这个问题，所以defaultZone一定要是驼峰命名，通过查看源码我们可以知道原因，找到org.springframework.cloud.netflix.eureka.EurekaClientConfigBean这个类，找到下面这段代码： 1234567891011121314151617181920212223242526public List&lt;String&gt; getEurekaServerServiceUrls(String myZone) &#123; String serviceUrls = (String)this.serviceUrl.get(myZone); if (serviceUrls == null || serviceUrls.isEmpty()) &#123; serviceUrls = (String)this.serviceUrl.get("defaultZone"); &#125; if (!StringUtils.isEmpty(serviceUrls)) &#123; String[] serviceUrlsSplit = StringUtils.commaDelimitedListToStringArray(serviceUrls); List&lt;String&gt; eurekaServiceUrls = new ArrayList(serviceUrlsSplit.length); String[] var5 = serviceUrlsSplit; int var6 = serviceUrlsSplit.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; String eurekaServiceUrl = var5[var7]; if (!this.endsWithSlash(eurekaServiceUrl)) &#123; eurekaServiceUrl = eurekaServiceUrl + "/"; &#125; eurekaServiceUrls.add(eurekaServiceUrl.trim()); &#125; return eurekaServiceUrls; &#125; else &#123; return new ArrayList(); &#125;&#125; 由此我们可以看到源码中就是get(&quot;defaultZone&quot;)，而不是default-zone 好了，以上就是无法注册服务这个坑的逐步debug的过程，以后再遇到相似问题可以借鉴下]]></content>
      <categories>
        <category>后端</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>踩坑</tag>
        <tag>eureka</tag>
        <tag>SpringSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue router history模式在tomcat的配置]]></title>
    <url>%2Fvue-router-tomcat-config.html</url>
    <content type="text"><![CDATA[vue router在使用history时，部署时需要在服务器再进一步配置 vue中，router使用history模式，即mode: history，可以让项目在浏览器的地址显示和正常网页URL一样，不会出现/#/这样奇奇怪怪的东西， 但使用这种history模式需要再进一步配置，否则就会发现一回车或者刷新页面就会404。而官网只介绍了Apache、Nginx的配置方法，由于 我目前是将项目build之后部署在tomcat上，所以需要在tomcat上增加一些配置。 以往我们使用Java写web项目部署在tomcat时，通常都会有一个WEB-INF文件夹，并包含一个web.xml文件，而vue项目build之后只是纯静 态资源项目，所以我们需要在build之后的dist文件夹里新增一个WEB-INF文件夹，并新建web.xml文件，文件内容如下： 123456789101112&lt;?xml version="1.0" encoding="ISO-8859-1"?&gt;&lt;web-app xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" version="3.0" metadata-complete="true"&gt; &lt;display-name&gt;Your Project Name&lt;/display-name&gt; &lt;description&gt; Your Project Description &lt;/description&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/&lt;/location&gt; &lt;/error-page&gt; &lt;/web-app&gt; 至此再启动tomcat，再访问，就不会再出现刷新或回车后404的现象]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS获取客户端本地IP]]></title>
    <url>%2Fvue-getclient-ip.html</url>
    <content type="text"><![CDATA[vue前后端分离后，后端Java在使用request.getRemoteAddr获取的永远都是前端服务器的IP 在使用vue前后端分离之后，发现后端（Java）在使用request.getRemoteAddr之后获取的永远都是前端所部署的服务器的IP，在翻墙之后找到一段获取客户端浏览器本地的IP 123456789101112131415161718192021222324252627282930313233343536export function getUserIp (onNewIP) &#123; // compatibility for firefox and chrome var myPeerConnection = window.RTCPeerConnection || window.mozRTCPeerConnection || window.webkitRTCPeerConnection var pc = new myPeerConnection(&#123; iceServers: [] &#125;) var noop = function () &#123;&#125; var localIPs = &#123;&#125; var ipRegex = /([0-9]&#123;1,3&#125;(\.[0-9]&#123;1,3&#125;)&#123;3&#125;|[a-f0-9]&#123;1,4&#125;(:[a-f0-9]&#123;1,4&#125;)&#123;7&#125;)/g function iterateIP (ip) &#123; if (!localIPs[ip]) &#123; onNewIP(ip) &#125; localIPs[ip] = true &#125; pc.createDataChannel('') // create offer and set local description pc.createOffer().then(function (sdp) &#123; sdp.sdp.split('\n').forEach(function (line) &#123; if (line.indexOf('candidate') &lt; 0) &#123; return &#125; line.match(ipRegex).forEach(iterateIP) &#125;) pc.setLocalDescription(sdp, noop, noop) &#125;).catch(function (reason) &#123; // An error occurred, so handle the failure to connect &#125;) pc.onicecandidate = function (ice) &#123; if (!ice || !ice.candidate || !ice.candidate.candidate || !ice.candidate.candidate.match(ipRegex)) &#123; return &#125; ice.candidate.candidate.match(ipRegex).forEach(iterateIP) &#125;&#125; 定义一个工具JS，将方法getUserIp导出使用，参数onNewIP是一个function，这里我在登录的页面中调用该方法，首先定义了个方法，设置IP 123setUserIp (ip) &#123; this.ip = ip&#125; 再调用getUserIp方法：1getUserIp(this.setUserIp) 此时，会调用setUserIp将ip设置为客户端IP，至此就获得了客户端IP，再将IP请求发送给后端]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue下载导出文件]]></title>
    <url>%2Fvue-download-file.html</url>
    <content type="text"><![CDATA[Vue下载，将字符串导出成txt或pdf等文本文件 将字符串导出成txt或pdf等文本文件，只需要下面几行代码即可1234567let aTag = document.createElement('a')let content = 'this is test'let blob = new Blob([content])aTag.download = 'a.txt'aTag.href = URL.createObjectURL(blob)aTag.click();URL.revokeObjectURL(blob)]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ace-editor前端代码编辑器使用]]></title>
    <url>%2Fjs-ace-editor.html</url>
    <content type="text"><![CDATA[如何在页面使用代码编辑器 在git上将项目下载或者clone下来 进入项目根目录 npm install node ./Makefile.dryice.js 此时再将项目中build/src文件夹下的ace.js拷进项目中 「ext-language_tools.js」文件是必要的 「mode-」开头的文件是支持的代码类型文件，将需要用到的拷进项目，与ace.js同一级 「theme-」开头的文件是编辑器样式文件，同样将需要的拷进与ace.js同一级 「snippets」文件夹下文件使用的话，在项目中ace.js同级创建「snippets」文件夹，再将需要的拷进去 在html中使用： 首先要记得先引入ace.js和ext-language_tool.js 123456789101112131415161718192021&lt;style&gt; #editor &#123; /*position: absolute;*/ width: 100%; height: 400px; &#125;&lt;/style&gt;&lt;div id="editor"&gt;&lt;/div&gt;var editorInit = function(editorType, contentText) &#123; ace.require("ace/ext/language_tools"); window.editor = ace.edit("editor"); // editor.$blockScrolling = Infinity; editor.getSession().setMode("ace/mode/" + editorType); editor.setOptions(&#123; enableBasicAutocompletion: true, enableSnippets: true, enableLiveAutocompletion: true &#125;); editor.setTheme("ace/theme/twilight"); editor.setValue(contentText);&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring与SpringBoot：SpringAOP使用@Aspect]]></title>
    <url>%2Fspring-aop-aspect.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;在spring中，AOP和IOC都是spring非常重要的特性，而在web开发中，定义切面、增强方法也是比较常见的，比如做统一的日志管理相关的、自定义的注解处理、或者在处理用户请求的前后我们需要做一些处理，等等，这时我们都可以使用切面来实现，而在以前，使用切面我们可能需要使用很多接口和类，现在，我们只需要@Aspect这一个注解就可以定义切面。 &emsp;&emsp;首先，我们定义一个类，然后在这个类上使用@Aspect注解，这样一个切面就定义好了，我们可以再加上@Component注解，这样就把这个切面交给Spring容器来管理。 1234@Aspect@Componentpublic class RecommendLogAspect &#123;&#125; 接下来就是定义切点，并对切点做一些增强操作：前置增强、环绕增强、后置增强等等，切点的定义我们可以在一个空方法体的方法上使用@Pointcut注解 12@Pointcut("@annotation(com.sino.baseline.common.annotation.InitQueryParam)") public void pointcut() &#123;&#125; @Pointcut()里面定义的是切点表达式，切点表达式有很多，上面例子代码中的是注解表达式，标注来指定注解的目标类或者方法，就比如凡是使用了com.sino.baseline.common.annotation.InitQueryParam这个注解的类或者方法都是切点。除了@annotation()还有几类比较常见的切点表达式： 1.execution(方法修饰符 返回类型 方法全限定名 参数)匹配指定的方法，例如. 12345678910111213141516171819202122232425262728@Pointcut("execution(* com.tcb.controller.SDProductController.showproductDetail(..))")``` &gt; \* 匹配任意字符，但只能匹配一个元素 &gt; .. 匹配任意字符，可以匹配任意多个元素，表示类时，必须和*联合使用 &gt; \+ 必须跟在类名后面，如Student+，表示类本身和继承或扩展指定类的所有类 2.args( 参数类型的类全限定名 ) 匹配参数是指定类型的方法，比如@Pointcut(com.xx.Student) 就是匹配所有参数是student类对象的方法，像void add(Student s)这样的方法就会被匹配。3.@args( 注解类的类全限定名 ) 匹配参数的类型的类被指定注解修饰的方法，注意，这个参数的类型还必须是自定义的类，比如@Pointcut(com.xx.anno.ExAnno)，你有一个方法void(Student s)&#123;&#125;，而参数类型Student是你自定义的类，而Student这个类被@ExAnno修饰了，那么，这个方法就会被匹配（这个地方有点坑！）。 4.within( 类全限定名 ) 匹配指定的类，比如@Pointcut(com.xx.IndexController)就是IndexController类下的方法都会被匹配，这里的类名支持正则模糊匹配，比如@Pointcut(com.xx.*Controller)就是com.xx包下的所有的Controller都会被匹配。对了，上面和下面的表达式都支持正则模糊匹配 5.target( 类全限定名 ) 匹配指定的类以及它的子类，比如@Pointcut(com.xxx.dao.BaseDao)就是匹配BaseDao接口以及所有实现类这个接口的子类。 6.@within( 类全限定名 ) 匹配使用了指定的注解的类以及它的子类，比如@Pointcut(com.xxx.anno.Log)就是指，我在BaseController里使用了@Log注解，那么BaseController以及继承BaseController的类都会被匹配。 7.@target( 类全限定名 ) 匹配使用了指定注解的类（从这里我们看出来，within、target和@within、@target是相反，郁闷。。。），还是@Pointcut(com.xxx.anno.Log)就是仅匹配使用了@Log注解的类--ok，以上是一些较常用的切点表达式，然后继续之前的。 在定义切点之后，我们就可以对切点进行增强操作（注意，我前面@Pointcut注解修饰的方法名是pointcut()哦），比如@Before("pointcut()")前置增强，@Around("pointcut()")环绕增强。。。等等，注意，我这里直接使用的前面定义切点的那个方法名，这种方式属于独立切点命名（划重点！），就是将切点单独定义出来，对于当切点较多时，能够提高一些重用性。这种算是显式地定义切点，除了这种还可以使用匿名切点，即直接在增强操作方法里直接写切点表达式，比如: ```java@Before("execution(* com.tcb.controller.SDProductController.showproductDetail(..))") public void beforeBrowse(JoinPoint joinPoint) &#123;&#125; 好了，增强主要有以下几种：1.@Before前置增强，在切点方法执行之前执行。这里多说几句，在增强方法中要获取request可以通过下面来获取： 12ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();HttpServletRequest request = attributes.getRequest(); 在前置增强中，想要获取切点方法的参数可以通过joinPoint.getArgs[]来获取，获取方法名可以通过joinPoint.getSignature().getDeclaringTypeName()来获取。2.@Around环绕增强.3.@AfterReturning后置增强，切点方法正常执行完返回后执行，如果有异常抛出而退出，则不会执行增强方法4.@AfterThrowing后置增强，只有切点方法异常抛出而退出后执行5.@After也是后置增强，但不管切点方法是正常退出还是异常退出都会执行 好了，以上就是AOP开发基于@Aspect等注解的使用方法，有新的心得再随时修改或者写第二篇，有不对的地方欢迎指摘，吃饭喽]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringData-JPA使用Specification实现动态查询]]></title>
    <url>%2Fspringdata-jpa-specification.html</url>
    <content type="text"><![CDATA[最近项目技术选型db框架选择了使用JPA，刚开始时，使用jpa进行一些单表简单的查询非常轻松，大家写的不亦乐乎，后来在遇到多条件动态查询的业务场景时，发现现有的JpaRepository提供的方法和自己写@Query已经满足了不了需求，难不成要对所有的条件和字段进行判断，再写很多个dao方法？后面查到jpa提供了围绕Specification这个接口的一系列类，来用于实现动态查询。 首先，需要定义一个dao接口，这个接口除了继承JpaRepository之外，还需要继承JpaSpecificationExecutor。12public interface FileInfoDao extends JpaRepository&lt;FileInfo, Long&gt;, JpaSpecificationExecutor&lt;FileInfo&gt;&#123;&#125; 这个接口我用于查询文件信息，我们可以看到JpaSpecificationExecutor有以下这些方法:12345T findOne(Specification&lt;T&gt; spec);List&lt;T&gt; findAll(Specification&lt;T&gt; spec);Page&lt;T&gt; findAll(Specification&lt;T&gt; spec, Pageable pageable);List&lt;T&gt; findAll(Specification&lt;T&gt; spec, Sort sort);long count(Specification&lt;T&gt; spec); indOne(spec): 根据条件查询获取一条数据; findAll(spec): 根据条件查询获取全部数据； findAll(specification, pageable): 根据条件分页查询数据，pageable设定页码、一页数据量，同时返回的是Page类对象，可以通过getContent()方法拿到List集合数据； findAll(specification, sort): 根据条件查询并返回排序后的数据； count(spec): 获取满足当前条件查询的数据总数； 现在光定义了dao也没用，人家需要你往方法里传Specification实现类的对象，Specification是一个接口： 123public interface Specification&lt;T&gt; &#123; Predicate toPredicate(Root&lt;T&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb);&#125; 所以我定义了一个实现类： 123456789101112131415161718192021222324252627282930public class SinoSpecification&lt;T&gt; implements Specification&lt;T&gt; &#123; private TableQueryParam param; private Class&lt;T&gt; clazz; public SinoSpecification(TableQueryParam param, Class&lt;T&gt; clazz) &#123; this.param = param; this.clazz = clazz; &#125; @Override public Predicate toPredicate(Root&lt;T&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) &#123; Field[] fields = clazz.getDeclaredFields(); Map&lt;String, Object&gt; conditions = param.getCondition(); List&lt;Predicate&gt; predicates = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; fields.length; i++) &#123; fields[i].setAccessible(true); String name = fields[i].getName(); if(conditions.containsKey(name)) &#123; if(ObjectUtils.isEmpty(conditions.get(name))) &#123; continue; &#125; predicates.add(cb.like(root.get(name), "%"+conditions.get(name)+"%")); &#125; &#125; return cb.and(predicates.toArray(new Predicate[predicates.size()])); &#125; &#125; 需要解释一下的是，TableQueryParam是我自定义的用于封装查询条件的类，有一个condition属性是条件Map集合。 这个类主要是通过反射获取实体类的字段属性，通过再去和TableQueryParam中的conditon里的条件进行比对，如果条件中包含，则将这个条件以及查询的值一起构造加入进Predicate，cb.like(arg1, arg2)这个方法，就代表模糊查询，类似sql中的Like，arg1参数代表要查询的字段，arg2代表查询的字段的值，转换成sql就是 arg1 LIKE arg2。当然，我这个自定义的SinoSpecification主要是用于模糊查询的，而真正Specification不仅仅支持模糊，还可以通过CriteriaBuilder里的方法来实现各种组合查询，例如cb.equal()进行等于查询，cb.greaterThan()、cb.lessThan()来实现大于小于，等等，可以说非常丰富。 定义好Specification之后，就可以调用前面说的findAll方法，将自定义的specification对象放进去即可。]]></content>
      <categories>
        <category>后端</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>jpa</tag>
      </tags>
  </entry>
</search>
